09:04:15.360 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@4a9b7b41: startup date [Fri Sep 11 09:04:15 CST 2020]; root of context hierarchy
09:04:15.583 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:04:15.610 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$2b56f98] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:15.833 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:04:15.868 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:04:16.081 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:04:16.081 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:04:16.156 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:04:16.156 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:04:16.315 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:04:16.402 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:04:16.524 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:04:16.527 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
09:04:16.530 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599786256529 with initial instances count: 4
09:04:16.788 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:04:17.015 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:04:17.015 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
09:04:17.046 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
09:04:17.060 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@23b550fd: startup date [Fri Sep 11 09:04:17 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4a9b7b41
09:04:18.102 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
09:04:18.464 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
09:04:18.916 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
09:04:18.960 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:04:19.108 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e69b6c9b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.279 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$7f4934d5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.287 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.292 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@10195bf5' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.296 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$a41dd787] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.305 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.341 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$2b56f98] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:04:19.881 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
09:04:19.897 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
09:04:19.908 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
09:04:19.908 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
09:04:19.911 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
09:04:20.137 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
09:04:20.141 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
09:04:20.141 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3081 ms
09:04:20.327 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:04:20.328 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:04:20.334 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@556d411f
09:04:20.534 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
09:04:20.743 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
09:04:21.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
09:04:21.752 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
09:04:21.752 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
09:04:21.752 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
09:04:21.753 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
09:04:21.753 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
09:04:23.451 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
09:04:23.451 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
09:04:23.452 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.452 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
09:04:23.452 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.452 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
09:04:23.453 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:04:23.454 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
09:04:23.454 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
09:04:23.454 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
09:04:23.454 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.454 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
09:04:23.455 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:04:23.455 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:04:23.456 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
09:04:23.456 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
09:04:23.456 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
09:04:23.456 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.457 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
09:04:23.457 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:04:23.457 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:04:23.457 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.458 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:04:23.459 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:04:23.462 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:04:23.462 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
09:04:23.463 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
09:04:23.464 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:04:23.464 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
09:04:23.464 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
09:04:23.464 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
09:04:23.466 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
09:04:23.468 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
09:04:23.468 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
09:04:23.469 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
09:04:23.471 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
09:04:23.471 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:04:23.586 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
09:04:23.597 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.601 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.602 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:04:23.602 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:04:23.879 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
09:04:23.934 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:04:23.934 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:04:24.048 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:04:24.136 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@23b550fd: startup date [Fri Sep 11 09:04:17 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4a9b7b41
09:04:24.190 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:04:24.190 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:04:24.871 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
09:04:24.879 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
09:04:24.879 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
09:04:24.879 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
09:04:24.879 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

09:04:24.880 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
09:04:24.880 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
09:04:24.880 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@e1b2c4
09:04:24.943 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 6b061a09-e97f-4aea-ad47-630fbdb8f4ad

09:04:25.067 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@37b3bb4, org.springframework.security.web.context.SecurityContextPersistenceFilter@1b5eae32, org.springframework.security.web.header.HeaderWriterFilter@3642659b, org.springframework.security.web.authentication.logout.LogoutFilter@6a1dfef5, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@3e7d08c7, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@a96d945, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@51f398f5, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@57f1e863, org.springframework.security.web.session.SessionManagementFilter@4bb9d8bd, org.springframework.security.web.access.ExceptionTranslationFilter@107aedc7, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@300be097]
09:04:25.206 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
09:04:25.364 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
09:04:25.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
09:04:25.487 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
09:04:25.489 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
09:04:25.489 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
09:04:25.496 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
09:04:25.497 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
09:04:25.498 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
09:04:25.500 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
09:04:25.507 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
09:04:25.517 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=23b550fd,type=ConfigurationPropertiesRebinder]
09:04:25.521 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
09:04:25.523 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
09:04:25.540 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
09:04:25.550 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:04:25.552 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:04:25.553 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:04:25.553 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:04:25.554 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:04:25.554 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:04:25.594 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:04:25.595 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:04:25.599 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:04:25.600 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
09:04:25.601 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
09:04:25.603 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599786265602 with initial instances count: 4
09:04:25.610 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
09:04:25.610 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599786265610, current=UP, previous=STARTING]
09:04:25.611 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
09:04:25.613 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
09:04:25.614 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
09:04:25.625 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
09:04:25.634 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
09:04:25.657 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
09:04:25.746 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
09:04:25.746 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
09:04:25.747 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
09:04:25.754 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
09:04:25.755 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
09:04:25.757 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
09:04:25.758 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
09:04:25.760 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
09:04:25.769 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
09:04:25.776 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
09:04:25.777 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
09:04:25.778 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
09:04:25.779 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
09:04:25.780 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
09:04:25.781 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
09:04:25.782 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
09:04:25.786 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
09:04:25.787 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
09:04:25.788 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
09:04:25.812 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
09:04:25.812 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
09:04:25.826 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
09:04:25.832 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
09:04:25.840 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
09:04:25.860 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
09:04:25.861 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
09:04:25.863 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.285 seconds (JVM running for 12.054)
09:04:26.253 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
09:04:26.253 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
09:04:26.267 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:04:26.276 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
09:04:26.421 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:04:26.484 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
09:04:26.485 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
09:08:23.002 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
09:08:23.015 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
09:08:23.036 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
09:08:23.043 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
09:08:23.052 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 8
09:08:36.724 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
09:08:36.727 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
09:08:36.731 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.inputList - <==      Total: 3
09:08:36.752 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:08:36.752 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:08:36.755 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:08:36.757 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:08:36.761 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
09:08:46.005 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
09:08:46.005 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-9-11(String), 2020-9-11(String)
09:08:46.008 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
09:08:46.012 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-9-11(String), 2020-9-11(String)
09:08:46.016 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
09:08:49.628 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
09:08:49.628 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-9-11(String), 2020-9-11(String)
09:08:49.630 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
09:08:49.633 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-9-11(String), 2020-9-11(String)
09:08:49.637 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
09:08:52.930 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:08:52.932 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:08:52.935 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:08:55.994 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:08:55.996 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:08:56.000 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:09:25.619 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:10:12.600 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:10:12.601 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:10:12.603 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
09:10:12.605 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:10:12.612 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:10:13.652 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:13.655 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:13.658 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:13.659 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:10:13.663 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:13.665 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:10:13.666 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:10:13.668 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:13.670 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:13.793 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:13.795 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:13.797 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:15.036 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:10:15.036 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:10:15.038 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
09:10:15.040 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:10:15.044 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:10:16.677 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:10:16.680 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:10:16.684 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:10:18.575 zt-spark [http-nio-9100-exec-6] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 09:10:18","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"112\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"20:40\",\"task\":[],\"dutyPeopleId\":11,\"peoplePhone\":\"18511071270\",\"peopleId\":9,\"peopleName\":\"用户一\",\"dutyStartTime\":\"08:40\",\"time\":[\"08:40\",\"20:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":12,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
09:10:18.577 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
09:10:18.581 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 09:10:18.575(Timestamp), 179(Integer), 112(String), 12(Integer)
09:10:18.621 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
09:10:18.629 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
09:10:18.633 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 9(Integer), 08:40(String), 20:40(String), 11(Integer)
09:10:18.646 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
09:10:18.696 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:10:18.696 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:10:18.699 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:10:18.703 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:10:18.707 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
09:10:20.137 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:10:20.142 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:10:20.145 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:10:21.299 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
09:10:21.302 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.inputList - ==> Parameters: 12(Integer)
09:10:21.304 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.inputList - <==      Total: 0
09:10:21.311 zt-spark [http-nio-9100-exec-9] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$49ce5a9a.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
09:10:22.534 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:10:22.537 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:10:22.540 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:10:24.832 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:24.833 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:10:24.835 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:24.835 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:24.838 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:24.838 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:10:24.839 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:10:24.841 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:24.843 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:24.897 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:24.899 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:24.901 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:28.879 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) ORDER BY a.id desc LIMIT 0, 30 
09:10:28.881 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:28.883 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:10:28.885 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) 
09:10:28.888 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:28.889 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:28.926 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:28.929 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:28.931 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:29.481 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) ORDER BY a.id desc LIMIT 0, 30 
09:10:29.484 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:29.486 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:10:29.487 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) 
09:10:29.491 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:29.492 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:29.528 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:29.530 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:29.532 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:30.022 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag = '4' ) ORDER BY a.id desc LIMIT 0, 30 
09:10:30.025 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:30.026 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 0
09:10:30.027 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag = '4' ) 
09:10:30.029 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:30.030 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:30.066 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:30.070 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:30.072 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:34.020 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:10:34.024 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:10:34.026 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:10:34.590 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.equipment_id AS equipmentId, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.of_park AS ofPark, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process, b.phone AS contact FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) ORDER BY a.id DESC LIMIT 0, 30 
09:10:34.593 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderList - ==> Parameters: 
09:10:34.595 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderList - <==      Total: 3
09:10:34.596 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderListTotal - ==>  Preparing: SELECT IFNULL(count(1),0) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) 
09:10:34.598 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderListTotal - ==> Parameters: 
09:10:34.599 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderListTotal - <==      Total: 1
09:10:45.469 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:45.469 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:10:45.472 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:10:45.472 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:45.474 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:45.474 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:10:45.475 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:10:45.478 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:10:45.479 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:10:45.542 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:10:45.544 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:10:45.546 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:10:50.445 zt-spark [http-nio-9100-exec-6] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 09:10:50","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"112\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"20:40\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"ASDF\"},{\"number\":[\"GHJK\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"}],\"dutyPeopleId\":11,\"peoplePhone\":\"18511071270\",\"peopleId\":3,\"peopleName\":\"用户一\",\"dutyStartTime\":\"08:40\",\"time\":[\"08:40\",\"20:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":12,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
09:10:50.445 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
09:10:50.449 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 09:10:50.445(Timestamp), 179(Integer), 112(String), 12(Integer)
09:10:50.490 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
09:10:50.491 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
09:10:50.494 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 08:40(String), 20:40(String), 11(Integer)
09:10:50.515 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
09:10:50.525 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
09:10:50.528 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 09:10:50.523(Timestamp), 设备2(String), ASDF(String), null
09:10:50.529 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
09:10:50.530 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
09:10:50.533 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 09:10:50.53(Timestamp), 设备2(String), GHJK(String), null
09:10:50.534 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
09:10:50.587 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:10:50.587 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:10:50.589 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:10:50.591 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:10:50.601 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 15
09:10:52.677 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:10:52.680 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:10:52.688 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 14
09:13:49.784 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@295dc8c6: startup date [Fri Sep 11 09:13:49 CST 2020]; root of context hierarchy
09:13:50.048 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:13:50.086 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$28436013] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:50.338 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:13:50.381 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:13:50.610 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:13:50.610 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:13:50.703 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:13:50.703 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:13:50.921 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:13:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:13:51.188 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:13:51.190 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
09:13:51.195 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599786831194 with initial instances count: 5
09:13:51.480 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:13:51.663 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:13:51.664 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
09:13:51.699 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
09:13:51.722 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@30d2942e: startup date [Fri Sep 11 09:13:51 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@295dc8c6
09:13:52.931 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
09:13:53.258 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
09:13:53.731 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
09:13:53.774 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:13:53.915 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c295d16] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.094 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$a4d72550] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.105 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.110 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@547bb2b2' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.115 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$c9abc802] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.126 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.155 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$28436013] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:13:54.726 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
09:13:54.738 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
09:13:54.747 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
09:13:54.747 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
09:13:54.751 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
09:13:54.999 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
09:13:55.003 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
09:13:55.003 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3281 ms
09:13:55.284 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:13:55.284 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:13:55.292 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@3a211e72
09:13:55.511 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
09:13:55.700 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
09:13:56.875 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
09:13:56.875 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
09:13:56.876 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
09:13:56.877 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
09:13:56.878 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
09:13:56.878 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
09:13:58.859 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
09:13:58.860 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
09:13:58.860 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.860 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
09:13:58.860 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
09:13:58.861 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:13:58.861 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.862 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
09:13:58.862 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
09:13:58.862 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
09:13:58.863 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
09:13:58.863 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:13:58.863 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:13:58.864 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.865 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
09:13:58.866 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
09:13:58.866 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
09:13:58.866 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
09:13:58.866 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:13:58.866 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:13:58.867 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.867 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.869 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
09:13:58.869 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
09:13:58.869 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
09:13:58.869 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
09:13:58.870 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:13:58.870 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:13:58.870 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:13:58.874 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:13:58.874 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
09:13:58.874 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
09:13:58.874 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:13:58.875 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
09:13:58.876 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
09:13:58.876 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
09:13:58.878 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
09:13:58.880 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
09:13:58.881 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
09:13:58.882 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
09:13:58.884 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
09:13:58.884 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:13:59.012 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
09:13:59.027 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.028 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.028 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.028 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.028 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.029 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.030 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.031 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.031 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.031 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:13:59.032 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:13:59.378 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
09:13:59.449 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:13:59.449 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:13:59.595 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:13:59.702 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@30d2942e: startup date [Fri Sep 11 09:13:51 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@295dc8c6
09:13:59.771 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:13:59.771 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:14:00.683 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
09:14:00.692 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
09:14:00.692 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
09:14:00.693 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
09:14:00.693 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

09:14:00.693 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
09:14:00.693 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
09:14:00.693 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@2812185
09:14:00.772 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 8d1b9c48-da9f-4909-819d-f3209ddaaecf

09:14:00.937 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@c76e0f2, org.springframework.security.web.context.SecurityContextPersistenceFilter@5b005355, org.springframework.security.web.header.HeaderWriterFilter@1fd258c3, org.springframework.security.web.authentication.logout.LogoutFilter@7a72265d, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@6c0b8896, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@6f1863dc, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@10640f9, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5a3692df, org.springframework.security.web.session.SessionManagementFilter@45c7610, org.springframework.security.web.access.ExceptionTranslationFilter@2d78fa4b, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@7be13df8]
09:14:01.069 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
09:14:01.264 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
09:14:01.270 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
09:14:01.414 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
09:14:01.416 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
09:14:01.416 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
09:14:01.426 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
09:14:01.427 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
09:14:01.428 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
09:14:01.432 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
09:14:01.440 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
09:14:01.452 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=30d2942e,type=ConfigurationPropertiesRebinder]
09:14:01.458 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
09:14:01.459 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
09:14:01.477 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
09:14:01.489 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:14:01.493 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:14:01.494 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:14:01.494 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:14:01.494 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:14:01.494 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:14:01.570 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:14:01.571 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:14:01.575 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:14:01.576 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
09:14:01.577 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
09:14:01.579 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599786841579 with initial instances count: 5
09:14:01.587 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
09:14:01.587 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599786841587, current=UP, previous=STARTING]
09:14:01.589 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
09:14:01.591 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
09:14:01.591 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
09:14:01.606 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
09:14:01.617 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
09:14:01.643 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
09:14:01.758 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
09:14:01.760 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
09:14:01.761 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
09:14:01.769 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
09:14:01.770 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
09:14:01.773 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
09:14:01.774 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
09:14:01.775 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
09:14:01.786 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
09:14:01.794 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
09:14:01.795 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
09:14:01.796 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
09:14:01.798 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
09:14:01.799 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
09:14:01.800 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
09:14:01.801 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
09:14:01.805 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
09:14:01.806 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
09:14:01.807 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
09:14:01.834 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
09:14:01.834 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
09:14:01.851 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
09:14:01.858 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
09:14:01.867 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
09:14:01.890 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
09:14:01.891 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
09:14:01.894 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.794 seconds (JVM running for 14.366)
09:14:02.044 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
09:14:02.044 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
09:14:02.063 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:14:02.071 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 27 ms
09:14:02.217 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:14:02.330 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
09:14:02.333 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
09:15:02.429 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:15:02.735 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:15:02.923 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 14
09:15:35.113 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:35.118 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:35.126 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:35.131 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:15:35.134 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:35.138 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:15:35.139 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:15:35.141 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:35.142 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:35.207 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:35.209 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:35.211 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:39.533 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) ORDER BY a.id desc LIMIT 0, 30 
09:15:39.536 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:39.539 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:15:39.539 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) 
09:15:39.541 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:39.543 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:39.579 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:39.582 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:39.584 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:40.122 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) ORDER BY a.id desc LIMIT 0, 30 
09:15:40.124 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:40.127 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:15:40.128 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) 
09:15:40.130 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:40.132 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:40.169 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:40.172 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:40.174 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:40.570 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag = '4' ) ORDER BY a.id desc LIMIT 0, 30 
09:15:40.572 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:40.574 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 0
09:15:40.575 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag = '4' ) 
09:15:40.577 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:40.578 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:40.617 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:40.619 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:40.621 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:40.990 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) ORDER BY a.id desc LIMIT 0, 30 
09:15:40.992 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:40.995 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:15:40.996 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IN ('1','2') ) 
09:15:40.998 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:41.001 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:41.042 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:41.044 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:41.047 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:41.371 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) ORDER BY a.id desc LIMIT 0, 30 
09:15:41.373 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:41.375 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 1
09:15:41.376 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 AND d.tag IS NULL ) 
09:15:41.378 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:41.379 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:41.412 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:41.414 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:41.416 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:41.811 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:15:41.813 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:15:41.815 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:15:41.816 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:15:41.818 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:15:41.820 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:15:41.860 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:15:41.862 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:15:41.864 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:15:43.954 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:15:43.956 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1003(String)
09:15:43.958 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:15:44.009 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:15:44.012 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1003(String)
09:15:44.014 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 4
09:15:44.015 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:15:44.017 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:15:44.019 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1003(String)
09:15:44.020 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: null(String)
09:15:44.020 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - <==      Total: 1
09:15:44.021 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:15:44.024 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,tag,tag_name AS tagName,join_name AS joinName,join_user_id AS joinUserId,operation_time AS operationTime,note FROM work_order_process WHERE work_order_id=? AND tag=? 
09:15:44.026 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1003(String), 5(String)
09:15:44.027 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.selectOne - <==      Total: 1
09:15:44.028 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.selectById - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE id=? 
09:15:44.030 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.selectById - ==> Parameters: 1003(String)
09:15:44.032 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.selectById - <==      Total: 1
09:15:49.637 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:15:49.639 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:15:49.641 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:15:49.678 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:15:49.678 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:15:49.680 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:15:49.680 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:15:49.681 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:15:49.681 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:15:49.682 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:15:49.684 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:15:49.685 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:16:00.185 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:16:00.188 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1003(String)
09:16:00.190 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:16:00.227 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:16:00.227 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:16:00.228 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:16:00.230 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1003(String)
09:16:00.230 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1003(String)
09:16:00.231 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: null(String)
09:16:00.231 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - <==      Total: 1
09:16:00.232 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 4
09:16:00.232 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:16:00.232 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,tag,tag_name AS tagName,join_name AS joinName,join_user_id AS joinUserId,operation_time AS operationTime,note FROM work_order_process WHERE work_order_id=? AND tag=? 
09:16:00.234 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1003(String), 5(String)
09:16:00.236 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.selectOne - <==      Total: 1
09:16:00.236 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.selectById - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE id=? 
09:16:00.238 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.selectById - ==> Parameters: 1003(String)
09:16:00.241 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.selectById - <==      Total: 1
09:16:02.903 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:16:02.905 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1002(String)
09:16:02.907 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:16:02.942 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:16:02.942 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:16:02.942 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:16:02.944 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: null(String)
09:16:02.944 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1002(String)
09:16:02.944 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1002(String)
09:16:02.945 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:16:02.945 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:16:02.945 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 1
09:16:04.890 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:16:04.892 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:16:04.894 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:16:04.927 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:16:04.927 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:16:04.927 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:16:04.929 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:16:04.929 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:16:04.929 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:16:04.930 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:16:04.930 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:16:04.930 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:16:12.743 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:16:12.743 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:16:12.747 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:16:12.749 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:16:12.756 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:16:15.681 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.company = ? 
09:16:15.682 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 18(Integer)
09:16:15.683 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 AND p.company = ? ORDER BY p.is_duty desc LIMIT 0,1000 
09:16:15.685 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 18(Integer)
09:16:15.688 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 2
09:16:36.886 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:16:36.886 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:16:36.888 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
09:16:36.890 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:16:36.894 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:16:39.692 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
09:16:39.694 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
09:16:39.701 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - <==      Total: 21
09:23:47.766 zt-spark [DiscoveryClient-HeartbeatExecutor-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - Re-registering apps/ZT-SPARK
09:23:47.766 zt-spark [DiscoveryClient-HeartbeatExecutor-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
09:23:47.785 zt-spark [DiscoveryClient-HeartbeatExecutor-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
09:23:47.788 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:23:48.930 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:23:48.932 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:23:48.936 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:23:48.935 zt-spark [http-nio-9100-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$f375fa0e.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
09:28:47.812 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:33:07.990 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:33:07.991 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:33:07.992 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:33:07.992 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:33:07.995 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:33:07.995 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:33:07.996 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:33:07.998 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:33:07.999 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:33:08.139 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:33:08.141 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:33:08.143 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:33:13.394 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:33:13.396 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:33:13.398 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:33:13.440 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:33:13.440 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:33:13.443 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:33:13.443 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:33:13.444 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:33:13.444 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:33:13.444 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:33:13.447 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:33:13.448 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:33:47.836 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:33:54.448 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:33:54.449 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:33:54.451 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:33:54.452 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:33:54.453 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:33:54.457 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:33:54.459 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:33:54.462 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:33:54.464 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:33:54.620 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:33:54.623 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:33:54.625 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:33:56.681 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:33:56.684 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:33:56.686 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:33:56.740 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:33:56.743 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:33:56.744 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:33:56.763 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:33:56.766 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:33:56.768 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:33:56.769 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:33:56.772 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:33:56.774 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:35:02.375 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:35:02.375 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:35:02.377 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:35:02.377 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:35:02.379 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:35:02.379 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:35:02.380 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:35:02.382 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:35:02.383 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:35:02.486 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:35:02.488 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:35:02.490 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:35:06.057 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:35:06.059 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:35:06.061 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:35:06.105 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:35:06.105 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:35:06.106 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:35:06.108 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:35:06.108 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:35:06.108 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:35:06.109 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:35:06.109 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:35:06.109 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:37:44.871 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.equipment_id AS equipmentId, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.of_park AS ofPark, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process, b.phone AS contact FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) ORDER BY a.id DESC LIMIT 0, 30 
09:37:44.873 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderList - ==> Parameters: 
09:37:44.876 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderList - <==      Total: 3
09:37:44.876 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderListTotal - ==>  Preparing: SELECT IFNULL(count(1),0) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) 
09:37:44.878 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderListTotal - ==> Parameters: 
09:37:44.879 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderListTotal - <==      Total: 1
09:37:46.808 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:37:46.808 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:37:46.810 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:37:46.812 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:37:46.816 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:38:02.869 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.equipment_id AS equipmentId, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.of_park AS ofPark, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process, b.phone AS contact FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) ORDER BY a.id DESC LIMIT 0, 30 
09:38:02.872 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderList - ==> Parameters: 
09:38:02.874 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderList - <==      Total: 3
09:38:02.875 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderListTotal - ==>  Preparing: SELECT IFNULL(count(1),0) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1=1 ) 
09:38:02.877 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderListTotal - ==> Parameters: 
09:38:02.878 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.W.workOrderListTotal - <==      Total: 1
09:38:47.860 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:39:31.225 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:39:31.225 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:39:31.227 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:39:31.229 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:39:31.233 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:40:39.824 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:40:39.824 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:40:39.826 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:40:39.828 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:40:39.831 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:41:17.727 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:41:17.727 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:41:17.729 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:41:17.731 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:41:17.734 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:41:29.740 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:41:29.741 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:41:29.743 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:41:29.745 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:41:29.748 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:41:50.113 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:41:50.114 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:41:50.116 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:41:50.116 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:41:50.117 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:41:50.118 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:41:50.119 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:41:50.121 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:41:50.122 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:41:50.211 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:41:50.213 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:41:50.215 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:41:51.576 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:41:51.578 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:41:51.580 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:41:51.617 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:41:51.617 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:41:51.620 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:41:51.620 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:41:51.621 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:41:51.621 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:41:51.622 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:41:51.624 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:41:51.625 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:43:47.884 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:48:47.908 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:50:49.283 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:50:49.283 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:50:49.286 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:50:49.286 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:50:49.288 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:50:49.288 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:50:49.288 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:50:49.291 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:50:49.292 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:50:49.382 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:50:49.383 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:50:49.385 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:50:51.765 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==>  Preparing: SELECT id AS id,tenant_id AS tenantId,problem_level AS problemLevel,problem_type AS problemType,problem_desc AS problemDesc,equipment_name AS equipmentName,equipment_id AS equipmentId,report_person_id AS reportPersonId,report_addr AS reportAddr,report_time AS reportTime,report_lng AS reportLng,report_lat AS reportLat,data_source AS dataSource,exigency_status AS exigencyStatus,note,attachment_group_id AS attachmentGroupId,create_time AS createTime,assign_user_id AS assignUserId,assign_user_name AS assignUserName,del_flag AS delFlag,of_park AS ofPark,of_park_id AS ofParkId FROM work_order WHERE (del_flag = ? AND id = ?) 
09:50:51.767 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - ==> Parameters: 0(String), 1001(String)
09:50:51.768 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.WorkOrderMapper.selectList - <==      Total: 1
09:50:51.809 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==>  Preparing: select id, group_id, tenant_id, up_user_id, path, suffix, type, create_time, note from attachment WHERE group_id = ? 
09:50:51.810 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==>  Preparing: select id, work_order_id, tag, tag_name, join_name, join_user_id, operation_time, note from work_order_process WHERE work_order_id = ? 
09:50:51.811 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectOne - ==>  Preparing: SELECT id AS id,work_order_id AS workOrderId,description,is_achieve AS isAchieve,create_time AS createTime,user_id AS userId FROM work_order_verify WHERE work_order_id=? 
09:50:51.812 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - ==> Parameters: 1(String)
09:50:51.812 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - ==> Parameters: 1001(String)
09:50:51.813 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectOne - ==> Parameters: 1001(String)
09:50:51.813 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.A.selectAttachmentList - <==      Total: 0
09:50:51.813 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.W.selectWorkOrderProcessList - <==      Total: 0
09:50:51.814 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.selectOne - <==      Total: 0
09:53:07.367 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
09:53:07.373 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
09:53:07.375 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.inputList - <==      Total: 3
09:53:07.381 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:53:07.382 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:07.384 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:53:07.386 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:07.389 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 3
09:53:09.795 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:53:09.799 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
09:53:09.802 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:53:15.875 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:53:15.879 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:53:15.881 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:53:25.156 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:53:25.158 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:53:25.160 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
09:53:36.254 zt-spark [http-nio-9100-exec-4] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 09:53:36","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"18844447778\",\"peopleId\":3,\"peopleName\":\"测试\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
09:53:36.260 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
09:53:36.263 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 09:53:36.255(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
09:53:36.308 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
09:53:36.318 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
09:53:36.320 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
09:53:36.333 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
09:53:36.344 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
09:53:36.347 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 09:53:36.34(Timestamp), 设备1(String), ASDF,GHJK(String), null
09:53:36.349 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
09:53:36.403 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:53:36.404 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:36.406 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:53:36.408 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:36.410 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
09:53:38.497 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:53:38.499 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:53:38.502 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:53:47.734 zt-spark [http-nio-9100-exec-6] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 09:53:47","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":3,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
09:53:47.735 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
09:53:47.738 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 09:53:47.734(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
09:53:47.784 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
09:53:47.785 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
09:53:47.787 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
09:53:47.808 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
09:53:47.809 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
09:53:47.811 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 09:53:47.809(Timestamp), 设备1(String), ASDF,GHJK(String), 3(Integer)
09:53:47.833 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 1
09:53:47.890 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:53:47.890 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:47.892 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:53:47.894 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:47.896 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
09:53:47.932 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:53:49.103 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:53:49.106 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:53:49.109 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:53:59.122 zt-spark [http-nio-9100-exec-3] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 09:53:59","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":3,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
09:53:59.123 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
09:53:59.127 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 09:53:59.122(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
09:53:59.157 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
09:53:59.158 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
09:53:59.161 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
09:53:59.173 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
09:53:59.174 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
09:53:59.176 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 09:53:59.174(Timestamp), 设备1(String), ASDF,GHJK(String), 3(Integer)
09:53:59.198 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 1
09:53:59.255 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
09:53:59.255 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:59.257 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
09:53:59.259 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
09:53:59.262 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
09:54:00.714 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:54:00.717 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:54:00.719 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:55:27.562 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:55:27.562 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:55:27.563 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
09:55:27.565 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:55:27.569 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:55:28.115 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:55:28.115 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:55:28.117 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:55:28.117 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:55:28.119 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:55:28.119 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:55:28.120 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:55:28.122 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:55:28.123 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:55:28.229 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:55:28.231 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:55:28.233 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:55:29.290 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:55:29.291 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:55:29.292 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:55:29.294 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:55:29.297 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:56:11.269 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
09:56:11.271 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
09:56:11.273 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
09:57:51.507 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
09:57:51.507 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:57:51.509 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,1000 
09:57:51.511 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
09:57:51.514 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
09:58:47.956 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:59:18.304 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:59:18.304 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==>  Preparing: SELECT a.id AS id, a.problem_level AS problemLevel, a.problem_type AS problemType, a.problem_desc AS problemDesc, a.equipment_name AS equipmentName, a.report_addr AS reportAddr, a.report_time AS reportTime, b.user_realname AS reportPersonName, a.report_lng AS reportLng, a.report_lat AS reportLat, a.attachment_group_id AS attachmentGroupId, ( CASE d.tag WHEN '1' THEN '已派遣' WHEN '2' THEN '已受理' WHEN '3' THEN '处置中' WHEN '4' THEN '已完成' WHEN '5' THEN '已关闭' ELSE '待派遣' END ) AS process FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) ORDER BY a.id desc LIMIT 0, 30 
09:59:18.306 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - ==> Parameters: 
09:59:18.306 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:59:18.308 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:59:18.308 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignList - <==      Total: 3
09:59:18.309 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==>  Preparing: SELECT count(1) FROM work_order AS a INNER JOIN sys_user AS b ON a.report_person_id = b.user_id LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id = d.work_order_id WHERE a.del_flag = '0' AND a.tenant_id = 14 AND ( 1 = 1 ) 
09:59:18.311 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - ==> Parameters: 
09:59:18.312 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.W.workOrderAssignListTotal - <==      Total: 1
09:59:18.379 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==>  Preparing: select 'pql' k ,count(1) v from work_order as a where a.tenant_id = 14 AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4' OR b.tag = '5') ) UNION ALL select 'czl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2') ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5') ) UNION ALL select 'wcl' k,count(1) v from work_order as a where a.tenant_id = 14 AND EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '4' ) AND NOT EXISTS( select 1 from work_order_process as b where b.work_order_id = a.id and b.tag = '5' ) 
09:59:18.381 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - ==> Parameters: 
09:59:18.382 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.WorkOrderMapper.statistics - <==      Total: 3
09:59:21.150 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@30d2942e: startup date [Fri Sep 11 09:13:51 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@295dc8c6
09:59:21.151 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
09:59:21.151 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789561151, current=DOWN, previous=UP]
09:59:21.151 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
09:59:21.154 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
09:59:21.154 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
09:59:21.154 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
09:59:21.154 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
09:59:21.157 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
09:59:21.157 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
09:59:21.157 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
09:59:21.157 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
09:59:21.158 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
09:59:21.159 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
09:59:22.326 zt-spark [Thread-40] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
09:59:22.342 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
09:59:22.352 zt-spark [Thread-40] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:59:25.357 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
09:59:25.363 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - deregister  status: 200
09:59:25.370 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
09:59:32.210 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5d1e75f4: startup date [Fri Sep 11 09:59:32 CST 2020]; root of context hierarchy
09:59:32.477 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:59:32.519 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b40500ff] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:32.771 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:59:32.816 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:59:33.057 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:59:33.057 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:59:33.144 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:59:33.144 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:59:33.364 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:59:33.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:59:33.618 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:59:33.621 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
09:59:33.625 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789573624 with initial instances count: 4
09:59:33.918 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:59:34.109 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:59:34.109 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
09:59:34.143 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
09:59:34.160 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6657795f: startup date [Fri Sep 11 09:59:34 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5d1e75f4
09:59:35.354 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
09:59:35.687 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
09:59:36.171 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
09:59:36.227 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
09:59:36.362 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$97eafe02] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.524 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$3098c63c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.535 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.540 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@49b6830e' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.551 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$556d68ee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.562 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:36.590 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b40500ff] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
09:59:37.120 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
09:59:37.132 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
09:59:37.142 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
09:59:37.142 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
09:59:37.146 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
09:59:37.409 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
09:59:37.413 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
09:59:37.413 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3253 ms
09:59:37.644 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:59:37.644 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:59:37.651 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@4073873e
09:59:37.872 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
09:59:38.063 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
09:59:39.322 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
09:59:39.322 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
09:59:39.322 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
09:59:39.322 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
09:59:39.323 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
09:59:39.323 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
09:59:39.323 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
09:59:39.323 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
09:59:39.323 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
09:59:39.324 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
09:59:39.325 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
09:59:39.325 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
09:59:41.244 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
09:59:41.245 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
09:59:41.245 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.246 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
09:59:41.246 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
09:59:41.246 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.246 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:59:41.247 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
09:59:41.248 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
09:59:41.248 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
09:59:41.248 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
09:59:41.248 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.248 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:59:41.249 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:59:41.250 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
09:59:41.250 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
09:59:41.250 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
09:59:41.250 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
09:59:41.251 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.251 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:59:41.251 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:59:41.251 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.252 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
09:59:41.253 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
09:59:41.257 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:59:41.257 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
09:59:41.257 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
09:59:41.257 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
09:59:41.257 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
09:59:41.258 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
09:59:41.260 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
09:59:41.262 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
09:59:41.263 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
09:59:41.264 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
09:59:41.266 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
09:59:41.266 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:59:41.391 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
09:59:41.406 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.407 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.407 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.407 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.408 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.409 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.410 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
09:59:41.411 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
09:59:41.755 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
09:59:41.830 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
09:59:41.830 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
09:59:41.977 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:59:42.084 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6657795f: startup date [Fri Sep 11 09:59:34 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5d1e75f4
09:59:42.154 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:59:42.154 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
09:59:43.059 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
09:59:43.069 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
09:59:43.069 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
09:59:43.069 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
09:59:43.070 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

09:59:43.070 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
09:59:43.070 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
09:59:43.070 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@7b17906d
09:59:43.149 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: a5ebd858-a48e-48af-b627-e94433244022

09:59:43.318 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@5b292f74, org.springframework.security.web.context.SecurityContextPersistenceFilter@7a7b29b8, org.springframework.security.web.header.HeaderWriterFilter@6749583e, org.springframework.security.web.authentication.logout.LogoutFilter@258451e1, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@5b1cf2c0, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@69ffde31, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3f5263bc, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@250a072d, org.springframework.security.web.session.SessionManagementFilter@796c6d7a, org.springframework.security.web.access.ExceptionTranslationFilter@5f2153f5, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@3626e9e0]
09:59:43.449 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
09:59:43.650 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
09:59:43.655 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
09:59:43.799 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
09:59:43.800 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
09:59:43.801 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
09:59:43.809 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
09:59:43.811 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
09:59:43.811 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
09:59:43.815 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
09:59:43.823 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
09:59:43.835 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6657795f,type=ConfigurationPropertiesRebinder]
09:59:43.841 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
09:59:43.843 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
09:59:43.861 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
09:59:43.873 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
09:59:43.876 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
09:59:43.878 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
09:59:43.878 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
09:59:43.878 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
09:59:43.878 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
09:59:43.956 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
09:59:43.957 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
09:59:43.961 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
09:59:43.961 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
09:59:43.963 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
09:59:43.964 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789583964 with initial instances count: 4
09:59:43.972 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
09:59:43.973 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789583973, current=UP, previous=STARTING]
09:59:43.974 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
09:59:43.976 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
09:59:43.977 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
09:59:43.991 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
09:59:44.002 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
09:59:44.029 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
09:59:44.134 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
09:59:44.135 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
09:59:44.136 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
09:59:44.142 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
09:59:44.143 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
09:59:44.146 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
09:59:44.147 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
09:59:44.148 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
09:59:44.157 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
09:59:44.165 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
09:59:44.166 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
09:59:44.167 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
09:59:44.168 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
09:59:44.169 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
09:59:44.170 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
09:59:44.171 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
09:59:44.175 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
09:59:44.176 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
09:59:44.177 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
09:59:44.204 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
09:59:44.204 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
09:59:44.220 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
09:59:44.226 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
09:59:44.236 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
09:59:44.257 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
09:59:44.258 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
09:59:44.260 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.771 seconds (JVM running for 13.779)
09:59:44.817 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
09:59:44.817 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
09:59:44.834 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
09:59:44.846 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 29 ms
09:59:44.989 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
09:59:45.068 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
09:59:45.069 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:00:19.160 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:00:19.183 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:00:19.193 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:00:19.194 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:00:19.195 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:00:19.199 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:00:19.201 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:00:19.210 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
10:00:22.470 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:00:22.475 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:00:22.484 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
10:01:10.988 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:01:10.993 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:01:10.993 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:10.994 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:01:10.997 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:01:11.000 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:01:11.002 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:11.008 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
10:01:12.277 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:01:12.280 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:01:12.289 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
10:01:15.654 zt-spark [http-nio-9100-exec-7] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:01:15","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":3,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:01:15.659 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:01:15.663 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:01:15.654(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:01:15.721 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:01:15.731 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:01:15.734 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:01:15.796 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:01:35.812 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:01:35.814 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - ==> Parameters: 3(Integer)
10:01:35.859 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - <==    Updates: 1
10:01:35.870 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
10:01:35.873 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:01:35.866(Timestamp), 设备1(String), ASDF,GHJK(String), 3(Integer)
10:01:35.875 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
10:01:35.939 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:01:35.940 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:35.944 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:01:35.947 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:35.951 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:01:39.171 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:01:39.178 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:01:39.185 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:01:50.221 zt-spark [http-nio-9100-exec-10] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:01:50","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":14,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:01:50.222 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:01:50.227 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:01:50.221(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:01:50.288 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:01:50.289 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:01:50.291 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:01:50.346 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:01:59.819 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:01:59.821 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.deleteById - ==> Parameters: 14(Integer)
10:01:59.886 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.deleteById - <==    Updates: 1
10:01:59.888 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
10:01:59.891 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:01:59.887(Timestamp), 设备1(String), ASDF,GHJK(String), 14(Integer)
10:01:59.893 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
10:01:59.954 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:01:59.954 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:59.957 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:01:59.961 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:01:59.965 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:02:01.856 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:01.860 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:01.863 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:06.596 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:06.600 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:06.603 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:12.041 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:12.047 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:12.055 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:28.261 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:28.264 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:28.267 zt-spark [http-nio-9100-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:32.900 zt-spark [http-nio-9100-exec-7] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:02:32","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:02:32.901 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:02:32.906 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:02:32.9(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:02:32.938 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:02:32.939 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:02:32.942 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:02:32.955 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:02:36.919 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:02:36.921 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - ==> Parameters: null
10:02:36.923 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.deleteById - <==    Updates: 0
10:02:36.924 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
10:02:36.927 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:02:36.923(Timestamp), 设备1(String), ASDF,GHJK(String), null
10:02:36.929 zt-spark [http-nio-9100-exec-7] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
10:02:36.980 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:02:36.981 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:02:36.983 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:02:36.986 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:02:36.989 zt-spark [http-nio-9100-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:02:43.294 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:43.296 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:43.300 zt-spark [http-nio-9100-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:46.450 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:46.454 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:46.458 zt-spark [http-nio-9100-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:02:51.339 zt-spark [http-nio-9100-exec-1] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:02:51","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:02:51.340 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:02:51.342 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:02:51.339(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:02:51.368 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:02:51.369 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:02:51.371 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:02:51.385 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:02:51.386 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:02:51.387 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.deleteById - ==> Parameters: null
10:02:51.389 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.deleteById - <==    Updates: 0
10:02:51.390 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.updatePointDutyJob - ==>  Preparing: update point_duty_job SET assign_user_id = ?, assign_user_name = ?, assign_time = ?, equipment_name = ?, equipment_num = ? where id = ? 
10:02:51.393 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.updatePointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:02:51.389(Timestamp), 设备1(String), ASDF(String), null
10:02:51.394 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.P.updatePointDutyJob - <==    Updates: 0
10:02:51.445 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:02:51.445 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:02:51.447 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:02:51.451 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:02:51.454 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:02:54.484 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:02:54.488 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:02:54.491 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:03:22.197 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:03:22.197 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:03:22.202 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:03:22.205 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:03:22.209 zt-spark [http-nio-9100-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:03:22.211 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:03:22.215 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:03:22.218 zt-spark [http-nio-9100-exec-4] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:03:28.386 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6657795f: startup date [Fri Sep 11 09:59:34 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5d1e75f4
10:03:28.388 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
10:03:28.389 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789808389, current=DOWN, previous=UP]
10:03:28.389 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:03:28.392 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
10:03:28.392 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:03:28.392 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
10:03:28.393 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:03:28.394 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
10:03:28.394 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
10:03:28.394 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:03:28.395 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
10:03:28.395 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
10:03:28.396 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
10:03:29.526 zt-spark [Thread-40] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
10:03:29.527 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:03:29.531 zt-spark [Thread-40] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:03:32.533 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
10:03:32.538 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - deregister  status: 200
10:03:32.542 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:03:39.341 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@307e4ca9: startup date [Fri Sep 11 10:03:39 CST 2020]; root of context hierarchy
10:03:39.593 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:03:39.626 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$44a4f617] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:39.881 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:03:39.925 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:03:40.163 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:03:40.163 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:03:40.257 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:03:40.257 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:03:40.488 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:03:40.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:03:40.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:03:40.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:03:40.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:03:40.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:03:40.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:03:40.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:03:40.724 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:03:40.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:03:40.731 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789820730 with initial instances count: 5
10:03:41.016 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:03:41.210 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:03:41.210 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:03:41.244 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:03:41.260 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@212d468e: startup date [Fri Sep 11 10:03:41 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@307e4ca9
10:03:42.455 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:03:42.811 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:03:43.262 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
10:03:43.301 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:03:43.434 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$288af31a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.596 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$c138bb54] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.606 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.611 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@625c9048' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.622 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$e60d5e06] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.633 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:43.661 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$44a4f617] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:03:44.209 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
10:03:44.221 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
10:03:44.230 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:03:44.230 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:03:44.234 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:03:44.475 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:03:44.478 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:03:44.478 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3218 ms
10:03:44.710 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:03:44.710 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:03:44.718 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@2c95db95
10:03:44.937 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:03:45.124 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:03:46.357 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:03:46.357 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:03:46.357 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:03:46.357 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:03:46.357 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:03:46.358 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:03:46.358 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:03:46.358 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:03:46.358 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:03:46.359 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:03:46.360 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:03:46.360 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:03:48.298 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:03:48.298 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:03:48.299 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.299 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:03:48.299 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:03:48.299 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.300 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:03:48.301 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:03:48.301 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:03:48.301 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:03:48.301 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:03:48.301 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.302 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:03:48.302 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:03:48.303 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:03:48.303 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:03:48.303 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:03:48.303 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:03:48.304 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.304 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:03:48.304 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:03:48.304 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.305 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:03:48.306 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:03:48.310 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:03:48.310 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:03:48.310 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:03:48.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:03:48.312 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:03:48.312 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:03:48.312 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:03:48.314 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:03:48.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:03:48.317 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:03:48.317 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:03:48.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:03:48.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:03:48.443 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:03:48.458 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.459 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.459 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.459 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.459 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.459 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.460 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.461 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.462 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.462 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.462 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.462 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.462 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:03:48.463 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:03:48.814 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:03:48.885 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:03:48.885 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:03:49.031 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:03:49.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@212d468e: startup date [Fri Sep 11 10:03:41 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@307e4ca9
10:03:49.207 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:03:49.207 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:03:50.073 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:03:50.081 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:03:50.082 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:03:50.082 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:03:50.083 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:03:50.083 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:03:50.083 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:03:50.083 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@e5223dc
10:03:50.161 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 543778d3-5507-47b2-8c8e-0d38b1bf4a3f

10:03:50.327 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@f66c727, org.springframework.security.web.context.SecurityContextPersistenceFilter@f1d35a9, org.springframework.security.web.header.HeaderWriterFilter@64de3ee2, org.springframework.security.web.authentication.logout.LogoutFilter@66832d30, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@92c2a74, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7d67fe03, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3c42973a, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@444923df, org.springframework.security.web.session.SessionManagementFilter@136c67cc, org.springframework.security.web.access.ExceptionTranslationFilter@5ccf6073, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@31d98f8e]
10:03:50.461 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:03:50.676 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:03:50.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:03:50.866 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:03:50.867 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:03:50.867 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:03:50.876 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:03:50.878 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:03:50.879 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:03:50.883 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:03:50.890 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:03:50.904 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=212d468e,type=ConfigurationPropertiesRebinder]
10:03:50.911 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:03:50.912 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:03:50.929 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:03:50.942 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:03:50.945 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:03:50.946 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:03:50.946 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:03:50.946 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:03:50.946 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:03:51.022 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:03:51.022 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:03:51.026 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:03:51.027 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:03:51.029 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:03:51.030 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789831030 with initial instances count: 5
10:03:51.038 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:03:51.038 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789831038, current=UP, previous=STARTING]
10:03:51.039 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:03:51.042 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:03:51.042 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:03:51.059 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:03:51.071 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:03:51.102 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:03:51.213 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:03:51.215 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:03:51.216 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:03:51.223 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:03:51.224 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:03:51.226 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:03:51.227 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:03:51.228 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:03:51.238 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:03:51.245 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:03:51.246 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:03:51.247 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:03:51.248 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:03:51.249 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:03:51.250 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:03:51.251 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:03:51.256 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:03:51.256 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:03:51.257 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:03:51.283 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:03:51.283 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:03:51.298 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:03:51.306 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
10:03:51.315 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:03:51.339 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
10:03:51.341 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
10:03:51.344 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.757 seconds (JVM running for 13.763)
10:03:51.919 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:03:51.919 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:03:51.934 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:03:51.943 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 24 ms
10:03:52.109 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:03:52.212 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:03:52.214 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:04:21.000 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:04:21.028 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:04:21.044 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:04:21.047 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:04:21.048 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:04:21.052 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:04:21.055 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:04:21.063 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:04:22.293 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:04:22.298 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:04:22.302 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:05:23.540 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@212d468e: startup date [Fri Sep 11 10:03:41 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@307e4ca9
10:05:23.541 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
10:05:23.541 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789923541, current=DOWN, previous=UP]
10:05:23.541 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:05:23.544 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
10:05:23.544 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:05:23.544 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
10:05:23.546 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:05:23.546 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
10:05:23.546 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
10:05:23.546 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:05:23.547 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
10:05:23.548 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
10:05:23.548 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
10:05:42.690 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@3f993e5d: startup date [Fri Sep 11 10:05:42 CST 2020]; root of context hierarchy
10:05:42.948 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:05:42.979 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$cbc6acee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:43.237 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:05:43.283 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:05:43.512 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:05:43.512 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:05:43.603 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:05:43.603 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:05:43.846 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:05:43.936 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:05:44.078 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:05:44.081 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:05:44.084 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789944083 with initial instances count: 5
10:05:44.366 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:05:44.549 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:05:44.550 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:05:44.583 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:05:44.600 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3af322b7: startup date [Fri Sep 11 10:05:44 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3f993e5d
10:05:45.795 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:05:46.169 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:05:46.637 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
10:05:46.676 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:05:46.816 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$afaca9f1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:46.986 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$485a722b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:46.997 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:47.003 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@2260b714' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:47.016 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$6d2f14dd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:47.028 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:47.057 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$cbc6acee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:05:47.614 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
10:05:47.626 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
10:05:47.636 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:05:47.636 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:05:47.639 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:05:47.879 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:05:47.882 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:05:47.882 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3282 ms
10:05:48.121 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:05:48.121 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:05:48.129 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@745aed4c
10:05:48.351 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:05:48.541 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:05:49.750 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:05:49.750 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:05:49.750 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:05:49.750 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:05:49.750 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:05:49.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:05:49.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:05:49.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:05:49.751 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:05:49.752 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:05:49.752 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:05:49.753 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:05:51.655 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:05:51.656 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:05:51.656 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.657 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:05:51.657 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:05:51.657 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.657 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:05:51.658 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:05:51.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:05:51.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:05:51.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:05:51.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:05:51.660 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:05:51.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:05:51.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:05:51.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:05:51.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:05:51.662 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.662 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:05:51.662 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:05:51.662 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.663 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:05:51.664 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:05:51.668 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:05:51.668 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:05:51.668 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:05:51.668 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:05:51.669 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:05:51.670 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:05:51.671 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:05:51.673 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:05:51.674 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:05:51.674 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:05:51.677 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:05:51.677 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:05:51.828 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:05:51.843 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.844 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.845 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.846 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.847 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.847 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.847 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.847 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:05:51.848 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:05:52.191 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:05:52.262 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:05:52.262 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:05:52.408 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:05:52.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3af322b7: startup date [Fri Sep 11 10:05:44 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3f993e5d
10:05:52.586 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:05:52.586 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:05:53.456 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:05:53.464 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:05:53.464 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:05:53.465 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:05:53.465 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:05:53.465 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:05:53.466 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:05:53.466 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@515ce57d
10:05:53.547 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 243d1ea9-0895-4a4d-9e53-1602d881c0b1

10:05:53.721 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@680b29f6, org.springframework.security.web.context.SecurityContextPersistenceFilter@275819fe, org.springframework.security.web.header.HeaderWriterFilter@1d592054, org.springframework.security.web.authentication.logout.LogoutFilter@4d4e3a54, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@3e660a2a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2374a321, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7c5742a7, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@58a8621d, org.springframework.security.web.session.SessionManagementFilter@39f552f2, org.springframework.security.web.access.ExceptionTranslationFilter@3b49cc9f, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@2b0b7be8]
10:05:53.859 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:05:54.062 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:05:54.068 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:05:54.219 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:05:54.221 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:05:54.221 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:05:54.231 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:05:54.232 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:05:54.233 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:05:54.236 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:05:54.245 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:05:54.260 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3af322b7,type=ConfigurationPropertiesRebinder]
10:05:54.274 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:05:54.276 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:05:54.301 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:05:54.318 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:05:54.322 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:05:54.324 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:05:54.324 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:05:54.324 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:05:54.324 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:05:54.408 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:05:54.409 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:05:54.413 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:05:54.413 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:05:54.415 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:05:54.416 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599789954416 with initial instances count: 5
10:05:54.425 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:05:54.425 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599789954425, current=UP, previous=STARTING]
10:05:54.426 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:05:54.429 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:05:54.429 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:05:54.443 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:05:54.455 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:05:54.485 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:05:54.602 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:05:54.603 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:05:54.604 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:05:54.610 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:05:54.611 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:05:54.614 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:05:54.614 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:05:54.616 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:05:54.625 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:05:54.633 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:05:54.634 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:05:54.635 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:05:54.636 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:05:54.637 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:05:54.639 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:05:54.640 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:05:54.644 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:05:54.645 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:05:54.646 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:05:54.705 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:05:54.705 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:05:54.720 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:05:54.728 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
10:05:54.738 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:05:54.762 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
10:05:54.765 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
10:05:54.768 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.819 seconds (JVM running for 13.807)
10:05:55.293 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:05:55.293 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:05:55.309 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:05:55.318 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 25 ms
10:05:55.467 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:05:55.562 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:05:55.564 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:06:50.063 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3af322b7: startup date [Fri Sep 11 10:05:44 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3f993e5d
10:06:50.063 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
10:06:50.063 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599790010063, current=DOWN, previous=UP]
10:06:50.064 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:06:50.066 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
10:06:50.067 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:06:50.067 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:06:50.067 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
10:06:50.069 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
10:06:50.069 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
10:06:50.069 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
10:06:50.069 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
10:06:50.070 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
10:06:50.070 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
10:06:54.684 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@7b269a1e: startup date [Fri Sep 11 10:06:54 CST 2020]; root of context hierarchy
10:06:54.898 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:06:54.923 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$be7ef284] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:55.167 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:06:55.204 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:06:55.428 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:06:55.428 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:06:55.504 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:06:55.504 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:06:55.690 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:06:55.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:06:55.900 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:06:55.902 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:06:55.905 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790015904 with initial instances count: 5
10:06:56.143 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:06:56.361 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:06:56.361 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:06:56.392 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:06:56.406 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@44b0d927: startup date [Fri Sep 11 10:06:56 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7b269a1e
10:06:57.270 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:06:57.560 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:06:57.938 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
10:06:57.971 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:06:58.082 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a264ef87] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.219 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$3b12b7c1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.227 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.232 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@3548018c' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.235 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$5fe75a73] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.245 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.267 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$be7ef284] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:06:58.753 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9100 (http)
10:06:58.763 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9100"]
10:06:58.772 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:06:58.772 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:06:58.775 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:06:59.000 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:06:59.004 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:06:59.004 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2598 ms
10:06:59.191 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:06:59.191 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:06:59.198 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@4ea92f0b
10:06:59.382 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:06:59.549 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:07:00.597 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:07:00.597 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:07:00.597 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:07:00.597 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:07:00.597 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:07:00.598 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:07:00.598 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:07:00.598 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:07:00.598 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:07:00.599 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:07:00.600 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:07:00.600 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:07:02.335 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:07:02.335 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:07:02.336 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.336 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:07:02.336 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:07:02.336 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:07:02.337 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.338 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:07:02.338 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:07:02.338 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:07:02.338 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:07:02.338 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:07:02.339 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:07:02.339 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.340 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:07:02.340 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:07:02.341 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:07:02.341 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:07:02.341 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:07:02.341 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:07:02.341 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.342 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.343 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:07:02.343 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:07:02.343 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:07:02.343 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:07:02.344 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:07:02.344 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:07:02.344 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:07:02.347 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:07:02.348 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:07:02.350 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:07:02.352 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:07:02.353 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:07:02.353 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:07:02.355 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:07:02.355 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:07:02.455 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:07:02.467 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.468 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.469 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.469 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.469 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.469 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.470 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:07:02.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:07:02.745 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:07:02.801 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:07:02.801 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:07:02.916 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:07:03.004 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@44b0d927: startup date [Fri Sep 11 10:06:56 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7b269a1e
10:07:03.058 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:07:03.058 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:07:03.743 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:07:03.751 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:07:03.751 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:07:03.751 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:07:03.752 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:07:03.752 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:07:03.752 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:07:03.752 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@187aebba
10:07:03.816 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 10f1421a-e85b-4910-ab69-37afbb7a02e5

10:07:03.945 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@b253df1, org.springframework.security.web.context.SecurityContextPersistenceFilter@59815374, org.springframework.security.web.header.HeaderWriterFilter@5f3d93f9, org.springframework.security.web.authentication.logout.LogoutFilter@5ca1fbd2, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@36ba3ee6, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@546846b9, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@39328374, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@194a219e, org.springframework.security.web.session.SessionManagementFilter@31fafa49, org.springframework.security.web.access.ExceptionTranslationFilter@742583b3, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@2424e47a]
10:07:04.062 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:07:04.247 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:07:04.252 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:07:04.369 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:07:04.371 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:07:04.371 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:07:04.380 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:07:04.381 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:07:04.382 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:07:04.385 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:07:04.392 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:07:04.402 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=44b0d927,type=ConfigurationPropertiesRebinder]
10:07:04.406 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:07:04.408 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:07:04.424 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:07:04.435 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:07:04.438 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:07:04.439 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:07:04.439 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:07:04.439 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:07:04.439 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:07:04.480 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:07:04.481 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:07:04.485 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:07:04.486 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:07:04.488 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:07:04.489 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790024489 with initial instances count: 5
10:07:04.495 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:07:04.495 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599790024495, current=UP, previous=STARTING]
10:07:04.496 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100: registering service...
10:07:04.499 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:07:04.499 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:07:04.511 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:07:04.521 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9100 - registration status: 204
10:07:04.544 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:07:04.634 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:07:04.635 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:07:04.636 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:07:04.642 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:07:04.643 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:07:04.645 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:07:04.646 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:07:04.647 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:07:04.656 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:07:04.662 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:07:04.663 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:07:04.665 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:07:04.666 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:07:04.667 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:07:04.668 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:07:04.669 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:07:04.672 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:07:04.673 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:07:04.674 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:07:04.697 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:07:04.697 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:07:04.712 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:07:04.719 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9100"]
10:07:04.727 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:07:04.748 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9100 (http) with context path ''
10:07:04.749 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9100
10:07:04.751 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.835 seconds (JVM running for 11.584)
10:07:05.287 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:07:05.288 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:07:05.301 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:07:05.309 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
10:07:05.456 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:07:05.524 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:07:05.525 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:07:28.768 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:07:28.794 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:07:28.810 zt-spark [http-nio-9100-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:07:28.810 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:07:28.812 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:07:28.816 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:07:28.820 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:07:28.826 zt-spark [http-nio-9100-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:07:30.817 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:07:30.821 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:07:30.825 zt-spark [http-nio-9100-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:11:25.448 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5840b2a0: startup date [Fri Sep 11 10:11:25 CST 2020]; root of context hierarchy
10:11:25.672 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:11:25.700 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$c9aaff2e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:25.941 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:11:25.981 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:11:26.209 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:11:26.209 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:11:26.291 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:11:26.291 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:11:26.493 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:11:26.582 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:11:26.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:11:26.708 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:11:26.710 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:11:26.713 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790286713 with initial instances count: 5
10:11:26.937 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:11:27.164 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:11:27.164 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:11:27.196 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:11:27.211 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@4ff4ff9e: startup date [Fri Sep 11 10:11:27 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5840b2a0
10:11:28.113 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:11:28.432 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:11:28.857 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
10:11:28.890 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:11:29.003 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ad90fc31] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.151 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$463ec46b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.160 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.166 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@6a372ccb' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.176 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$6b13671d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.186 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.215 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$c9aaff2e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:11:29.716 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
10:11:29.727 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
10:11:29.736 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:11:29.736 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:11:29.739 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:11:29.973 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:11:29.978 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:11:29.978 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2767 ms
10:11:30.170 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:11:30.170 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:11:30.177 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@50961f7a
10:11:30.366 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:11:30.540 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:11:31.679 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:11:31.680 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:11:31.681 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:11:31.681 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:11:31.682 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:11:31.683 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:11:31.683 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:11:33.425 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:11:33.426 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:11:33.426 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.426 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:11:33.426 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:11:33.426 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.427 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:11:33.428 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:11:33.429 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:11:33.429 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:11:33.429 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:11:33.429 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.429 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:11:33.430 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:11:33.431 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:11:33.431 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:11:33.431 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:11:33.431 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:11:33.432 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.432 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:11:33.432 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:11:33.432 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:11:33.434 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:11:33.438 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:11:33.438 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:11:33.439 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:11:33.440 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:11:33.440 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:11:33.440 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:11:33.442 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:11:33.445 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:11:33.445 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:11:33.446 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:11:33.448 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:11:33.448 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:11:33.578 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:11:33.593 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.595 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.596 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.596 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.596 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.596 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.596 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.597 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.597 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.597 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.597 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.598 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.599 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:11:33.600 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:11:33.960 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:11:34.041 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:11:34.041 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:11:34.159 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:11:34.252 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@4ff4ff9e: startup date [Fri Sep 11 10:11:27 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5840b2a0
10:11:34.309 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:11:34.309 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:11:35.017 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:11:35.027 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:11:35.028 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:11:35.028 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:11:35.029 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:11:35.029 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:11:35.029 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:11:35.029 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@211abf8a
10:11:35.096 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: fe59cf01-1f5d-44dd-a59b-9aafbccf25c4

10:11:35.230 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@472f8172, org.springframework.security.web.context.SecurityContextPersistenceFilter@281e4721, org.springframework.security.web.header.HeaderWriterFilter@4c994cd8, org.springframework.security.web.authentication.logout.LogoutFilter@a246b4d, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@21e3dc01, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@5eb1a4e6, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@12adb54d, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5de58967, org.springframework.security.web.session.SessionManagementFilter@14f3f341, org.springframework.security.web.access.ExceptionTranslationFilter@7cdae676, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@266c8897]
10:11:35.339 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:11:35.500 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:11:35.505 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:11:35.629 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:11:35.631 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:11:35.631 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:11:35.638 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:11:35.639 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:11:35.640 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:11:35.643 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:11:35.650 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:11:35.662 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=4ff4ff9e,type=ConfigurationPropertiesRebinder]
10:11:35.667 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:11:35.669 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:11:35.687 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:11:35.698 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:11:35.701 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:11:35.702 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:11:35.702 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:11:35.703 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:11:35.703 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:11:35.749 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:11:35.750 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:11:35.755 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:11:35.756 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:11:35.758 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:11:35.759 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790295759 with initial instances count: 4
10:11:35.767 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:11:35.767 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599790295767, current=UP, previous=STARTING]
10:11:35.769 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
10:11:35.772 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:11:35.773 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:11:35.790 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:11:35.802 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
10:11:35.834 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:11:35.942 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:11:35.943 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:11:35.945 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:11:35.954 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:11:35.957 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:11:35.962 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:11:35.963 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:11:35.965 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:11:35.978 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:11:35.987 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:11:35.988 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:11:35.990 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:11:35.993 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:11:35.994 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:11:35.996 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:11:35.998 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:11:36.004 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:11:36.006 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:11:36.008 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:11:36.054 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:11:36.055 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:11:36.078 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:11:36.091 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
10:11:36.104 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:11:36.141 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
10:11:36.143 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
10:11:36.147 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.435 seconds (JVM running for 12.186)
10:11:36.748 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:11:36.748 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:11:36.771 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
10:11:36.912 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:11:37.084 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:11:37.169 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:11:37.170 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:13:00.452 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@a9b005a: startup date [Fri Sep 11 10:13:00 CST 2020]; root of context hierarchy
10:13:00.681 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:13:00.705 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9354f70a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:00.947 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:13:00.983 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:13:01.206 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:13:01.206 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:13:01.285 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:13:01.285 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:13:01.472 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:13:01.569 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:13:01.570 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:13:01.684 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:13:01.686 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:13:01.689 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790381689 with initial instances count: 5
10:13:01.920 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:13:02.140 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:13:02.140 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:13:02.172 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:13:02.186 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@71026bc5: startup date [Fri Sep 11 10:13:02 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@a9b005a
10:13:03.057 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:13:03.350 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:13:03.733 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
10:13:03.766 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:13:03.881 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$773af40d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.014 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$fe8bc47] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.022 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.027 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@fd01b5' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.036 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$34bd5ef9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.045 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.068 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9354f70a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:13:04.538 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
10:13:04.548 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
10:13:04.557 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:13:04.557 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:13:04.577 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:13:04.806 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:13:04.810 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:13:04.810 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2624 ms
10:13:04.997 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:13:04.997 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:13:05.003 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@73fa038c
10:13:05.188 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:13:05.359 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:13:06.462 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:13:06.463 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:13:06.464 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:13:06.465 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:13:06.465 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:13:08.208 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:13:08.209 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:13:08.209 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.210 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:13:08.210 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:13:08.210 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.210 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:13:08.211 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:13:08.211 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:13:08.211 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:13:08.212 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:13:08.212 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.212 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:13:08.212 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:13:08.214 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:13:08.215 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.216 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:13:08.216 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:13:08.216 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:13:08.216 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:13:08.217 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:13:08.217 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:13:08.217 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:13:08.220 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:13:08.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:13:08.223 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:13:08.225 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:13:08.226 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:13:08.226 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:13:08.228 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:13:08.228 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:13:08.331 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:13:08.344 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.345 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.346 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.346 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.346 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.346 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.347 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.347 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.347 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.347 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.347 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.348 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.348 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.348 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.348 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.348 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.349 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.349 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.349 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:13:08.350 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:13:08.627 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:13:08.683 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:13:08.683 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:13:08.796 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:13:08.892 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@71026bc5: startup date [Fri Sep 11 10:13:02 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@a9b005a
10:13:08.949 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:13:08.950 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:13:09.643 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:13:09.651 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:13:09.651 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:13:09.651 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:13:09.651 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:13:09.652 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:13:09.652 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:13:09.652 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@230ee64c
10:13:09.715 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: d2ba8dfa-9486-49d8-b636-e0103a30d801

10:13:09.840 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@3b90d2c1, org.springframework.security.web.context.SecurityContextPersistenceFilter@22986166, org.springframework.security.web.header.HeaderWriterFilter@2c296758, org.springframework.security.web.authentication.logout.LogoutFilter@13539065, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2e10bac0, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@6c522b3c, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@673ea87b, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@6ecb0679, org.springframework.security.web.session.SessionManagementFilter@31f7e2c6, org.springframework.security.web.access.ExceptionTranslationFilter@1f7d3fce, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@e864c76]
10:13:09.955 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:13:10.127 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:13:10.132 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:13:10.276 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:13:10.277 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:13:10.277 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:13:10.284 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:13:10.285 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:13:10.286 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:13:10.289 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:13:10.295 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:13:10.305 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=71026bc5,type=ConfigurationPropertiesRebinder]
10:13:10.309 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:13:10.310 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:13:10.327 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:13:10.338 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:13:10.340 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:13:10.342 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:13:10.342 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:13:10.342 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:13:10.342 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:13:10.384 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:13:10.384 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:13:10.388 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:13:10.389 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:13:10.390 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:13:10.391 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599790390391 with initial instances count: 5
10:13:10.397 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:13:10.398 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599790390398, current=UP, previous=STARTING]
10:13:10.399 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
10:13:10.401 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:13:10.401 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:13:10.412 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:13:10.423 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
10:13:10.444 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:13:10.533 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:13:10.534 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:13:10.535 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:13:10.542 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:13:10.543 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:13:10.546 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:13:10.547 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:13:10.548 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:13:10.557 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:13:10.564 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:13:10.565 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:13:10.566 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:13:10.567 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:13:10.568 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:13:10.569 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:13:10.570 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:13:10.574 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:13:10.574 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:13:10.575 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:13:10.598 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:13:10.599 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:13:10.613 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:13:10.619 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
10:13:10.628 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:13:10.648 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
10:13:10.649 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
10:13:10.651 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.871 seconds (JVM running for 11.631)
10:13:11.074 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:13:11.074 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:13:11.092 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 18 ms
10:13:11.233 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:13:11.393 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:13:11.462 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:13:11.463 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:13:31.819 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:13:31.843 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:13:31.855 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:13:31.855 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:13:31.859 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:13:31.859 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:13:31.866 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:13:31.872 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:13:35.601 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:13:35.605 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:13:35.608 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:13:46.220 zt-spark [http-nio-9201-exec-8] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:13:46","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:13:46.223 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:13:46.226 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:13:46.22(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:13:46.268 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:13:46.276 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:13:46.278 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:13:46.326 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:13:46.328 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:13:46.330 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - ==> Parameters: null
10:13:46.332 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - <==    Updates: 0
10:13:46.339 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ? ) 
10:13:46.341 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:13:46.337(Timestamp), 设备1(String), ASDF,GHJK(String)
10:13:46.360 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
10:13:46.460 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:13:46.461 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:13:46.463 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:13:46.465 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:13:46.469 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:14:00.611 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:14:00.618 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:14:00.623 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:14:09.056 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:14:09.060 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:14:09.065 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:14:11.648 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:14:11.651 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:14:11.654 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:18:10.408 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:22:39.843 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:22:39.845 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:22:39.849 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:22:47.852 zt-spark [http-nio-9201-exec-8] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:22:47","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:22:47.853 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:22:47.855 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:22:47.852(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:22:47.906 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:22:47.907 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:22:47.911 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:22:47.923 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:22:47.924 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - ==>  Preparing: DELETE FROM point_duty_job WHERE id=? 
10:22:47.926 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - ==> Parameters: null
10:22:47.928 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteById - <==    Updates: 0
10:22:47.929 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ? ) 
10:22:47.931 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 王舒达(String), 2020-09-11 10:22:47.928(Timestamp), 设备1(String), ASDF(String)
10:22:47.948 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
10:22:48.004 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:22:48.005 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:22:48.007 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:22:48.011 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:22:48.014 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:23:10.433 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:23:30.285 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:23:30.290 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:23:30.293 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:28:10.457 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:33:10.481 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:34:07.885 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@3c5d7b3f: startup date [Fri Sep 11 10:34:07 CST 2020]; root of context hierarchy
10:34:08.117 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:34:08.144 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6707593a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:08.415 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:34:08.453 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:34:08.667 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:34:08.667 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:34:08.745 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:34:08.745 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:34:08.910 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:34:08.997 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:34:09.116 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:34:09.119 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:34:09.122 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599791649121 with initial instances count: 6
10:34:09.357 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:34:09.590 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:34:09.591 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:34:09.622 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:34:09.636 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2c2202c4: startup date [Fri Sep 11 10:34:09 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3c5d7b3f
10:34:10.513 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:34:10.785 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:34:11.176 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
10:34:11.208 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:34:11.322 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4aed563d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.457 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$e39b1e77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.466 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.471 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@144e32eb' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.481 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$86fc129] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.490 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.513 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6707593a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:34:11.988 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
10:34:11.997 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
10:34:12.006 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:34:12.006 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:34:12.009 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:34:12.240 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:34:12.243 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:34:12.243 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2608 ms
10:34:12.432 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:34:12.433 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:34:12.439 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@16edd6ea
10:34:12.635 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:34:12.817 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:34:13.933 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:34:13.933 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:34:13.933 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:34:13.933 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:34:13.933 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:34:13.934 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:34:13.934 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:34:13.934 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:34:13.934 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:34:13.935 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:34:13.935 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:34:13.936 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:34:15.603 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:34:15.604 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:34:15.604 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.605 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:34:15.605 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.605 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:34:15.605 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:34:15.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:34:15.608 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:34:15.609 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:34:15.609 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:34:15.609 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:34:15.609 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.609 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:34:15.610 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:34:15.610 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:34:15.610 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.611 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:34:15.611 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:34:15.611 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:34:15.612 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:34:15.612 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:34:15.612 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:34:15.612 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:34:15.615 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:34:15.615 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:34:15.615 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:34:15.616 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:34:15.617 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:34:15.617 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:34:15.617 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:34:15.617 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:34:15.618 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:34:15.621 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:34:15.621 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:34:15.622 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:34:15.624 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:34:15.624 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:34:15.734 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:34:15.747 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.748 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.749 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.750 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.751 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.751 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:34:15.751 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:34:16.058 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:34:16.115 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:34:16.115 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:34:16.233 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:34:16.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2c2202c4: startup date [Fri Sep 11 10:34:09 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3c5d7b3f
10:34:16.381 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:34:16.381 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:34:17.069 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:34:17.077 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:34:17.077 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:34:17.077 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:34:17.078 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:34:17.078 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:34:17.078 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:34:17.078 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@4a470464
10:34:17.143 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 025cc19f-1c8e-41b6-978b-0abdb4887610

10:34:17.270 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@390ec226, org.springframework.security.web.context.SecurityContextPersistenceFilter@5720529c, org.springframework.security.web.header.HeaderWriterFilter@215709cf, org.springframework.security.web.authentication.logout.LogoutFilter@1873ae22, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@bc31488, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1fa059f8, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@493c6875, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@529adec3, org.springframework.security.web.session.SessionManagementFilter@7aca09f1, org.springframework.security.web.access.ExceptionTranslationFilter@7decd3b4, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@53172279]
10:34:17.380 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:34:17.541 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:34:17.546 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:34:17.666 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:34:17.668 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:34:17.668 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:34:17.675 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:34:17.676 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:34:17.677 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:34:17.680 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:34:17.687 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:34:17.696 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=2c2202c4,type=ConfigurationPropertiesRebinder]
10:34:17.701 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:34:17.702 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:34:17.719 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:34:17.730 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:34:17.733 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:34:17.734 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:34:17.734 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:34:17.734 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:34:17.734 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:34:17.774 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:34:17.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:34:17.779 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:34:17.780 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:34:17.781 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:34:17.783 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599791657782 with initial instances count: 6
10:34:17.789 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:34:17.789 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599791657789, current=UP, previous=STARTING]
10:34:17.790 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
10:34:17.793 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:34:17.793 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:34:17.805 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:34:17.813 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
10:34:17.837 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:34:17.930 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:34:17.931 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:34:17.932 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:34:17.938 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:34:17.940 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:34:17.942 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:34:17.943 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:34:17.944 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:34:17.953 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:34:17.960 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:34:17.961 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:34:17.962 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:34:17.964 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:34:17.965 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:34:17.967 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:34:17.968 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:34:17.973 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:34:17.975 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:34:17.976 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:34:18.002 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:34:18.002 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:34:18.018 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:34:18.026 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
10:34:18.035 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:34:18.061 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
10:34:18.062 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
10:34:18.065 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.862 seconds (JVM running for 11.752)
10:34:18.534 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:34:18.534 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:34:18.557 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
10:34:18.703 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:34:18.889 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:34:19.011 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:34:19.013 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:34:44.165 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:34:44.190 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:34:44.202 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:34:44.204 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:34:44.206 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:34:44.209 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:34:44.212 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:34:44.219 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:34:46.668 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:34:46.672 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:34:46.676 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:34:56.591 zt-spark [http-nio-9201-exec-4] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:34:56","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"二班一天\",\"taskDescription\":\"1号门值班\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"18:40\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":12,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"05:37\",\"time\":[\"05:37\",\"18:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":13,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:34:56.593 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:34:56.596 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 10:34:56.591(Timestamp), 179(Integer), 1号门值班(String), 13(Integer)
10:34:56.620 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:34:56.627 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:34:56.629 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 05:37(String), 18:40(String), 12(Integer)
10:34:56.645 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:34:56.646 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - ==>  Preparing: delete from point_duty_job where people_id = ? 
10:34:56.648 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - ==> Parameters: 3(Integer)
10:34:56.650 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - <==    Updates: 0
10:34:56.657 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ? ) 
10:34:56.659 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 179(String), 王舒达(String), 2020-09-11 10:34:56.655(Timestamp), 13(String), 设备1(String), ASDF(String)
10:34:56.687 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
10:34:56.745 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:34:56.745 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:34:56.748 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:34:56.750 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:34:56.754 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:35:36.628 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:35:36.632 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:35:36.636 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:35:43.351 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:35:43.355 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:35:43.360 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:36:10.101 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:36:10.106 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:36:10.110 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:38:06.108 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@2dbb780d: startup date [Fri Sep 11 10:38:06 CST 2020]; root of context hierarchy
10:38:06.328 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:38:06.357 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$fa698461] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:06.598 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:38:06.634 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:38:06.871 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:38:06.871 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:38:06.955 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:38:06.955 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:38:07.137 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:38:07.233 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:38:07.234 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:38:07.350 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:38:07.352 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:38:07.355 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599791887355 with initial instances count: 6
10:38:07.598 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:38:07.853 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:38:07.853 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:38:07.891 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:38:07.905 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6ecb1053: startup date [Fri Sep 11 10:38:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@2dbb780d
10:38:08.864 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:38:09.187 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:38:09.583 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
10:38:09.617 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:38:09.732 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$de4f8164] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.867 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$76fd499e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.876 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.881 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@65a4b26' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.890 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$9bd1ec50] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.899 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:09.922 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$fa698461] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:38:10.412 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
10:38:10.423 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
10:38:10.431 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:38:10.431 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:38:10.434 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:38:10.664 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:38:10.667 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:38:10.668 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2763 ms
10:38:10.857 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:38:10.857 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:38:10.864 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@73fa038c
10:38:11.052 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:38:11.233 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:38:12.369 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:38:12.370 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:38:12.371 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:38:12.371 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:38:12.371 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:38:12.372 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:38:12.372 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:38:14.590 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:38:14.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:38:14.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:38:14.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:38:14.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:38:14.593 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:38:14.593 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:38:14.593 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:38:14.594 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:38:14.594 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.594 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:38:14.594 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:38:14.595 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:38:14.595 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:38:14.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:38:14.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:38:14.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:38:14.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:38:14.597 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:38:14.598 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:38:14.599 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:38:14.601 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:38:14.601 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:38:14.602 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:38:14.603 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:38:14.603 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:38:14.603 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:38:14.604 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:38:14.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:38:14.607 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:38:14.608 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:38:14.610 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:38:14.610 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:38:14.711 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:38:14.722 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.723 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.723 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.723 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.723 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:38:14.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:38:14.997 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:38:15.055 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:38:15.056 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:38:15.171 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:38:15.259 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6ecb1053: startup date [Fri Sep 11 10:38:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@2dbb780d
10:38:15.313 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:38:15.314 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:38:16.004 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:38:16.011 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:38:16.012 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:38:16.012 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:38:16.012 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:38:16.012 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:38:16.012 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:38:16.013 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@71525572
10:38:16.079 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 930a27e6-651a-42e3-a1d0-bf8d7c5ff03f

10:38:16.210 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@54ea6eab, org.springframework.security.web.context.SecurityContextPersistenceFilter@746202b9, org.springframework.security.web.header.HeaderWriterFilter@3936c6b3, org.springframework.security.web.authentication.logout.LogoutFilter@5f0a50f, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2e0e1bd1, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@b73cc7d, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@1cc9e37, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@47867ab8, org.springframework.security.web.session.SessionManagementFilter@34620c33, org.springframework.security.web.access.ExceptionTranslationFilter@67f08c07, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@76e8412]
10:38:16.330 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:38:16.523 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:38:16.528 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:38:16.648 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:38:16.649 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:38:16.649 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:38:16.657 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:38:16.658 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:38:16.659 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:38:16.662 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:38:16.668 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:38:16.678 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6ecb1053,type=ConfigurationPropertiesRebinder]
10:38:16.683 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:38:16.684 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:38:16.702 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:38:16.713 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:38:16.716 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:38:16.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:38:16.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:38:16.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:38:16.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:38:16.759 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:38:16.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:38:16.765 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:38:16.765 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:38:16.767 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:38:16.768 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599791896768 with initial instances count: 6
10:38:16.775 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:38:16.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599791896775, current=UP, previous=STARTING]
10:38:16.776 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
10:38:16.779 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:38:16.779 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:38:16.791 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:38:16.800 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
10:38:16.824 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:38:16.913 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:38:16.914 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:38:16.915 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:38:16.920 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:38:16.922 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:38:16.924 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:38:16.925 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:38:16.926 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:38:16.935 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:38:16.941 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:38:16.942 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:38:16.943 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:38:16.945 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:38:16.946 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:38:16.947 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:38:16.947 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:38:16.951 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:38:16.952 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:38:16.953 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:38:16.977 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:38:16.978 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:38:16.993 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:38:16.999 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
10:38:17.008 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:38:17.030 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
10:38:17.031 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
10:38:17.033 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.635 seconds (JVM running for 12.499)
10:38:17.253 zt-spark [RMI TCP Connection(22)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:38:17.253 zt-spark [RMI TCP Connection(22)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:38:17.267 zt-spark [RMI TCP Connection(21)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:38:17.273 zt-spark [RMI TCP Connection(22)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 20 ms
10:38:17.425 zt-spark [RMI TCP Connection(21)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:38:17.503 zt-spark [RMI TCP Connection(21)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:38:17.506 zt-spark [RMI TCP Connection(21)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:43:03.647 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@238b13ec: startup date [Fri Sep 11 10:43:03 CST 2020]; root of context hierarchy
10:43:03.869 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:43:03.894 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$eadf485b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:04.138 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:43:04.176 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:43:04.404 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:43:04.404 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:43:04.479 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:43:04.479 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:43:04.669 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:43:04.760 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:43:04.880 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:43:04.882 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
10:43:04.886 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599792184884 with initial instances count: 6
10:43:05.130 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:43:05.361 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:43:05.361 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
10:43:05.392 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
10:43:05.405 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1045007f: startup date [Fri Sep 11 10:43:05 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@238b13ec
10:43:06.286 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
10:43:06.587 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
10:43:06.998 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
10:43:07.032 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
10:43:07.149 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$cec5455e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.282 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$67730d98] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.291 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.296 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@4d6f0b4f' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.306 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$8c47b04a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.316 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.339 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$eadf485b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
10:43:07.811 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
10:43:07.821 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
10:43:07.831 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
10:43:07.831 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
10:43:07.834 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
10:43:08.100 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
10:43:08.103 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
10:43:08.104 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2699 ms
10:43:08.299 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:43:08.300 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:43:08.307 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@669cc860
10:43:08.498 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
10:43:08.673 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
10:43:09.745 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
10:43:09.746 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
10:43:09.746 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
10:43:09.746 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
10:43:09.746 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
10:43:09.746 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
10:43:09.747 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
10:43:09.747 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
10:43:09.747 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
10:43:09.747 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
10:43:09.748 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
10:43:09.748 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
10:43:11.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
10:43:11.515 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
10:43:11.516 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.516 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
10:43:11.516 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
10:43:11.517 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.517 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:43:11.518 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
10:43:11.518 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
10:43:11.518 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
10:43:11.518 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
10:43:11.519 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.519 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:43:11.519 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:43:11.520 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
10:43:11.521 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
10:43:11.521 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
10:43:11.521 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
10:43:11.521 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.521 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:43:11.522 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:43:11.522 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.523 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
10:43:11.523 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
10:43:11.523 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
10:43:11.524 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
10:43:11.524 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
10:43:11.524 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
10:43:11.524 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
10:43:11.527 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:43:11.527 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
10:43:11.527 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
10:43:11.527 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
10:43:11.528 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
10:43:11.529 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
10:43:11.529 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
10:43:11.530 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
10:43:11.533 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
10:43:11.533 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
10:43:11.534 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
10:43:11.536 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
10:43:11.536 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:43:11.645 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
10:43:11.658 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.659 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.660 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.661 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.662 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
10:43:11.663 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
10:43:11.957 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
10:43:12.014 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
10:43:12.014 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
10:43:12.133 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:43:12.221 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1045007f: startup date [Fri Sep 11 10:43:05 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@238b13ec
10:43:12.276 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:43:12.276 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
10:43:12.969 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:43:12.977 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:43:12.977 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
10:43:12.978 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:43:12.978 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:43:12.978 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
10:43:12.978 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
10:43:12.978 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@89ce4d9
10:43:13.043 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 6406bd0b-3373-4114-8339-5dc9bf120c1f

10:43:13.175 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1a628a04, org.springframework.security.web.context.SecurityContextPersistenceFilter@642a8e0f, org.springframework.security.web.header.HeaderWriterFilter@fd4641e, org.springframework.security.web.authentication.logout.LogoutFilter@20ebaa68, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@296b7099, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@5716b2df, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@399ebbf8, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@1e005989, org.springframework.security.web.session.SessionManagementFilter@399adb46, org.springframework.security.web.access.ExceptionTranslationFilter@277317ce, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@223232c9]
10:43:13.283 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
10:43:13.446 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
10:43:13.451 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
10:43:13.570 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
10:43:13.571 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
10:43:13.571 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
10:43:13.579 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
10:43:13.580 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
10:43:13.581 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
10:43:13.584 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
10:43:13.591 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
10:43:13.602 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=1045007f,type=ConfigurationPropertiesRebinder]
10:43:13.607 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
10:43:13.608 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
10:43:13.625 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
10:43:13.635 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
10:43:13.638 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
10:43:13.639 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
10:43:13.639 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
10:43:13.640 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
10:43:13.640 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
10:43:13.681 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
10:43:13.682 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
10:43:13.687 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
10:43:13.687 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
10:43:13.689 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
10:43:13.690 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599792193690 with initial instances count: 6
10:43:13.696 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
10:43:13.697 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599792193697, current=UP, previous=STARTING]
10:43:13.698 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
10:43:13.701 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
10:43:13.701 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
10:43:13.712 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
10:43:13.723 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
10:43:13.746 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
10:43:13.835 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
10:43:13.837 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
10:43:13.838 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
10:43:13.844 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
10:43:13.845 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
10:43:13.847 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
10:43:13.848 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
10:43:13.849 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
10:43:13.859 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
10:43:13.865 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
10:43:13.866 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
10:43:13.867 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
10:43:13.869 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
10:43:13.870 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
10:43:13.871 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
10:43:13.872 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
10:43:13.875 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
10:43:13.876 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
10:43:13.877 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
10:43:13.902 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
10:43:13.902 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
10:43:13.917 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
10:43:13.925 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
10:43:13.933 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
10:43:13.955 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
10:43:13.956 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
10:43:13.959 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.12 seconds (JVM running for 12.259)
10:43:14.226 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
10:43:14.226 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
10:43:14.241 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
10:43:14.250 zt-spark [RMI TCP Connection(4)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 24 ms
10:43:14.387 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
10:43:14.469 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
10:43:14.471 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
10:44:25.474 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
10:44:25.532 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
10:44:25.554 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 3
10:44:25.562 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:44:25.563 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:44:25.571 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:44:25.578 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:44:25.587 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:44:27.450 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:44:27.456 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:44:27.462 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:44:33.532 zt-spark [http-nio-9201-exec-4] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 10:44:33","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"shuda","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"112\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"20:40\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":11,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"08:40\",\"time\":[\"08:40\",\"20:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":12,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"179","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"B000001","tag":"spark_OPERATE"}es_end!
10:44:33.535 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
10:44:33.539 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 10:44:33.532(Timestamp), 179(Integer), 112(String), 12(Integer)
10:44:33.591 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
10:44:33.598 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
10:44:33.601 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 08:40(String), 20:40(String), 11(Integer)
10:44:33.627 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
10:44:33.628 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - ==>  Preparing: delete from point_duty_job where people_id = ? 
10:44:33.630 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - ==> Parameters: 3(Integer)
10:44:33.632 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteDataByPeopleId - <==    Updates: 0
10:44:33.640 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ? ) 
10:44:33.642 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 179(String), 王舒达(String), 2020-09-11 10:44:33.638(Timestamp), 12(String), 3(Integer), 设备1(String), ASDF(String)
10:44:33.652 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
10:44:33.716 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
10:44:33.716 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:44:33.718 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
10:44:33.721 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
10:44:33.726 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
10:44:35.826 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:44:35.829 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:44:35.833 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:44:38.563 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:44:38.566 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:44:38.570 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:44:42.247 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:44:42.249 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 12(Integer)
10:44:42.252 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:45:03.246 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
10:45:03.252 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 13(Integer)
10:45:03.255 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
10:48:13.706 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:53:13.731 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
10:58:13.755 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:03:13.779 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:06:27.785 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@18334665: startup date [Fri Sep 11 11:06:27 CST 2020]; root of context hierarchy
11:06:28.003 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:06:28.027 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$dd551ceb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:28.310 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:06:28.357 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:06:28.639 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:06:28.639 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:06:28.738 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:06:28.738 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:06:28.979 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:06:29.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:06:29.070 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:06:29.207 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:06:29.209 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:06:29.212 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599793589211 with initial instances count: 6
11:06:29.477 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:06:29.706 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:06:29.706 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:06:29.753 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:06:29.767 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@236ed6a2: startup date [Fri Sep 11 11:06:29 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@18334665
11:06:31.201 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:06:31.681 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:06:32.229 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:06:32.266 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:06:32.387 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c13b19ee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.528 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$59e8e228] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.536 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.541 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@10916dad' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.545 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$7ebd84da] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.554 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:32.576 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$dd551ceb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:06:33.049 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:06:33.059 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:06:33.067 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:06:33.067 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:06:33.070 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:06:33.325 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:06:33.329 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:06:33.329 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3562 ms
11:06:33.533 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:06:33.533 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:06:33.540 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@773fa290
11:06:33.729 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:06:33.903 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:06:34.991 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:06:34.991 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:06:34.992 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:06:34.993 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:06:34.994 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:06:34.994 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:06:36.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:06:36.788 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:06:36.788 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.788 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:06:36.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:06:36.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:06:36.790 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:06:36.790 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:06:36.791 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:06:36.791 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.791 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:06:36.791 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:06:36.791 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:06:36.793 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:06:36.793 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:06:36.793 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:06:36.793 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:06:36.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:06:36.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:06:36.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.795 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:06:36.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:06:36.799 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:06:36.800 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:06:36.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:06:36.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:06:36.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:06:36.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:06:36.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:06:36.803 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:06:36.805 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:06:36.806 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:06:36.806 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:06:36.808 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:06:36.809 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:06:36.920 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:06:36.932 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.933 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.934 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.935 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.935 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.935 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.935 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.936 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:06:36.937 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:06:37.223 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:06:37.279 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:06:37.280 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:06:37.395 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:06:37.485 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@236ed6a2: startup date [Fri Sep 11 11:06:29 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@18334665
11:06:37.542 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:06:37.542 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:06:38.245 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:06:38.252 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:06:38.253 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@4f7747df
11:06:38.320 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 8db0e776-0556-4bff-8b3b-e14a22794edf

11:06:38.452 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@569892c0, org.springframework.security.web.context.SecurityContextPersistenceFilter@6b4d5810, org.springframework.security.web.header.HeaderWriterFilter@501ce5dd, org.springframework.security.web.authentication.logout.LogoutFilter@5e4b1a37, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@3f4a729a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@49815220, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3af4ddf9, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@11e09175, org.springframework.security.web.session.SessionManagementFilter@3c65c543, org.springframework.security.web.access.ExceptionTranslationFilter@f10b010, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@58ff531a]
11:06:38.561 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:06:38.726 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:06:38.730 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:06:38.852 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:06:38.853 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:06:38.853 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:06:38.861 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:06:38.862 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:06:38.863 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:06:38.866 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:06:38.873 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:06:38.882 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=236ed6a2,type=ConfigurationPropertiesRebinder]
11:06:38.887 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:06:38.888 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:06:38.905 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:06:38.916 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:06:38.919 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:06:38.920 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:06:38.920 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:06:38.920 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:06:38.920 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:06:38.964 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:06:38.965 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:06:38.969 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:06:38.970 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:06:38.971 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:06:38.972 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599793598972 with initial instances count: 6
11:06:38.979 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:06:38.980 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599793598980, current=UP, previous=STARTING]
11:06:38.981 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:06:38.983 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:06:38.983 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:06:38.995 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:06:39.005 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:06:39.029 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:06:39.121 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:06:39.122 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:06:39.123 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:06:39.129 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:06:39.130 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:06:39.133 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:06:39.134 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:06:39.135 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:06:39.143 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:06:39.151 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:06:39.152 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:06:39.153 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:06:39.154 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:06:39.155 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:06:39.156 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:06:39.157 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:06:39.161 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:06:39.162 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:06:39.163 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:06:39.188 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:06:39.188 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:06:39.203 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:06:39.211 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:06:39.219 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:06:39.242 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:06:39.243 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:06:39.245 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.243 seconds (JVM running for 13.083)
11:06:39.491 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:06:39.657 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:06:39.726 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:06:39.726 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:06:39.731 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:06:39.732 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:06:39.748 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 22 ms
11:07:05.879 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:07:05.905 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
11:07:05.910 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
11:07:05.911 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
11:07:05.913 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
11:07:05.917 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
11:07:05.919 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:07:05.919 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 3
11:07:39.525 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
11:07:39.526 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
11:07:39.529 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
11:07:39.532 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
11:07:39.536 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 8
11:07:55.072 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
11:07:55.072 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
11:07:55.074 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
11:07:55.077 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
11:07:55.083 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
11:07:56.728 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
11:07:56.728 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:07:56.729 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
11:07:56.731 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:07:56.735 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
11:07:57.678 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN point_duty_job dutyjob ON dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
11:07:57.679 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
11:07:57.680 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.com_id, d.start_time, d.end_time, d.task_flag, d.duty_status, d.task_description, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join point_duty_job dutyjob on dutyjob.people_id = dupeo.people_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
11:07:57.684 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
11:07:57.685 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:07:57.686 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:07:57.689 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
11:07:57.694 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - <==      Total: 3
11:08:12.632 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
11:08:12.633 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
11:08:12.635 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
11:08:12.637 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
11:08:12.646 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
11:08:13.951 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:08:13.956 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:08:13.966 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:08:13.978 zt-spark [http-nio-9201-exec-9] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$c5c05862.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:08:22.667 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:08:22.667 zt-spark [http-nio-9201-exec-2] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$c5c05862.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:08:22.671 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:08:22.678 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:08:58.178 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:08:58","methods":"POST","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskFlag\":\"true\",\"taskDescription\":\"123\",\"organId\":28,\"taskBool\":true,\"startTime\":1599753600000,\"dutyStatus\":\"\",\"time\":[\"2020-09-11\",\"2020-09-30\"],\"endTime\":1599753600000,\"comId\":33,\"people\":[{\"dutyEndTime\":\"09:40\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"peopleId\":3,\"dutyStartTime\":\"08:40\",\"time\":[\"08:40\",\"09:40\"]}]}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/save","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:08:58.181 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - ==>  Preparing: insert into zt_company_duty ( com_id, organ_id, start_time, end_time, duty_type, task_flag, duty_status, create_time, create_by, del_flag, task_description ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 
11:08:58.184 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:08:58.179(Timestamp), 1(Integer), 1(String), 123(String)
11:08:58.232 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - <==    Updates: 1
11:08:58.239 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==>  Preparing: insert into zt_dutyid_peopleid ( duty_id, people_id, duty_start_time, duty_end_time ) values ( ?, ?, ?, ? ) 
11:08:58.242 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==> Parameters: 15(Integer), 3(Integer), 08:40(String), 09:40(String)
11:08:58.282 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - <==    Updates: 1
11:08:58.289 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, del_flag, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:08:58.292 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:08:58.287(Timestamp), 15(String), 3(Integer), 1(String), 设备1(String), ASDF,GHJK(String)
11:08:58.315 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:08:58.317 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:08:58.320 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 15(Integer), 14(Integer), null
11:08:58.340 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:08:58.396 zt-spark [http-nio-9201-exec-4] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$c5c05862.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:09:01.631 zt-spark [http-nio-9201-exec-5] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$c5c05862.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:09:01.633 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:09:01.638 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:09:01.645 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:10:05.030 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@333442ff: startup date [Fri Sep 11 11:10:05 CST 2020]; root of context hierarchy
11:10:05.340 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:10:05.393 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$a8849ac2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:05.686 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:10:05.722 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:10:05.999 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:10:06.000 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:10:06.095 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:10:06.095 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:10:06.264 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:10:06.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:10:06.525 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:10:06.528 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:10:06.531 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599793806531 with initial instances count: 6
11:10:06.882 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:10:07.236 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:10:07.236 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:10:07.277 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:10:07.297 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2d96d41d: startup date [Fri Sep 11 11:10:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@333442ff
11:10:08.283 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:10:08.570 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:10:08.985 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:10:09.021 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:10:09.143 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$8c6a97c5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.301 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$25185fff] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.310 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.315 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@304e80a7' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.325 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$49ed02b1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.334 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.357 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$a8849ac2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:10:09.835 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:10:09.848 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:10:09.860 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:10:09.860 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:10:09.865 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:10:10.121 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:10:10.124 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:10:10.124 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2827 ms
11:10:10.352 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:10:10.352 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:10:10.359 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@5288dd82
11:10:10.552 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:10:10.724 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:10:11.788 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:10:11.788 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:10:11.788 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:10:11.788 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:10:11.788 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:10:11.789 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:10:11.789 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:10:11.789 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:10:11.789 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:10:11.790 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:10:11.791 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:10:11.791 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:10:13.501 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:10:13.502 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:10:13.502 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.502 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:10:13.502 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:10:13.502 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.503 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:10:13.504 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:10:13.504 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:10:13.504 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:10:13.504 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:10:13.504 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.505 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:10:13.505 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:10:13.506 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:10:13.506 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:10:13.507 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:10:13.507 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:10:13.507 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.507 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:10:13.507 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:10:13.508 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:10:13.509 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:10:13.510 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:10:13.512 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:10:13.513 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:10:13.513 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:10:13.513 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:10:13.513 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:10:13.513 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:10:13.514 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:10:13.515 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:10:13.516 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:10:13.518 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:10:13.519 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:10:13.519 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:10:13.522 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:10:13.522 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:10:13.623 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:10:13.635 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.636 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.637 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.638 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.639 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.639 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.639 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.639 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.639 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:10:13.640 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:10:13.914 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:10:13.973 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:10:13.973 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:10:14.087 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:10:14.175 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2d96d41d: startup date [Fri Sep 11 11:10:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@333442ff
11:10:14.230 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:10:14.230 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:10:14.957 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:10:14.965 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:10:14.965 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:10:14.965 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:10:14.965 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:10:14.966 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:10:14.966 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:10:14.966 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@7594741e
11:10:15.029 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: fbd4342c-0073-4fd3-b202-23c161dbd1e9

11:10:15.155 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@44c805e5, org.springframework.security.web.context.SecurityContextPersistenceFilter@2e5b4cd2, org.springframework.security.web.header.HeaderWriterFilter@50a0789, org.springframework.security.web.authentication.logout.LogoutFilter@39d8b079, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2cf75621, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7abf3021, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3c6e7f08, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@62a209a5, org.springframework.security.web.session.SessionManagementFilter@1e0cab99, org.springframework.security.web.access.ExceptionTranslationFilter@47424b2c, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@449efc89]
11:10:15.265 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:10:15.431 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:10:15.436 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:10:15.556 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:10:15.558 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:10:15.558 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:10:15.565 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:10:15.566 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:10:15.567 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:10:15.570 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:10:15.577 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:10:15.586 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=2d96d41d,type=ConfigurationPropertiesRebinder]
11:10:15.591 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:10:15.593 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:10:15.609 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:10:15.620 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:10:15.623 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:10:15.624 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:10:15.624 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:10:15.624 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:10:15.624 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:10:15.666 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:10:15.667 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:10:15.671 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:10:15.671 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:10:15.672 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:10:15.674 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599793815673 with initial instances count: 6
11:10:15.680 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:10:15.680 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599793815680, current=UP, previous=STARTING]
11:10:15.681 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:10:15.684 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:10:15.684 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:10:15.695 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:10:15.704 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:10:15.727 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:10:15.818 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:10:15.820 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:10:15.821 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:10:15.827 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:10:15.828 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:10:15.831 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:10:15.832 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:10:15.833 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:10:15.842 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:10:15.849 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:10:15.850 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:10:15.851 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:10:15.852 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:10:15.853 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:10:15.854 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:10:15.855 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:10:15.859 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:10:15.861 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:10:15.862 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:10:15.884 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:10:15.884 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:10:15.899 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:10:15.905 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:10:15.913 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:10:15.934 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:10:15.935 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:10:15.937 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.814 seconds (JVM running for 12.604)
11:10:16.453 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:10:16.453 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:10:16.466 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:10:16.473 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 20 ms
11:10:16.616 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:10:16.708 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:10:16.711 zt-spark [RMI TCP Connection(8)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:10:21.942 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:10:21.950 zt-spark [http-nio-9201-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$5a603c09.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:10:21.966 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:10:21.988 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:14:01.101 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@762f4f12: startup date [Fri Sep 11 11:14:01 CST 2020]; root of context hierarchy
11:14:01.336 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:14:01.360 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6d36bda8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:01.617 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:14:01.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:14:01.908 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:14:01.909 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:14:01.993 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:14:01.993 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:14:02.176 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:14:02.268 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:14:02.395 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:14:02.397 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:14:02.401 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794042400 with initial instances count: 6
11:14:02.649 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:14:02.909 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:14:02.910 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:14:02.940 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:14:02.952 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1fbee8b0: startup date [Fri Sep 11 11:14:02 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@762f4f12
11:14:03.857 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:14:04.157 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:14:04.539 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:14:04.574 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:14:04.689 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$511cbaab] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.831 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$e9ca82e5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.840 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.845 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@7227a69e' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.848 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$e9f2597] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.858 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:04.880 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6d36bda8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:14:05.448 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:14:05.466 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:14:05.481 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:14:05.481 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:14:05.486 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:14:05.769 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:14:05.774 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:14:05.774 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2822 ms
11:14:06.046 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:14:06.047 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:14:06.055 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@73fa038c
11:14:06.284 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:14:06.501 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:14:07.936 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:14:07.937 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:14:07.937 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:14:07.937 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:14:07.937 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:14:07.937 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:14:07.938 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:14:07.938 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:14:07.938 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:14:07.939 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:14:07.939 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:14:07.940 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:14:09.691 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:14:09.691 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:14:09.691 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.692 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:14:09.692 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:14:09.692 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.692 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:14:09.693 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:14:09.694 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:14:09.694 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:14:09.694 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:14:09.694 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.694 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:14:09.695 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:14:09.696 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:14:09.696 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:14:09.696 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:14:09.696 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:14:09.696 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.697 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:14:09.697 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:14:09.697 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.698 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:14:09.699 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:14:09.702 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:14:09.702 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:14:09.703 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:14:09.704 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:14:09.704 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:14:09.704 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:14:09.704 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:14:09.706 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:14:09.708 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:14:09.708 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:14:09.708 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:14:09.711 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:14:09.711 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:14:09.811 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:14:09.823 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.824 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.824 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.824 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.825 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.826 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.827 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:14:09.828 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:14:10.104 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:14:10.163 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:14:10.163 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:14:10.280 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:14:10.371 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1fbee8b0: startup date [Fri Sep 11 11:14:02 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@762f4f12
11:14:10.425 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:14:10.425 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:14:11.116 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:14:11.123 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:14:11.124 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@144e6519
11:14:11.192 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 520f1a03-0132-4f3c-b4ef-6039e7589017

11:14:11.323 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1b874b12, org.springframework.security.web.context.SecurityContextPersistenceFilter@3e63f06e, org.springframework.security.web.header.HeaderWriterFilter@2bb7ef04, org.springframework.security.web.authentication.logout.LogoutFilter@320cb933, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@5436438c, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@21937b2f, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4419bc9e, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@29db1bec, org.springframework.security.web.session.SessionManagementFilter@4c119db5, org.springframework.security.web.access.ExceptionTranslationFilter@328331af, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@8ce2ed5]
11:14:11.442 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:14:11.619 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:14:11.624 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:14:11.768 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:14:11.770 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:14:11.770 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:14:11.777 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:14:11.778 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:14:11.778 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:14:11.782 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:14:11.789 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:14:11.798 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=1fbee8b0,type=ConfigurationPropertiesRebinder]
11:14:11.803 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:14:11.804 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:14:11.821 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:14:11.832 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:14:11.835 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:14:11.837 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:14:11.837 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:14:11.837 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:14:11.837 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:14:11.878 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:14:11.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:14:11.884 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:14:11.884 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:14:11.886 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:14:11.887 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794051887 with initial instances count: 6
11:14:11.894 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:14:11.894 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794051894, current=UP, previous=STARTING]
11:14:11.895 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:14:11.898 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:14:11.898 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:14:11.910 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:14:11.921 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:14:11.943 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:14:12.032 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:14:12.033 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:14:12.034 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:14:12.041 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:14:12.042 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:14:12.045 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:14:12.046 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:14:12.047 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:14:12.057 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:14:12.063 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:14:12.064 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:14:12.065 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:14:12.067 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:14:12.068 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:14:12.069 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:14:12.069 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:14:12.074 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:14:12.075 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:14:12.076 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:14:12.099 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:14:12.099 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:14:12.114 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:14:12.120 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:14:12.129 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:14:12.150 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:14:12.151 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:14:12.153 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.79 seconds (JVM running for 12.566)
11:14:12.640 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:14:12.640 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:14:12.654 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:14:12.661 zt-spark [RMI TCP Connection(9)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
11:14:12.816 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:14:12.888 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:14:12.889 zt-spark [RMI TCP Connection(10)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:14:37.941 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:14:37.948 zt-spark [http-nio-9201-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: 
### Error querying database.  Cause: java.lang.NullPointerException: target is null for method size
### Cause: java.lang.NullPointerException: target is null for method size] with root cause
java.lang.NullPointerException: target is null for method size
	at org.apache.ibatis.ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1618)
	at org.apache.ibatis.ognl.ASTMethod.getValueBody(ASTMethod.java:91)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.ASTGreater.getValueBody(ASTGreater.java:50)
	at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)
	at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:470)
	at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:434)
	at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:44)
	at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32)
	at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34)
	at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:33)
	at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:41)
	at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:292)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy177.selectCompanyDutyListByLike(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:101)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$11875bfb.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:14:37.972 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:14:38.007 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:15:56.423 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@6cd5f5c0: startup date [Fri Sep 11 11:15:56 CST 2020]; root of context hierarchy
11:15:56.720 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:15:56.758 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6814f39] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:15:57.017 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:15:57.066 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:15:57.320 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:15:57.320 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:15:57.412 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:15:57.412 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:15:57.656 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:15:57.747 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:15:57.748 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:15:57.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:15:57.900 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:15:57.904 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794157903 with initial instances count: 6
11:15:58.202 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:15:58.396 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:15:58.396 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:15:58.431 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:15:58.448 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@66b0caf6: startup date [Fri Sep 11 11:15:58 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6cd5f5c0
11:15:59.655 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:16:00.022 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:16:00.486 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:16:00.525 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:16:00.664 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ea674c3c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.826 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$83151476] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.836 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.841 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@6ab0ab58' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.853 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$a7e9b728] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.864 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:00.894 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6814f39] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:01.448 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:16:01.460 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:16:01.469 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:16:01.469 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:16:01.473 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:16:01.742 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:16:01.745 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:16:01.745 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3297 ms
11:16:01.979 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:16:01.979 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:16:01.986 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@3233d8b3
11:16:02.207 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:16:02.412 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:16:03.726 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:16:03.727 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:16:03.728 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:16:03.728 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:16:03.729 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:16:03.729 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:16:05.639 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:16:05.640 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:16:05.640 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.640 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:16:05.640 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:16:05.641 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.641 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:05.642 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:16:05.642 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:16:05.642 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:16:05.643 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:16:05.643 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.643 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:05.643 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:05.644 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:16:05.645 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:16:05.645 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:16:05.645 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:16:05.645 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.646 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:05.646 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:05.646 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.647 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:16:05.647 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:16:05.648 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:16:05.648 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:16:05.648 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:05.648 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:05.648 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:05.652 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:16:05.652 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:16:05.652 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:16:05.652 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:16:05.652 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:16:05.653 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:16:05.655 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:16:05.658 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:16:05.658 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:16:05.659 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:16:05.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:16:05.661 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:16:05.792 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:16:05.808 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.809 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.809 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.810 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.811 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.812 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:05.813 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:16:06.256 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:16:06.382 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:16:06.382 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:16:06.550 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:06.668 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@66b0caf6: startup date [Fri Sep 11 11:15:58 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6cd5f5c0
11:16:06.743 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:06.743 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:07.629 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:16:07.638 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:16:07.638 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:16:07.639 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:16:07.639 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:16:07.639 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:16:07.639 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:16:07.639 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@71184afd
11:16:07.722 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: a93846be-aef2-4422-8212-cdc33c12ec11

11:16:07.890 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@10816ff8, org.springframework.security.web.context.SecurityContextPersistenceFilter@51d90b60, org.springframework.security.web.header.HeaderWriterFilter@7d6434c5, org.springframework.security.web.authentication.logout.LogoutFilter@4573345d, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@7058d632, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@358034fb, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4612d3b4, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@2b1f6e4c, org.springframework.security.web.session.SessionManagementFilter@4c8ba3ee, org.springframework.security.web.access.ExceptionTranslationFilter@66d28c8d, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@1114489c]
11:16:08.023 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:16:08.227 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:16:08.232 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:16:08.405 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:16:08.407 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:16:08.407 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:16:08.422 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:16:08.425 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:16:08.426 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:16:08.433 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:16:08.442 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:16:08.456 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=66b0caf6,type=ConfigurationPropertiesRebinder]
11:16:08.462 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:16:08.463 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:16:08.482 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:16:08.495 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:16:08.498 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:16:08.499 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:16:08.500 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:16:08.500 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:16:08.500 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:16:08.577 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:16:08.578 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:16:08.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:16:08.583 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:16:08.586 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:16:08.587 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794168587 with initial instances count: 6
11:16:08.595 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:16:08.596 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794168596, current=UP, previous=STARTING]
11:16:08.597 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:16:08.599 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:16:08.600 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:16:08.615 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:16:08.626 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:16:08.660 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:16:08.809 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:16:08.811 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:16:08.813 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:16:08.819 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:16:08.820 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:16:08.823 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:16:08.824 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:16:08.825 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:16:08.835 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:16:08.848 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:16:08.849 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:16:08.850 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:16:08.853 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:16:08.854 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:16:08.856 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:16:08.857 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:16:08.864 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:16:08.865 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:16:08.866 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:16:08.903 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:16:08.903 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:16:08.923 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:16:08.966 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:16:08.983 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:16:09.083 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:16:09.085 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:16:09.109 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 13.447 seconds (JVM running for 14.442)
11:16:09.337 zt-spark [RMI TCP Connection(12)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:16:09.337 zt-spark [RMI TCP Connection(12)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:16:09.352 zt-spark [RMI TCP Connection(11)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:16:09.361 zt-spark [RMI TCP Connection(12)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 24 ms
11:16:09.505 zt-spark [RMI TCP Connection(11)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:16:09.623 zt-spark [RMI TCP Connection(11)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:16:09.625 zt-spark [RMI TCP Connection(11)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:16:30.522 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@66b0caf6: startup date [Fri Sep 11 11:15:58 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6cd5f5c0
11:16:30.524 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:16:30.524 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794190524, current=DOWN, previous=UP]
11:16:30.525 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:16:30.526 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:16:30.527 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:16:30.527 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:16:30.528 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:16:30.529 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:16:30.529 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:16:30.529 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:16:30.529 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:16:30.530 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:16:30.530 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:16:31.657 zt-spark [Thread-40] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
11:16:31.658 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:16:31.661 zt-spark [Thread-40] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:16:34.663 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
11:16:34.667 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - deregister  status: 200
11:16:34.670 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:16:40.378 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@58b34374: startup date [Fri Sep 11 11:16:40 CST 2020]; root of context hierarchy
11:16:40.727 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:16:40.773 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$4e8f89da] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:41.039 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:16:41.082 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:16:41.319 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:16:41.319 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:16:41.408 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:16:41.408 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:16:41.630 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:16:41.727 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:16:41.883 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:16:41.886 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:16:41.890 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794201889 with initial instances count: 6
11:16:42.196 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:16:42.392 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:16:42.392 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:16:42.427 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:16:42.443 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@e44ed30: startup date [Fri Sep 11 11:16:42 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@58b34374
11:16:44.049 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:16:44.457 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:16:45.470 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:16:45.545 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:16:45.787 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$327586dd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.071 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$cb234f17] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.085 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.091 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@3b41c624' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.099 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$eff7f1c9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.112 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.152 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$4e8f89da] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:16:46.960 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:16:46.971 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:16:46.981 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:16:46.982 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:16:46.986 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:16:47.318 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:16:47.324 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:16:47.324 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 4881 ms
11:16:47.606 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:16:47.606 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:16:47.614 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@200ae433
11:16:47.847 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:16:48.047 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:16:49.377 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:16:49.378 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:16:49.379 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:16:49.379 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:16:49.380 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:16:49.380 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:16:51.310 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:16:51.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:16:51.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:16:51.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:16:51.311 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.312 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:51.313 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:16:51.313 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:16:51.313 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:16:51.313 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:16:51.314 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.314 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:51.314 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.316 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:51.317 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:51.317 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.318 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:16:51.318 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:16:51.318 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:16:51.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:16:51.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:16:51.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:16:51.319 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:16:51.322 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:16:51.323 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:16:51.324 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:16:51.324 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:16:51.324 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:16:51.324 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:16:51.326 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:16:51.328 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:16:51.329 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:16:51.329 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:16:51.331 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:16:51.332 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:16:51.457 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:16:51.471 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.472 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.473 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.474 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.475 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:16:51.476 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:16:51.829 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:16:51.901 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:16:51.901 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:16:52.052 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:52.169 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@e44ed30: startup date [Fri Sep 11 11:16:42 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@58b34374
11:16:52.241 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:52.242 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:16:53.197 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:16:53.206 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:16:53.206 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:16:53.207 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:16:53.207 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:16:53.207 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:16:53.207 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:16:53.207 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@30504cc1
11:16:53.288 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 1d8730ae-3e59-4739-bceb-07e40f4ad1bf

11:16:53.458 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@57ff73cf, org.springframework.security.web.context.SecurityContextPersistenceFilter@35497ae4, org.springframework.security.web.header.HeaderWriterFilter@7100862, org.springframework.security.web.authentication.logout.LogoutFilter@1a8b6e6f, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@3063ee01, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@44e0b099, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@71af5ba3, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@53abf092, org.springframework.security.web.session.SessionManagementFilter@131d35a, org.springframework.security.web.access.ExceptionTranslationFilter@1ae0b3e8, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@8c7f0db]
11:16:53.596 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:16:53.795 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:16:53.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:16:53.944 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:16:53.945 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:16:53.946 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:16:53.954 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:16:53.956 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:16:53.956 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:16:53.960 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:16:53.968 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:16:53.980 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=e44ed30,type=ConfigurationPropertiesRebinder]
11:16:53.985 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:16:53.987 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:16:54.005 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:16:54.019 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:16:54.023 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:16:54.024 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:16:54.024 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:16:54.024 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:16:54.024 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:16:54.104 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:16:54.105 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:16:54.110 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:16:54.110 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:16:54.112 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:16:54.113 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794214113 with initial instances count: 6
11:16:54.121 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:16:54.122 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794214122, current=UP, previous=STARTING]
11:16:54.123 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:16:54.125 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:16:54.125 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:16:54.140 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:16:54.150 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:16:54.177 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:16:54.284 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:16:54.285 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:16:54.287 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:16:54.293 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:16:54.295 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:16:54.297 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:16:54.298 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:16:54.299 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:16:54.308 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:16:54.315 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:16:54.316 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:16:54.317 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:16:54.319 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:16:54.320 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:16:54.321 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:16:54.322 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:16:54.326 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:16:54.327 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:16:54.328 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:16:54.354 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:16:54.355 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:16:54.369 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:16:54.377 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:16:54.386 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:16:54.409 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:16:54.410 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:16:54.413 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 14.812 seconds (JVM running for 15.8)
11:16:54.693 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:16:54.693 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:16:54.707 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:16:54.717 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 24 ms
11:16:54.866 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:16:54.939 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:16:54.941 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:17:08.157 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:17:08.180 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:17:08.193 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:17:08.194 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:17:08.196 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 
11:17:08.199 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:17:08.200 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:17:08.201 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:17:36.496 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:17:36","methods":"POST","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskFlag\":\"true\",\"taskDescription\":\"123\",\"organId\":28,\"taskBool\":true,\"startTime\":1599667200000,\"dutyStatus\":\"\",\"time\":[\"2020-09-10\",\"2020-09-19\"],\"endTime\":1599667200000,\"comId\":33,\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"peopleId\":3,\"dutyStartTime\":\"\",\"time\":[\"2016-10-10T00:40:00.000Z\",\"2016-10-10T01:40:00.000Z\"]}]}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/save","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:17:36.503 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - ==>  Preparing: insert into zt_company_duty ( com_id, organ_id, start_time, end_time, duty_type, task_flag, duty_status, create_time, create_by, del_flag, task_description ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 
11:17:36.509 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:17:36.496(Timestamp), 1(Integer), 1(String), 123(String)
11:17:36.554 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.insertCompanyDuty - <==    Updates: 1
11:17:36.566 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==>  Preparing: insert into zt_dutyid_peopleid ( duty_id, people_id, duty_start_time, duty_end_time ) values ( ?, ?, ?, ? ) 
11:17:36.569 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==> Parameters: 16(Integer), 3(Integer), (String), (String)
11:17:36.574 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - <==    Updates: 1
11:17:36.613 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, del_flag, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:17:36.615 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:17:36.582(Timestamp), 16(String), 3(Integer), 1(String), 设备1(String), ASDF,GHJK(String)
11:17:36.624 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:17:36.635 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:17:36.638 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 16(Integer), 15(Integer), null
11:17:36.658 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:17:36.731 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:17:36.731 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:17:36.735 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:17:36.737 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:17:36.742 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:17:40.423 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:17:40.427 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:17:40.432 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:18:46.811 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:18:46.816 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:18:46.819 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:19:24.307 zt-spark [Thread-42] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@e44ed30: startup date [Fri Sep 11 11:16:42 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@58b34374
11:19:24.308 zt-spark [Thread-42] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:19:24.308 zt-spark [Thread-42] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794364308, current=DOWN, previous=UP]
11:19:24.308 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:19:24.311 zt-spark [Thread-42] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:19:24.311 zt-spark [Thread-42] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:19:24.311 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:19:24.312 zt-spark [Thread-42] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:19:24.314 zt-spark [Thread-42] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:19:24.314 zt-spark [Thread-42] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:19:24.314 zt-spark [Thread-42] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:19:24.314 zt-spark [Thread-42] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:19:24.315 zt-spark [Thread-42] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:19:24.315 zt-spark [Thread-42] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:19:25.444 zt-spark [Thread-42] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
11:19:25.445 zt-spark [Thread-42] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:19:25.449 zt-spark [Thread-42] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:19:28.451 zt-spark [Thread-42] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
11:19:28.454 zt-spark [Thread-42] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - deregister  status: 200
11:19:28.458 zt-spark [Thread-42] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:19:33.888 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@78ab4dac: startup date [Fri Sep 11 11:19:33 CST 2020]; root of context hierarchy
11:19:34.152 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:19:34.190 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$76bd14dc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:34.443 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:19:34.486 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:19:34.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:19:34.717 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:19:34.807 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:19:34.807 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:19:35.023 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:19:35.112 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:19:35.264 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:19:35.267 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:19:35.271 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794375269 with initial instances count: 5
11:19:35.558 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:19:35.748 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:19:35.748 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:19:35.782 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:19:35.798 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@44131b71: startup date [Fri Sep 11 11:19:35 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@78ab4dac
11:19:36.994 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:19:37.326 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:19:37.812 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:19:37.855 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:19:37.999 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$5aa311df] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.182 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$f350da19] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.192 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.197 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@6abeeddf' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.207 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$18257ccb] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.218 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.246 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$76bd14dc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:19:38.781 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:19:38.794 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:19:38.804 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:19:38.804 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:19:38.808 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:19:39.058 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:19:39.061 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:19:39.061 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3263 ms
11:19:39.324 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:19:39.324 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:19:39.332 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@6166d34
11:19:39.551 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:19:39.739 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:19:40.960 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:19:40.961 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:19:40.962 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:19:40.963 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:19:40.963 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:19:42.899 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:19:42.900 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:19:42.901 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.901 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:19:42.901 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:19:42.901 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:19:42.901 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:19:42.903 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:19:42.904 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:19:42.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:19:42.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:19:42.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:19:42.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:19:42.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:19:42.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:19:42.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:19:42.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:19:42.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:19:42.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:19:42.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:19:42.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:19:42.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:19:42.913 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:19:42.913 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:19:42.913 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:19:42.913 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:19:42.913 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:19:42.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:19:42.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:19:42.918 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:19:42.919 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:19:42.919 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:19:42.922 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:19:42.922 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:19:43.046 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:19:43.061 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:19:43.066 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:19:43.409 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:19:43.482 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:19:43.483 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:19:43.632 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:19:43.741 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@44131b71: startup date [Fri Sep 11 11:19:35 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@78ab4dac
11:19:43.811 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:19:43.811 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:19:44.712 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:19:44.721 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:19:44.721 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:19:44.722 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:19:44.722 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:19:44.722 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:19:44.722 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:19:44.722 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@49629bfc
11:19:44.805 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: a16a3683-c658-41e5-b327-a64b937b198a

11:19:45.004 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@59b9d6cc, org.springframework.security.web.context.SecurityContextPersistenceFilter@27a4316d, org.springframework.security.web.header.HeaderWriterFilter@2e95a101, org.springframework.security.web.authentication.logout.LogoutFilter@61b09408, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@480b0300, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7e9d9b28, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@6dbdc42a, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@12b8af28, org.springframework.security.web.session.SessionManagementFilter@1f17063f, org.springframework.security.web.access.ExceptionTranslationFilter@6024db17, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@6621dfc8]
11:19:45.134 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:19:45.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:19:45.344 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:19:45.495 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:19:45.496 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:19:45.496 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:19:45.506 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:19:45.507 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:19:45.508 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:19:45.511 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:19:45.520 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:19:45.532 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=44131b71,type=ConfigurationPropertiesRebinder]
11:19:45.538 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:19:45.540 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:19:45.559 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:19:45.573 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:19:45.576 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:19:45.578 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:19:45.578 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:19:45.578 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:19:45.578 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:19:45.658 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:19:45.658 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:19:45.662 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:19:45.663 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:19:45.665 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:19:45.666 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794385666 with initial instances count: 5
11:19:45.674 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:19:45.675 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794385674, current=UP, previous=STARTING]
11:19:45.676 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:19:45.678 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:19:45.679 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:19:45.695 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:19:45.704 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:19:45.736 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:19:45.846 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:19:45.847 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:19:45.848 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:19:45.855 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:19:45.856 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:19:45.858 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:19:45.859 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:19:45.860 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:19:45.870 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:19:45.877 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:19:45.878 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:19:45.879 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:19:45.880 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:19:45.881 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:19:45.882 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:19:45.883 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:19:45.887 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:19:45.888 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:19:45.889 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:19:45.917 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:19:45.917 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:19:45.932 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:19:45.941 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:19:45.951 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:19:45.977 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:19:45.978 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:19:45.982 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.854 seconds (JVM running for 13.786)
11:19:46.495 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:19:46.636 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:19:46.636 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:19:46.657 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:19:46.659 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
11:19:46.740 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:19:46.742 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:20:00.037 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:20:00.058 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:20:00.073 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:20:00.073 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:20:00.077 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:20:00.079 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:20:00.080 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:20:00.084 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:21:13.998 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:21:14.001 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:21:14.011 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:21:14.011 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:21:14.014 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:21:14.022 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:21:14.022 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:21:14.030 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:21:15.655 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:21:15.663 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:21:15.667 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:21:28.702 zt-spark [http-nio-9201-exec-9] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:21:28","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"123\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":22,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"},{\"number\":[\"GHJK\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"}],\"dutyPeopleId\":15,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"\",\"time\":[\"\",\"\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":16,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:21:28.708 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:21:28.712 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:21:28.702(Timestamp), 1(Integer), 123(String), 16(Integer)
11:21:28.771 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:21:28.773 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:21:28.775 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 16(Integer)
11:21:28.787 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 1
11:21:28.788 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:21:28.799 zt-spark [http-nio-9201-exec-9] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.binding.BindingException: Parameter 'companyDutyId' not found. Available parameters are [dutyId, param1]] with root cause
org.apache.ibatis.binding.BindingException: Parameter 'companyDutyId' not found. Available parameters are [dutyId, param1]
	at org.apache.ibatis.binding.MapperMethod$ParamMap.get(MapperMethod.java:204)
	at org.apache.ibatis.reflection.wrapper.MapWrapper.get(MapWrapper.java:45)
	at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:122)
	at com.baomidou.mybatisplus.MybatisDefaultParameterHandler.setParameters(MybatisDefaultParameterHandler.java:262)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.parameterize(PreparedStatementHandler.java:93)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.parameterize(RoutingStatementHandler.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy233.parameterize(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy233.parameterize(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:86)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:49)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.delete(DefaultSqlSession.java:213)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.delete(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.delete(SqlSessionTemplate.java:310)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:68)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy180.deletePointDutyJobByDutyId(Unknown Source)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.updateCompanyDuty(CompanyDutyServiceImpl.java:238)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$4128151e.updateCompanyDuty(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.update(CompanyDutyController.java:109)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPut(FrameworkServlet.java:888)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:664)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:22:02.888 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 
11:22:02.888 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
11:22:02.890 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.user_name, p.company, p.parking_lot, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 ORDER BY p.is_duty desc LIMIT 0,30 
11:22:02.892 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - ==> Parameters: 
11:22:02.897 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByLike - <==      Total: 20
11:22:04.647 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
11:22:04.647 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
11:22:04.649 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
11:22:04.651 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
11:22:04.657 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
11:22:06.092 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
11:22:06.092 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:22:06.094 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
11:22:06.097 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:22:06.100 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
11:22:09.521 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
11:22:09.521 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:22:09.523 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
11:22:09.524 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
11:22:09.528 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
11:22:10.046 zt-spark [http-nio-9201-exec-6] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at com.ztman.ztspark.controller.CompanyFileController.downloadExcel(CompanyFileController.java:153)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
11:24:13.161 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@44131b71: startup date [Fri Sep 11 11:19:35 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@78ab4dac
11:24:13.163 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:24:13.163 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794653163, current=DOWN, previous=UP]
11:24:13.163 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:24:13.165 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:24:13.166 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:24:13.166 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:24:13.167 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:24:13.168 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:24:13.168 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:24:13.168 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:24:13.169 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:24:13.170 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:24:13.171 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:24:14.299 zt-spark [Thread-40] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
11:24:14.300 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:24:14.304 zt-spark [Thread-40] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:24:17.306 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
11:24:17.306 zt-spark [DiscoveryClient-0] WARN  c.n.discovery.TimedSupervisorTask - task supervisor shutting down, can't accept the task
11:24:17.311 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - deregister  status: 200
11:24:17.315 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:24:22.837 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@404f0db4: startup date [Fri Sep 11 11:24:22 CST 2020]; root of context hierarchy
11:24:23.095 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:24:23.128 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$5363bbe0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:23.390 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:24:23.435 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:24:23.674 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:24:23.674 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:24:23.770 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:24:23.771 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:24:24.008 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:24:24.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:24:24.242 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:24:24.245 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:24:24.249 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794664247 with initial instances count: 5
11:24:24.536 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:24:24.734 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:24:24.735 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:24:24.770 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:24:24.788 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@7db561ae: startup date [Fri Sep 11 11:24:24 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@404f0db4
11:24:26.025 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:24:26.386 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:24:26.850 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:24:26.890 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:24:27.028 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$3749b8e3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.192 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$cff7811d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.203 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.208 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@4fdecd23' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.218 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$f4cc23cf] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.229 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.258 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$5363bbe0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:24:27.814 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:24:27.825 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:24:27.835 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:24:27.835 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:24:27.838 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:24:28.084 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:24:28.088 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:24:28.089 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3301 ms
11:24:28.327 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:24:28.327 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:24:28.335 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@70546223
11:24:28.564 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:24:28.756 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:24:30.033 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:24:30.033 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:24:30.033 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:24:30.033 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:24:30.033 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:24:30.034 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:24:30.034 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:24:30.034 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:24:30.034 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:24:30.035 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:24:30.036 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:24:30.036 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:24:32.004 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:24:32.005 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:24:32.005 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.005 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:24:32.006 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:24:32.006 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:24:32.006 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.007 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:24:32.007 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:24:32.008 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:24:32.008 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:24:32.008 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:24:32.008 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:24:32.008 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.010 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:24:32.010 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:24:32.010 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:24:32.010 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:24:32.011 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:24:32.011 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:24:32.011 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.011 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.012 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:24:32.013 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:24:32.017 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:24:32.017 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:24:32.017 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:24:32.017 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:24:32.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:24:32.019 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:24:32.020 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:24:32.023 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:24:32.023 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:24:32.024 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:24:32.026 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:24:32.026 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:24:32.159 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:24:32.175 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.177 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.178 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.179 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.180 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.180 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.180 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.180 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.180 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:24:32.181 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:24:32.570 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:24:32.643 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:24:32.643 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:24:32.818 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:24:32.927 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@7db561ae: startup date [Fri Sep 11 11:24:24 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@404f0db4
11:24:33.000 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:24:33.000 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:24:33.888 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:24:33.896 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:24:33.897 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:24:33.897 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:24:33.898 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:24:33.898 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:24:33.898 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:24:33.898 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@6930f7a7
11:24:33.979 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 45a7bc18-130e-46dc-9094-3056ab5f7886

11:24:34.147 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@7289d564, org.springframework.security.web.context.SecurityContextPersistenceFilter@4c278e39, org.springframework.security.web.header.HeaderWriterFilter@2a1e9f1a, org.springframework.security.web.authentication.logout.LogoutFilter@a54411e, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@138e102b, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@159671b8, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3b3e2c9a, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@7c91cb2b, org.springframework.security.web.session.SessionManagementFilter@3b4084f4, org.springframework.security.web.access.ExceptionTranslationFilter@4f001a50, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@71360501]
11:24:34.282 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:24:34.483 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:24:34.489 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:24:34.636 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:24:34.638 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:24:34.638 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:24:34.647 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:24:34.648 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:24:34.650 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:24:34.653 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:24:34.661 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:24:34.674 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7db561ae,type=ConfigurationPropertiesRebinder]
11:24:34.681 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:24:34.682 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:24:34.702 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:24:34.715 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:24:34.718 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:24:34.719 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:24:34.719 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:24:34.719 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:24:34.719 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:24:34.796 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:24:34.796 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:24:34.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:24:34.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:24:34.802 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:24:34.803 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794674803 with initial instances count: 4
11:24:34.811 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:24:34.811 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794674811, current=UP, previous=STARTING]
11:24:34.813 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:24:34.816 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:24:34.816 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:24:34.831 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:24:34.840 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:24:34.869 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:24:34.977 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:24:34.978 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:24:34.979 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:24:34.985 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:24:34.987 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:24:34.989 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:24:34.990 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:24:34.991 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:24:35.000 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:24:35.009 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:24:35.010 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:24:35.011 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:24:35.012 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:24:35.013 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:24:35.014 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:24:35.015 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:24:35.020 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:24:35.021 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:24:35.021 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:24:35.048 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:24:35.048 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:24:35.064 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:24:35.072 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:24:35.081 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:24:35.135 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:24:35.137 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:24:35.139 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 13.042 seconds (JVM running for 13.999)
11:24:35.628 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:24:35.629 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:24:35.652 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
11:24:35.806 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:24:36.023 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:24:36.108 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:24:36.109 zt-spark [RMI TCP Connection(7)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:24:52.915 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:24:52.936 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:24:52.950 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:24:52.951 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:24:52.956 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:24:52.958 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:24:52.958 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:24:52.963 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:24:54.235 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:24:54.240 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:24:54.244 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:24:58.185 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:24:58.188 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:24:58.192 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:25:56.352 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@7db561ae: startup date [Fri Sep 11 11:24:24 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@404f0db4
11:25:56.354 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:25:56.354 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794756354, current=DOWN, previous=UP]
11:25:56.354 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:25:56.357 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:25:56.357 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:25:56.357 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:25:56.358 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:25:56.359 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:25:56.359 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:25:56.359 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:25:56.360 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:25:56.360 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:25:56.361 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:25:57.488 zt-spark [Thread-40] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
11:25:57.489 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:25:57.493 zt-spark [Thread-40] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:26:00.495 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
11:26:00.499 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - deregister  status: 200
11:26:00.502 zt-spark [Thread-40] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:26:05.917 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@e9591f5: startup date [Fri Sep 11 11:26:05 CST 2020]; root of context hierarchy
11:26:06.183 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:26:06.220 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$28cd53e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:06.480 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:26:06.524 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:26:06.761 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:26:06.761 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:26:06.850 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:26:06.850 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:26:07.072 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:26:07.169 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:26:07.323 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:26:07.326 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:26:07.330 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794767329 with initial instances count: 5
11:26:07.629 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:26:07.845 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:26:07.845 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:26:07.881 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:26:07.899 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@341e47fa: startup date [Fri Sep 11 11:26:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@e9591f5
11:26:09.145 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:26:09.482 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:26:09.977 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:26:10.021 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:26:10.177 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e672d241] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.344 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$7f209a7b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.356 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.364 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@364c7eb6' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.369 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$a3f53d2d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.380 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.409 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$28cd53e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:26:10.943 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:26:10.955 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:26:10.965 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:26:10.966 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:26:10.969 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:26:11.255 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:26:11.258 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:26:11.258 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3360 ms
11:26:11.500 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:26:11.500 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:26:11.509 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@3c3c43b5
11:26:11.737 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:26:11.933 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:26:13.221 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:26:13.222 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:26:13.222 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:26:13.222 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:26:13.222 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:26:13.223 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:26:13.223 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:26:15.144 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:26:15.144 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:26:15.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:26:15.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:26:15.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.147 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:26:15.148 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:26:15.149 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:26:15.149 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:26:15.149 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:26:15.149 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:26:15.149 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.150 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:26:15.150 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:26:15.150 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.151 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:26:15.152 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:26:15.156 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:26:15.157 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:26:15.159 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:26:15.161 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:26:15.162 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:26:15.162 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:26:15.165 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:26:15.165 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:26:15.293 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:26:15.309 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.310 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.311 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.312 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.313 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.313 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:26:15.313 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:26:15.663 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:26:15.737 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:26:15.737 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:26:15.887 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:26:15.998 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@341e47fa: startup date [Fri Sep 11 11:26:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@e9591f5
11:26:16.069 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:26:16.069 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:26:16.981 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:26:16.991 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:26:16.991 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:26:16.991 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:26:16.992 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:26:16.992 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:26:16.992 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:26:16.992 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@2cc13b05
11:26:17.074 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: f2925e7f-6e15-49dc-b818-78056890fb3c

11:26:17.242 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1307547e, org.springframework.security.web.context.SecurityContextPersistenceFilter@65b1b65e, org.springframework.security.web.header.HeaderWriterFilter@34c4f767, org.springframework.security.web.authentication.logout.LogoutFilter@2bf9286b, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@51103a6a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@176c4a34, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@35a9ed60, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@6621dfc8, org.springframework.security.web.session.SessionManagementFilter@1731a7c1, org.springframework.security.web.access.ExceptionTranslationFilter@1c9b4132, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@28450756]
11:26:17.378 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:26:17.580 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:26:17.586 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:26:17.732 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:26:17.733 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:26:17.733 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:26:17.742 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:26:17.744 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:26:17.745 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:26:17.748 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:26:17.756 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:26:17.768 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=341e47fa,type=ConfigurationPropertiesRebinder]
11:26:17.773 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:26:17.775 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:26:17.793 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:26:17.805 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:26:17.809 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:26:17.810 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:26:17.810 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:26:17.811 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:26:17.811 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:26:17.892 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:26:17.892 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:26:17.896 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:26:17.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:26:17.898 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:26:17.900 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794777900 with initial instances count: 5
11:26:17.908 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:26:17.908 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794777908, current=UP, previous=STARTING]
11:26:17.909 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:26:17.912 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:26:17.912 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:26:17.926 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:26:17.936 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:26:17.964 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:26:18.075 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:26:18.076 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:26:18.078 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:26:18.084 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:26:18.085 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:26:18.088 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:26:18.088 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:26:18.089 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:26:18.098 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:26:18.105 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:26:18.106 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:26:18.107 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:26:18.109 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:26:18.110 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:26:18.111 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:26:18.112 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:26:18.116 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:26:18.117 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:26:18.118 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:26:18.144 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:26:18.144 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:26:18.158 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:26:18.166 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:26:18.174 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:26:18.198 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:26:18.199 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:26:18.201 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 13.031 seconds (JVM running for 13.941)
11:26:18.563 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:26:18.709 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:26:18.710 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:26:18.727 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:26:18.733 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 22 ms
11:26:18.811 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:26:18.812 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:27:17.478 zt-spark [Thread-40] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@341e47fa: startup date [Fri Sep 11 11:26:07 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@e9591f5
11:27:17.480 zt-spark [Thread-40] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:27:17.480 zt-spark [Thread-40] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794837480, current=DOWN, previous=UP]
11:27:17.480 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:27:17.483 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:27:17.483 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:27:17.484 zt-spark [Thread-40] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:27:17.484 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:27:17.485 zt-spark [Thread-40] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:27:17.485 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:27:17.485 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:27:17.486 zt-spark [Thread-40] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:27:17.486 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:27:17.487 zt-spark [Thread-40] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:27:48.354 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@126e8a0c: startup date [Fri Sep 11 11:27:48 CST 2020]; root of context hierarchy
11:27:48.566 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:27:48.593 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$a018023c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:48.840 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:27:48.877 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:27:49.101 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:27:49.101 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:27:49.178 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:27:49.178 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:27:49.354 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:27:49.447 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:27:49.561 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:27:49.563 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:27:49.566 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794869565 with initial instances count: 5
11:27:49.803 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:27:50.026 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:27:50.026 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:27:50.056 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:27:50.069 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6395274f: startup date [Fri Sep 11 11:27:50 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@126e8a0c
11:27:50.938 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:27:51.230 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:27:51.614 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:27:51.647 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:27:51.759 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$83fdff3f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.897 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$1cabc779] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.906 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.910 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@3ff68f17' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.914 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$41806a2b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.923 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:51.946 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$a018023c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:27:52.424 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:27:52.434 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:27:52.442 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:27:52.442 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:27:52.445 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:27:52.705 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:27:52.708 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:27:52.708 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2639 ms
11:27:52.894 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:27:52.894 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:27:52.901 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@73fa038c
11:27:53.084 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:27:53.251 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:27:54.361 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:27:54.362 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:27:54.363 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:27:54.363 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:27:54.364 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:27:54.364 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:27:56.062 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:27:56.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:27:56.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:27:56.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:27:56.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:27:56.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.065 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:27:56.065 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:27:56.065 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:27:56.065 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:27:56.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:27:56.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:27:56.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.067 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:27:56.068 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:27:56.068 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:27:56.068 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:27:56.068 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:27:56.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:27:56.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.070 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:27:56.070 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:27:56.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:27:56.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:27:56.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:27:56.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:27:56.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:27:56.074 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:27:56.074 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:27:56.074 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:27:56.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:27:56.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:27:56.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:27:56.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:27:56.077 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:27:56.079 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:27:56.080 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:27:56.080 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:27:56.083 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:27:56.083 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:27:56.228 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:27:56.246 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.247 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.247 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.248 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.249 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.250 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.251 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.251 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.251 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:27:56.251 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:27:56.672 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:27:56.744 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:27:56.744 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:27:56.932 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:27:57.042 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6395274f: startup date [Fri Sep 11 11:27:50 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@126e8a0c
11:27:57.098 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:27:57.098 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:27:57.959 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:27:57.968 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:27:57.968 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:27:57.969 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:27:57.969 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:27:57.969 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:27:57.969 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:27:57.969 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@333c5de9
11:27:58.045 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 5d00bbdb-c069-4024-8783-cb97b2768d00

11:27:58.223 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@c10d8cb, org.springframework.security.web.context.SecurityContextPersistenceFilter@37c06276, org.springframework.security.web.header.HeaderWriterFilter@6bb2dcf6, org.springframework.security.web.authentication.logout.LogoutFilter@38bf13b1, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@4c4aa2fa, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@5105f98b, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@38839cca, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@77fb3c75, org.springframework.security.web.session.SessionManagementFilter@14386338, org.springframework.security.web.access.ExceptionTranslationFilter@5883a4c9, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@21ca80d3]
11:27:58.351 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:27:58.585 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:27:58.592 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:27:58.756 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:27:58.758 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:27:58.758 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:27:58.770 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:27:58.772 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:27:58.773 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:27:58.777 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:27:58.785 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:27:58.796 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6395274f,type=ConfigurationPropertiesRebinder]
11:27:58.801 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:27:58.802 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:27:58.823 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:27:58.835 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:27:58.838 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:27:58.840 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:27:58.840 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:27:58.840 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:27:58.840 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:27:58.896 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:27:58.896 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:27:58.897 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:27:58.901 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:27:58.902 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:27:58.904 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:27:58.905 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599794878905 with initial instances count: 5
11:27:58.911 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:27:58.912 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599794878912, current=UP, previous=STARTING]
11:27:58.913 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:27:58.915 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:27:58.915 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:27:58.927 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:27:58.944 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:27:58.979 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:27:59.082 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:27:59.084 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:27:59.086 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:27:59.092 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:27:59.094 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:27:59.096 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:27:59.097 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:27:59.098 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:27:59.106 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:27:59.113 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:27:59.114 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:27:59.114 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:27:59.116 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:27:59.117 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:27:59.118 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:27:59.119 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:27:59.123 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:27:59.124 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:27:59.125 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:27:59.148 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:27:59.148 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:27:59.163 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:27:59.190 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:27:59.198 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:27:59.219 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:27:59.220 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:27:59.222 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.609 seconds (JVM running for 12.402)
11:27:59.602 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:27:59.602 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:27:59.616 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:27:59.623 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
11:27:59.835 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:27:59.901 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:27:59.903 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:28:47.461 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:28:47.479 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:28:47.487 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:28:47.488 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:28:47.491 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:28:47.494 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:28:47.498 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:28:47.498 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:28:49.048 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:28:49.053 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:28:49.058 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:28:54.176 zt-spark [http-nio-9201-exec-4] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:28:54","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"123\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":15,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"\",\"time\":[\"\",\"\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":16,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:28:54.179 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:28:54.182 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:28:54.177(Timestamp), 1(Integer), 123(String), 16(Integer)
11:28:54.235 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:28:54.237 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:28:54.239 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 16(Integer)
11:28:54.241 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 0
11:28:54.241 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from point_duty_job where duty_id = ? 
11:28:54.243 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==> Parameters: 16(Integer)
11:28:54.244 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - <==    Updates: 0
11:28:54.251 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
11:28:54.253 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), (String), (String), 15(Integer)
11:28:54.268 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
11:28:54.276 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ? ) 
11:28:54.279 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:28:54.274(Timestamp), 16(String), 3(Integer), 设备1(String), ASDF(String)
11:28:54.302 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:28:54.303 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:28:54.306 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 16(Integer), 15(Integer), 23(Integer)
11:28:54.310 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:28:54.380 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:28:54.381 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:28:54.383 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:28:54.386 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:28:54.390 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:28:56.611 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:28:56.615 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:28:56.618 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:29:25.048 zt-spark [http-nio-9201-exec-7] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:29:25","methods":"POST","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskFlag\":\"true\",\"taskDescription\":\"1111\",\"organId\":28,\"taskBool\":true,\"startTime\":1599753600000,\"dutyStatus\":\"\",\"time\":[\"2020-09-11\",\"2020-09-12\"],\"endTime\":1599753600000,\"comId\":33,\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"GHJK\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"}],\"peopleId\":16,\"dutyStartTime\":\"\",\"time\":[\"2016-10-10T00:40:00.000Z\",\"2016-10-10T01:40:00.000Z\"]}]}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/save","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:29:25.049 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.insertCompanyDuty - ==>  Preparing: insert into zt_company_duty ( com_id, organ_id, start_time, end_time, duty_type, task_flag, duty_status, create_time, create_by, del_flag, task_description ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:25.054 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.insertCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:29:25.048(Timestamp), 1(Integer), 1(String), 1111(String)
11:29:25.105 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.insertCompanyDuty - <==    Updates: 1
11:29:25.106 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==>  Preparing: insert into zt_dutyid_peopleid ( duty_id, people_id, duty_start_time, duty_end_time ) values ( ?, ?, ?, ? ) 
11:29:25.108 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==> Parameters: 17(Integer), 16(Integer), (String), (String)
11:29:25.145 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - <==    Updates: 1
11:29:25.146 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, del_flag, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:25.149 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:29:25.146(Timestamp), 17(String), 16(Integer), 1(String), 设备2(String), GHJK(String)
11:29:25.178 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:25.179 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:25.181 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 17(Integer), 16(Integer), 24(Integer)
11:29:25.195 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:25.256 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:29:25.256 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:25.258 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:29:25.260 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:25.263 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:29:28.239 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:29:28.243 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
11:29:28.246 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:29:34.084 zt-spark [http-nio-9201-exec-10] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:29:34","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"1111\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"GHJK\"],\"dutyJobId\":24,\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"},{\"number\":[\"ASDF\",\"GHJK\"],\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":16,\"peoplePhone\":\"17888885555\",\"peopleId\":16,\"peopleName\":\"多的\",\"dutyStartTime\":\"\",\"time\":[\"\",\"\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":17,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:29:34.086 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:29:34.090 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:29:34.085(Timestamp), 1(Integer), 1111(String), 17(Integer)
11:29:34.135 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:29:34.136 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:29:34.138 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 17(Integer)
11:29:34.152 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 1
11:29:34.153 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from point_duty_job where duty_id = ? 
11:29:34.155 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==> Parameters: 17(Integer)
11:29:34.169 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - <==    Updates: 1
11:29:34.169 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
11:29:34.171 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 16(Integer), (String), (String), 16(Integer)
11:29:34.185 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
11:29:34.186 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( id, assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:34.189 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 24(Integer), 1(String), 金枪鱼(String), 2020-09-11 11:29:34.186(Timestamp), 17(String), 16(Integer), 设备2(String), GHJK(String)
11:29:34.202 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:34.203 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:34.205 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 17(Integer), 16(Integer), 24(Integer)
11:29:34.218 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:34.220 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ? ) 
11:29:34.222 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:29:34.219(Timestamp), 17(String), 16(Integer), 设备1(String), ASDF,GHJK(String)
11:29:34.235 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:34.236 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:34.237 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 17(Integer), 16(Integer), 25(Integer)
11:29:34.252 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:34.314 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:29:34.315 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:34.317 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:29:34.321 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:34.325 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 3
11:29:36.147 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:29:36.150 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
11:29:36.156 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
11:29:43.278 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:29:43","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"1111\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"08:00\",\"task\":[{\"number\":[\"GHJK\"],\"dutyJobId\":24,\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"},{\"number\":[\"ASDF\",\"GHJK\"],\"dutyJobId\":25,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF,GHJK\"}],\"dutyPeopleId\":16,\"peoplePhone\":\"17888885555\",\"peopleId\":16,\"peopleName\":\"多的\",\"dutyStartTime\":\"08:00\",\"time\":[\"08:00\",\"08:00\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599753600000,\"time\":[\"2020-09-11\",\"2020-09-11\"],\"id\":17,\"endTime\":1599753600000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:29:43.280 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:29:43.283 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-11 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:29:43.278(Timestamp), 1(Integer), 1111(String), 17(Integer)
11:29:43.313 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:29:43.313 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:29:43.316 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 17(Integer)
11:29:43.329 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 2
11:29:43.330 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from point_duty_job where duty_id = ? 
11:29:43.332 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==> Parameters: 17(Integer)
11:29:43.354 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - <==    Updates: 2
11:29:43.355 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
11:29:43.357 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 16(Integer), 08:00(String), 08:00(String), 16(Integer)
11:29:43.371 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
11:29:43.372 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( id, assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:43.375 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 24(Integer), 1(String), 金枪鱼(String), 2020-09-11 11:29:43.372(Timestamp), 17(String), 16(Integer), 设备2(String), GHJK(String)
11:29:43.388 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:43.389 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:43.391 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 17(Integer), 16(Integer), 24(Integer)
11:29:43.404 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:43.405 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( id, assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:43.407 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 25(Integer), 1(String), 金枪鱼(String), 2020-09-11 11:29:43.405(Timestamp), 17(String), 16(Integer), 设备1(String), ASDF,GHJK(String)
11:29:43.429 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:43.430 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:43.432 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 17(Integer), 16(Integer), 25(Integer)
11:29:43.446 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:43.510 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:29:43.510 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:43.513 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:29:43.515 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:43.521 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 3
11:29:44.948 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:29:44.951 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
11:29:44.956 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
11:29:48.056 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:29:48.060 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 16(Integer)
11:29:48.063 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:29:51.882 zt-spark [http-nio-9201-exec-8] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:29:51","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"123\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"08:00\",\"task\":[{\"number\":[\"ASDF\"],\"dutyJobId\":23,\"equipmentName\":\"设备1\",\"equipmentNum\":\"ASDF\"}],\"dutyPeopleId\":15,\"peoplePhone\":\"17655554444\",\"peopleId\":3,\"peopleName\":\"李四\",\"dutyStartTime\":\"08:00\",\"time\":[\"08:00\",\"08:00\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1599667200000,\"time\":[\"2020-09-10\",\"2020-09-10\"],\"id\":16,\"endTime\":1599667200000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:29:51.883 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:29:51.886 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:29:51.882(Timestamp), 1(Integer), 123(String), 16(Integer)
11:29:51.926 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:29:51.926 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:29:51.928 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 16(Integer)
11:29:51.942 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 1
11:29:51.943 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from point_duty_job where duty_id = ? 
11:29:51.945 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==> Parameters: 16(Integer)
11:29:51.951 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - <==    Updates: 1
11:29:51.952 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
11:29:51.954 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 3(Integer), 08:00(String), 08:00(String), 15(Integer)
11:29:51.959 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
11:29:51.960 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( id, assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:29:51.962 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 23(Integer), 1(String), 金枪鱼(String), 2020-09-11 11:29:51.959(Timestamp), 16(String), 3(Integer), 设备1(String), ASDF(String)
11:29:51.967 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:29:51.969 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:29:51.971 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 16(Integer), 15(Integer), 23(Integer)
11:29:51.976 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:29:52.025 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:29:52.026 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:52.028 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:29:52.030 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:29:52.033 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 3
11:29:53.085 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:29:53.087 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
11:29:53.090 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
11:30:13.379 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:13.380 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:13.382 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:30:13.385 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:13.389 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:30:16.740 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:16.741 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-12(String), 2020-9-12(String)
11:30:16.742 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:16.744 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-12(String), 2020-9-12(String)
11:30:16.747 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:17.686 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:17.686 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-13(String), 2020-9-13(String)
11:30:17.687 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:17.690 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-13(String), 2020-9-13(String)
11:30:17.692 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:18.325 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:18.326 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-19(String), 2020-9-19(String)
11:30:18.327 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:18.329 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-19(String), 2020-9-19(String)
11:30:18.331 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:18.813 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:18.813 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-18(String), 2020-9-18(String)
11:30:18.815 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:18.816 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-18(String), 2020-9-18(String)
11:30:18.819 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:19.271 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:19.272 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-17(String), 2020-9-17(String)
11:30:19.273 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:19.275 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-17(String), 2020-9-17(String)
11:30:19.277 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:19.754 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:19.755 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-15(String), 2020-9-15(String)
11:30:19.756 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:19.758 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-15(String), 2020-9-15(String)
11:30:19.760 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:20.395 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:20.395 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-16(String), 2020-9-16(String)
11:30:20.397 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:20.399 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-16(String), 2020-9-16(String)
11:30:20.401 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:20.939 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:20.939 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-14(String), 2020-9-14(String)
11:30:20.941 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:20.944 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-14(String), 2020-9-14(String)
11:30:20.946 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:21.623 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:21.623 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-21(String), 2020-9-21(String)
11:30:21.625 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:30:21.627 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-21(String), 2020-9-21(String)
11:30:21.629 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:30:25.669 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:25.669 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:25.672 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:30:25.675 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:25.678 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:30:27.200 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:27.201 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-10(String), 2020-9-10(String)
11:30:27.203 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:30:27.205 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-10(String), 2020-9-10(String)
11:30:27.208 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 1
11:30:28.126 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:30:28.126 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:28.128 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:30:28.130 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:30:28.133 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:30:58.433 zt-spark [http-nio-9201-exec-4] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:30:58","methods":"POST","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"二班一天\",\"taskFlag\":\"true\",\"taskDescription\":\"测试长值班\",\"organId\":28,\"taskBool\":true,\"startTime\":1599667200000,\"dutyStatus\":\"\",\"time\":[\"2020-09-10\",\"2020-10-22\"],\"endTime\":1599667200000,\"comId\":33,\"people\":[{\"dutyEndTime\":\"\",\"task\":[{\"number\":[\"ASDF\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"ASDF\"}],\"peopleId\":7,\"dutyStartTime\":\"\",\"time\":[\"2016-10-10T00:40:00.000Z\",\"2016-10-10T01:40:00.000Z\"]}]}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/save","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:30:58.434 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.insertCompanyDuty - ==>  Preparing: insert into zt_company_duty ( com_id, organ_id, start_time, end_time, duty_type, task_flag, duty_status, create_time, create_by, del_flag, task_description ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 
11:30:58.437 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.insertCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-10 00:00:00.0(Timestamp), 2020-09-10 00:00:00.0(Timestamp), 二班一天(String), 1(String), 1(String), 2020-09-11 11:30:58.433(Timestamp), 1(Integer), 1(String), 测试长值班(String)
11:30:58.459 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.insertCompanyDuty - <==    Updates: 1
11:30:58.460 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==>  Preparing: insert into zt_dutyid_peopleid ( duty_id, people_id, duty_start_time, duty_end_time ) values ( ?, ?, ?, ? ) 
11:30:58.462 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==> Parameters: 18(Integer), 7(Integer), (String), (String)
11:30:58.475 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - <==    Updates: 1
11:30:58.476 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, del_flag, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:30:58.478 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:30:58.476(Timestamp), 18(String), 7(Integer), 1(String), 设备2(String), ASDF(String)
11:30:58.500 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:30:58.501 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:30:58.504 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 18(Integer), 17(Integer), 26(Integer)
11:30:58.525 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:30:58.580 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:30:58.581 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:30:58.583 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:30:58.585 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:30:58.588 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
11:31:01.363 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:31:01.366 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 18(Integer)
11:31:01.369 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:32:00.505 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:32:00.505 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:32:00.508 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:32:00.512 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:32:00.516 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
11:32:35.878 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:32:35.880 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:32:35.881 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:32:35.881 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:32:35.883 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:32:35.884 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:32:35.885 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:32:35.889 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
11:32:39.808 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:39.808 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:32:39.811 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:32:39.813 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:32:39.816 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:32:41.259 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:41.259 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-26(String), 2020-9-26(String)
11:32:41.261 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:41.263 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-26(String), 2020-9-26(String)
11:32:41.265 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:42.011 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:42.011 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-19(String), 2020-9-19(String)
11:32:42.013 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:42.015 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-19(String), 2020-9-19(String)
11:32:42.017 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:42.481 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:42.481 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-18(String), 2020-9-18(String)
11:32:42.483 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:42.486 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-18(String), 2020-9-18(String)
11:32:42.488 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:43.003 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:43.003 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-17(String), 2020-9-17(String)
11:32:43.004 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:43.006 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-17(String), 2020-9-17(String)
11:32:43.008 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:43.576 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:43.576 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-16(String), 2020-9-16(String)
11:32:43.577 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:43.580 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-16(String), 2020-9-16(String)
11:32:43.582 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:43.992 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:43.992 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-23(String), 2020-9-23(String)
11:32:43.993 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:43.996 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-23(String), 2020-9-23(String)
11:32:43.998 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:45.406 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:45.407 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-15(String), 2020-10-15(String)
11:32:45.408 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:45.411 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-15(String), 2020-10-15(String)
11:32:45.413 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:45.885 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:45.886 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-8(String), 2020-10-8(String)
11:32:45.887 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:45.889 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-8(String), 2020-10-8(String)
11:32:45.892 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:46.265 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:32:46.265 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-13(String), 2020-10-13(String)
11:32:46.267 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') 
11:32:46.269 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-10-13(String), 2020-10-13(String)
11:32:46.271 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
11:32:58.921 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:33:26.399 zt-spark [http-nio-9201-exec-10] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:33:26","methods":"POST","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskFlag\":\"true\",\"taskDescription\":\"2020-9-9 = 2020-10-21\",\"organId\":28,\"taskBool\":true,\"startTime\":1599580800000,\"dutyStatus\":\"\",\"time\":[\"2020-09-09\",\"2020-10-21\"],\"endTime\":1599580800000,\"comId\":33,\"people\":[{\"dutyEndTime\":\"09:40\",\"task\":[{\"number\":[\"GHJK\"],\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"}],\"peopleId\":4,\"dutyStartTime\":\"08:00\",\"time\":[\"08:00\",\"09:40\"]}]}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/save","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:33:26.400 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.insertCompanyDuty - ==>  Preparing: insert into zt_company_duty ( com_id, organ_id, start_time, end_time, duty_type, task_flag, duty_status, create_time, create_by, del_flag, task_description ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 
11:33:26.405 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.insertCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-09 00:00:00.0(Timestamp), 2020-09-09 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:33:26.399(Timestamp), 1(Integer), 1(String), 2020-9-9 = 2020-10-21(String)
11:33:26.434 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.insertCompanyDuty - <==    Updates: 1
11:33:26.435 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==>  Preparing: insert into zt_dutyid_peopleid ( duty_id, people_id, duty_start_time, duty_end_time ) values ( ?, ?, ?, ? ) 
11:33:26.437 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - ==> Parameters: 19(Integer), 4(Integer), 08:00(String), 09:40(String)
11:33:26.451 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.Z.insertZdutyidPeopleid - <==    Updates: 1
11:33:26.452 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( assign_user_id, assign_user_name, assign_time, duty_id, people_id, del_flag, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:33:26.454 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 1(String), 金枪鱼(String), 2020-09-11 11:33:26.451(Timestamp), 19(String), 4(Integer), 1(String), 设备2(String), GHJK(String)
11:33:26.468 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:33:26.468 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:33:26.470 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 19(Integer), 18(Integer), 27(Integer)
11:33:26.484 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:33:26.536 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:33:26.536 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:33:26.538 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:33:26.541 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:33:26.544 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:34:06.928 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND DATE_FORMAT(d.end_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.start_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
11:34:06.929 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:34:06.932 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 AND DATE_FORMAT(d.end_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.start_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,10 
11:34:06.936 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 2020-9-11(String), 2020-9-11(String)
11:34:06.939 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
11:34:10.521 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:34:10.523 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 19(Integer)
11:34:10.526 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:34:22.584 zt-spark [http-nio-9201-exec-5] INFO  c.z.z.c.CompanyDutyController - es_begin:{"address":"","logDate":"2020-09-11 11:34:22","methods":"PUT","ip":"","originalSql":"","userAgent":"","userName":"spark","params":"{\"dutyType\":\"一班一天\",\"taskDescription\":\"2020-9-9 = 2020-10-21\",\"createPhone\":\"\",\"taskBool\":true,\"dutyStatus\":\"1\",\"people\":[{\"dutyEndTime\":\"09:40\",\"task\":[{\"number\":[\"GHJK\"],\"dutyJobId\":27,\"equipmentName\":\"设备2\",\"equipmentNum\":\"GHJK\"}],\"dutyPeopleId\":18,\"peoplePhone\":\"18844447778\",\"peopleId\":4,\"peopleName\":\"测试\",\"dutyStartTime\":\"08:00\",\"time\":[\"08:00\",\"09:40\"]}],\"organName\":\"车场1A\",\"taskFlag\":\"true\",\"organId\":28,\"startTime\":1600272000000,\"time\":[\"2020-09-17\",\"2020-10-27\"],\"id\":19,\"endTime\":1600272000000,\"comId\":33,\"createName\":\"\"}","serviceName":"","userId":"1","sqlCommandType":"","url":"/companyduty/update","userDeptId":"1","userEmpNo":"spark","tag":"spark_OPERATE"}es_end!
11:34:22.585 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.updateCompanyDuty - ==>  Preparing: update zt_company_duty SET com_id = ?, organ_id = ?, start_time = ?, end_time = ?, duty_type = ?, task_flag = ?, duty_status = ?, update_time = ?, update_by = ?, task_description = ? where id = ? 
11:34:22.588 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.updateCompanyDuty - ==> Parameters: 33(Integer), 28(Integer), 2020-09-17 00:00:00.0(Timestamp), 2020-09-17 00:00:00.0(Timestamp), 一班一天(String), 1(String), 1(String), 2020-09-11 11:34:22.584(Timestamp), 1(Integer), 2020-9-9 = 2020-10-21(String), 19(Integer)
11:34:22.614 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.updateCompanyDuty - <==    Updates: 1
11:34:22.615 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==>  Preparing: delete from zt_dutyid_peopleid_task where company_duty_id = ? 
11:34:22.617 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - ==> Parameters: 19(Integer)
11:34:22.631 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deleteZtDutyIdPeopleIdTaskByCompanyDutyId - <==    Updates: 1
11:34:22.631 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==>  Preparing: delete from point_duty_job where duty_id = ? 
11:34:22.634 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - ==> Parameters: 19(Integer)
11:34:22.639 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.deletePointDutyJobByDutyId - <==    Updates: 1
11:34:22.640 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==>  Preparing: update zt_dutyid_peopleid SET people_id = ?, duty_start_time = ?, duty_end_time = ? where duty_people_id = ? 
11:34:22.641 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - ==> Parameters: 4(Integer), 08:00(String), 09:40(String), 18(Integer)
11:34:22.647 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.Z.updateZdutyidPeopleid - <==    Updates: 1
11:34:22.648 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertPointDutyJob - ==>  Preparing: insert into point_duty_job ( id, assign_user_id, assign_user_name, assign_time, duty_id, people_id, equipment_name, equipment_num ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) 
11:34:22.652 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertPointDutyJob - ==> Parameters: 27(Integer), 1(String), 金枪鱼(String), 2020-09-11 11:34:22.648(Timestamp), 19(String), 4(Integer), 设备2(String), GHJK(String)
11:34:22.664 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertPointDutyJob - <==    Updates: 1
11:34:22.665 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==>  Preparing: insert into zt_dutyid_peopleid_task (company_duty_id,duty_people_id,point_duty_job_id) values (?,?,?) 
11:34:22.667 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - ==> Parameters: 19(Integer), 18(Integer), 27(Integer)
11:34:22.681 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.P.insertZtDutyId_PeopleIdTask - <==    Updates: 1
11:34:22.733 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:34:22.733 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:34:22.735 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:34:22.739 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:34:22.742 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:34:50.474 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:34:50.474 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:34:50.475 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:34:50.476 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:34:50.477 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:34:50.478 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:34:50.480 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:34:50.480 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:37:28.212 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@f68be2: startup date [Fri Sep 11 11:37:28 CST 2020]; root of context hierarchy
11:37:28.430 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:37:28.455 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70d62d01] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:28.696 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:37:28.736 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:37:28.962 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:37:28.962 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:37:29.036 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:37:29.037 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:37:29.216 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:37:29.316 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:37:29.450 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:37:29.453 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:37:29.456 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795449455 with initial instances count: 5
11:37:29.695 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:37:29.927 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:37:29.927 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:37:29.958 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:37:29.972 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@62376002: startup date [Fri Sep 11 11:37:29 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@f68be2
11:37:30.860 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:37:31.147 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:37:31.567 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:37:31.601 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:37:31.716 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$54bc2a04] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.856 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$ed69f23e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.865 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.869 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@5b541cd5' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.873 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$123e94f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.883 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:31.906 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70d62d01] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:37:32.376 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:37:32.386 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:37:32.395 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:37:32.395 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:37:32.398 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:37:32.667 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:37:32.670 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:37:32.670 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2698 ms
11:37:32.865 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:37:32.865 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:37:32.872 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@341fa12c
11:37:33.059 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:37:33.232 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:37:34.277 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:37:34.278 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:37:34.279 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:37:34.279 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:37:34.279 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:37:34.280 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:37:34.280 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:37:36.018 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:37:36.019 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:37:36.019 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.020 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:37:36.020 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:37:36.020 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.020 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:37:36.022 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:37:36.022 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:37:36.022 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:37:36.022 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:37:36.023 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.023 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:37:36.023 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:37:36.024 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:37:36.025 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:37:36.026 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.027 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:37:36.027 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:37:36.027 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:37:36.027 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:37:36.028 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:37:36.028 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:37:36.028 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:37:36.031 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:37:36.031 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:37:36.031 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:37:36.031 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:37:36.032 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:37:36.033 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:37:36.033 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:37:36.034 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:37:36.037 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:37:36.037 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:37:36.037 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:37:36.040 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:37:36.040 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:37:36.150 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:37:36.162 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.163 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.163 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.163 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.163 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.164 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.164 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.164 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.164 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.164 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.165 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.166 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.167 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:37:36.167 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:37:36.477 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:37:36.535 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:37:36.535 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:37:36.653 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:37:36.745 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@62376002: startup date [Fri Sep 11 11:37:29 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@f68be2
11:37:36.801 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:37:36.801 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:37:37.500 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:37:37.508 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:37:37.508 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:37:37.508 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:37:37.509 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:37:37.509 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:37:37.509 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:37:37.509 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@75ce5e8f
11:37:37.575 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 0e0fb72c-7f89-4daa-a636-217214cd731c

11:37:37.706 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@6191d168, org.springframework.security.web.context.SecurityContextPersistenceFilter@134d6bd7, org.springframework.security.web.header.HeaderWriterFilter@36495c79, org.springframework.security.web.authentication.logout.LogoutFilter@dbe620c, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@4cb08ff1, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@52a822cd, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@6a8c4c15, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@189e74b7, org.springframework.security.web.session.SessionManagementFilter@5a57a5a0, org.springframework.security.web.access.ExceptionTranslationFilter@5477b1f1, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@71f7759a]
11:37:37.820 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:37:37.984 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:37:37.989 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:37:38.109 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:37:38.111 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:37:38.111 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:37:38.119 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:37:38.120 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:37:38.121 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:37:38.124 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:37:38.131 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:37:38.140 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=62376002,type=ConfigurationPropertiesRebinder]
11:37:38.145 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:37:38.146 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:37:38.164 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:37:38.175 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:37:38.178 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:37:38.179 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:37:38.179 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:37:38.179 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:37:38.179 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:37:38.223 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:37:38.224 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:37:38.228 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:37:38.229 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:37:38.230 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:37:38.232 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795458232 with initial instances count: 5
11:37:38.239 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:37:38.239 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599795458239, current=UP, previous=STARTING]
11:37:38.240 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:37:38.242 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:37:38.243 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:37:38.254 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:37:38.266 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:37:38.288 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:37:38.379 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:37:38.380 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:37:38.381 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:37:38.387 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:37:38.388 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:37:38.390 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:37:38.391 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:37:38.392 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:37:38.401 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:37:38.408 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:37:38.409 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:37:38.410 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:37:38.412 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:37:38.413 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:37:38.414 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:37:38.415 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:37:38.419 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:37:38.420 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:37:38.421 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:37:38.446 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:37:38.446 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:37:38.462 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:37:38.470 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:37:38.479 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:37:38.501 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:37:38.502 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:37:38.504 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.334 seconds (JVM running for 12.53)
11:37:38.887 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:37:38.887 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:37:38.901 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:37:38.908 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
11:37:39.057 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:37:39.147 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:37:39.149 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:38:10.588 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:38:10.609 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:38:10.621 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:38:10.622 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:38:10.626 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:38:10.629 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:38:10.630 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:38:10.636 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:38:13.256 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
11:38:13.259 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 19(Integer)
11:38:13.263 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
11:38:54.484 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:38:54.486 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:38:54.487 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:38:54.487 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:38:54.489 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:38:54.493 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:38:54.493 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:38:54.499 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:39:06.025 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:39:06.027 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:39:06.027 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:39:06.027 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:39:06.029 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:39:06.032 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:39:06.032 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:39:06.037 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:39:42.180 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:39:42.184 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:39:42.184 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:39:42.185 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:39:42.187 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:39:42.189 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:39:42.189 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:39:42.197 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:42:23.301 zt-spark [Thread-33] INFO  o.s.c.a.AnnotationConfigApplicationContext - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@f68be2: startup date [Fri Sep 11 11:37:28 CST 2020]; root of context hierarchy
11:42:23.301 zt-spark [Thread-33] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@62376002: startup date [Fri Sep 11 11:37:29 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@f68be2
11:42:23.302 zt-spark [Thread-33] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
11:42:23.303 zt-spark [Thread-33] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599795743303, current=DOWN, previous=UP]
11:42:23.303 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:42:23.307 zt-spark [Thread-33] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
11:42:23.307 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:42:23.307 zt-spark [Thread-33] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:42:23.308 zt-spark [Thread-33] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
11:42:23.310 zt-spark [Thread-33] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
11:42:23.310 zt-spark [Thread-33] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
11:42:23.310 zt-spark [Thread-33] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
11:42:23.320 zt-spark [Thread-33] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
11:42:23.322 zt-spark [Thread-33] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
11:42:23.323 zt-spark [Thread-33] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
11:42:24.457 zt-spark [Thread-33] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
11:42:24.458 zt-spark [Thread-33] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:42:24.462 zt-spark [Thread-33] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:42:27.463 zt-spark [Thread-33] INFO  c.netflix.discovery.DiscoveryClient - Unregistering ...
11:42:27.466 zt-spark [Thread-33] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - deregister  status: 200
11:42:27.470 zt-spark [Thread-33] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:42:30.117 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@42da8a9b: startup date [Fri Sep 11 11:42:30 CST 2020]; root of context hierarchy
11:42:30.157 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:42:30.157 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70d62d01] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:30.283 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:42:30.287 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:42:30.288 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:42:30.288 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:42:30.288 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:42:30.288 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:42:30.337 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:42:30.338 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:42:30.341 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:42:30.342 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:42:30.342 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795750342 with initial instances count: 4
11:42:30.482 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:42:30.640 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:42:30.641 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:42:30.651 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:42:30.654 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@55492bef: startup date [Fri Sep 11 11:42:30 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@42da8a9b
11:42:31.334 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:42:31.431 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:42:31.599 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:42:31.622 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:42:31.649 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$54bc2a04] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.671 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$ed69f23e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.674 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.676 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@55c36645' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.677 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$123e94f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.680 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.686 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70d62d01] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:42:31.870 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:42:31.870 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:42:31.870 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:42:31.871 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:42:31.980 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:42:31.982 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:42:31.982 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 1328 ms
11:42:32.043 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:42:32.043 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:42:32.043 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@2568390e
11:42:32.125 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:42:32.219 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-2} inited
11:42:32.807 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:42:32.807 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:42:32.807 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:42:32.807 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:42:32.808 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:42:33.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:42:33.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:42:33.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:42:33.787 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:42:33.788 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.788 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:42:33.789 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:42:33.792 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.793 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:42:33.794 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:42:33.796 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:42:33.797 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:42:33.799 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:42:33.799 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:42:33.799 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:42:33.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:42:33.801 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:42:33.878 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.881 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.882 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.883 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.883 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:42:33.883 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:42:34.017 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:42:34.045 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:42:34.045 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:42:34.107 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:42:34.139 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@55492bef: startup date [Fri Sep 11 11:42:30 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@42da8a9b
11:42:34.167 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:42:34.167 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:42:34.479 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:42:34.481 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:42:34.481 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@62c20d08
11:42:34.511 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 34322413-6896-4b7d-820e-2a09ecae9aed

11:42:34.546 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@5940755f, org.springframework.security.web.context.SecurityContextPersistenceFilter@2851fc0e, org.springframework.security.web.header.HeaderWriterFilter@25602298, org.springframework.security.web.authentication.logout.LogoutFilter@5c052655, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@4e928071, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@f8b3a5a, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@2bdbadd1, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@412655c1, org.springframework.security.web.session.SessionManagementFilter@6c136758, org.springframework.security.web.access.ExceptionTranslationFilter@560e3e60, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@34efd4e6]
11:42:34.586 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:42:34.666 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:42:34.669 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:42:34.736 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:42:34.737 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:42:34.737 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:42:34.741 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:42:34.741 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:42:34.742 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:42:34.747 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:42:34.751 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:42:34.754 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=55492bef,type=ConfigurationPropertiesRebinder]
11:42:34.757 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:42:34.760 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:42:34.777 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:42:34.784 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:42:34.786 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:42:34.787 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:42:34.787 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:42:34.787 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:42:34.787 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:42:34.826 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:42:34.827 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:42:34.830 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:42:34.831 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:42:34.831 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:42:34.832 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795754832 with initial instances count: 4
11:42:34.838 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:42:34.838 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599795754838, current=UP, previous=STARTING]
11:42:34.839 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:42:34.841 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:42:34.842 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:42:34.843 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:42:34.843 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:42:34.853 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:42:34.886 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:42:34.887 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:42:34.887 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:42:34.891 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:42:34.892 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:42:34.894 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:42:34.894 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:42:34.895 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:42:34.901 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:42:34.906 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:42:34.907 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:42:34.908 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:42:34.909 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:42:34.910 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:42:34.911 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:42:34.912 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:42:34.915 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:42:34.916 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:42:34.916 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:42:34.931 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:42:34.931 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:42:34.943 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:42:34.945 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:42:34.946 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:42:34.950 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:42:34.950 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:42:34.951 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 4.988 seconds (JVM running for 308.954)
11:42:34.957 zt-spark [restartedMain] INFO  o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
11:43:22.137 zt-spark [http-nio-9201-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:43:22.137 zt-spark [http-nio-9201-exec-1] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:43:22.151 zt-spark [http-nio-9201-exec-1] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 14 ms
11:43:22.203 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:43:22.207 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:43:22.214 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:43:22.215 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:43:22.218 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:43:22.219 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:43:22.225 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:43:22.230 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:45:49.140 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@47eac70a: startup date [Fri Sep 11 11:45:49 CST 2020]; root of context hierarchy
11:45:49.382 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:45:49.413 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$7af3a8f2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:49.659 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:45:49.697 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:45:49.912 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:45:49.913 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:45:49.988 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:45:49.988 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:45:50.178 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:45:50.275 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:45:50.401 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:45:50.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
11:45:50.407 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795950405 with initial instances count: 5
11:45:50.642 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:45:50.863 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:45:50.863 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
11:45:50.899 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
11:45:50.913 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@71eecbef: startup date [Fri Sep 11 11:45:50 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@47eac70a
11:45:51.785 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
11:45:52.068 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
11:45:52.470 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
11:45:52.503 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
11:45:52.615 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$5ed9a5f5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.751 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$f7876e2f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.759 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.764 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@205e6b9d' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.773 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$1c5c10e1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.782 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:52.805 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$7af3a8f2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
11:45:53.270 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
11:45:53.280 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
11:45:53.288 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
11:45:53.288 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
11:45:53.292 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
11:45:53.566 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
11:45:53.568 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
11:45:53.569 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2656 ms
11:45:53.755 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:45:53.755 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:45:53.762 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@ffccda
11:45:53.964 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
11:45:54.135 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
11:45:55.193 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
11:45:55.194 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
11:45:55.195 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
11:45:55.195 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
11:45:55.196 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
11:45:55.196 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
11:45:55.196 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
11:45:56.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
11:45:56.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
11:45:56.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
11:45:56.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
11:45:56.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:45:56.911 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
11:45:56.911 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
11:45:56.911 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
11:45:56.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
11:45:56.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:45:56.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.914 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:45:56.915 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:45:56.915 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
11:45:56.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
11:45:56.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
11:45:56.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
11:45:56.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
11:45:56.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
11:45:56.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
11:45:56.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
11:45:56.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
11:45:56.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
11:45:56.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:45:56.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
11:45:56.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
11:45:56.922 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
11:45:56.923 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
11:45:56.926 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
11:45:56.926 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
11:45:56.926 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
11:45:56.929 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
11:45:56.929 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:45:57.036 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
11:45:57.049 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.049 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.050 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.061 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.061 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.062 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.063 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.064 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
11:45:57.065 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
11:45:57.337 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
11:45:57.394 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
11:45:57.394 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
11:45:57.510 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:45:57.599 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@71eecbef: startup date [Fri Sep 11 11:45:50 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@47eac70a
11:45:57.655 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:45:57.655 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
11:45:58.337 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
11:45:58.345 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
11:45:58.345 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
11:45:58.345 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
11:45:58.346 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

11:45:58.346 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
11:45:58.346 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
11:45:58.346 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@4685b78e
11:45:58.412 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: f5babc3f-d2ca-4637-bba1-6e2d3ecc710f

11:45:58.542 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@21186b36, org.springframework.security.web.context.SecurityContextPersistenceFilter@417da61e, org.springframework.security.web.header.HeaderWriterFilter@3e7f73f4, org.springframework.security.web.authentication.logout.LogoutFilter@64c85081, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@5452e2a7, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@b253df1, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3cb466, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@34bb6e45, org.springframework.security.web.session.SessionManagementFilter@2424e47a, org.springframework.security.web.access.ExceptionTranslationFilter@4f4a6623, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@1ad24df3]
11:45:58.653 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
11:45:58.815 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
11:45:58.819 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
11:45:58.943 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
11:45:58.945 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
11:45:58.945 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
11:45:58.952 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
11:45:58.954 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
11:45:58.954 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
11:45:58.957 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
11:45:58.965 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
11:45:58.975 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=71eecbef,type=ConfigurationPropertiesRebinder]
11:45:58.980 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
11:45:58.982 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
11:45:58.999 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
11:45:59.010 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
11:45:59.014 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
11:45:59.015 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
11:45:59.015 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
11:45:59.015 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
11:45:59.015 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
11:45:59.064 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:45:59.064 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
11:45:59.064 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
11:45:59.065 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
11:45:59.065 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
11:45:59.065 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
11:45:59.065 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
11:45:59.065 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
11:45:59.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
11:45:59.070 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
11:45:59.072 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
11:45:59.073 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599795959073 with initial instances count: 5
11:45:59.081 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
11:45:59.081 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599795959081, current=UP, previous=STARTING]
11:45:59.082 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
11:45:59.084 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
11:45:59.085 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
11:45:59.098 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
11:45:59.108 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
11:45:59.133 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
11:45:59.224 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
11:45:59.225 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
11:45:59.226 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
11:45:59.232 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
11:45:59.233 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
11:45:59.236 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
11:45:59.237 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
11:45:59.238 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
11:45:59.247 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
11:45:59.255 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
11:45:59.256 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
11:45:59.257 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
11:45:59.258 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
11:45:59.259 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
11:45:59.260 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
11:45:59.261 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
11:45:59.265 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
11:45:59.266 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
11:45:59.267 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
11:45:59.292 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
11:45:59.293 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
11:45:59.308 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
11:45:59.317 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
11:45:59.325 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
11:45:59.351 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
11:45:59.352 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
11:45:59.354 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.969 seconds (JVM running for 11.94)
11:45:59.668 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
11:45:59.669 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
11:45:59.683 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
11:45:59.690 zt-spark [RMI TCP Connection(5)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
11:45:59.838 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
11:45:59.918 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
11:45:59.920 zt-spark [RMI TCP Connection(6)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
11:46:09.025 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:46:09.049 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:46:09.054 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:46:09.054 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:46:09.059 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:46:09.062 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:46:09.068 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:46:09.068 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:47:20.172 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
11:47:20.172 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:47:20.175 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
11:47:20.180 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
11:47:20.187 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
11:47:20.191 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
11:47:20.197 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
11:47:20.210 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.inputList - <==      Total: 21
11:50:59.089 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
11:55:59.114 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:00:59.138 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:05:59.162 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:10:59.186 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:15:59.210 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:20:48.895 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
12:20:48.897 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:20:48.901 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
12:20:48.908 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:20:48.909 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:20:48.919 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
12:20:48.914 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
12:20:48.928 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - <==      Total: 21
12:20:59.234 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:25:59.258 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:30:59.282 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:35:59.306 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:40:59.330 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:45:13.408 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@26fafc08: startup date [Fri Sep 11 12:45:13 CST 2020]; root of context hierarchy
12:45:13.622 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
12:45:13.646 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$e5c37165] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:13.881 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
12:45:13.918 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
12:45:14.139 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
12:45:14.139 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
12:45:14.212 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
12:45:14.212 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
12:45:14.389 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
12:45:14.479 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
12:45:14.593 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
12:45:14.596 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
12:45:14.599 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599799514598 with initial instances count: 5
12:45:14.829 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
12:45:15.060 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
12:45:15.061 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
12:45:15.092 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
12:45:15.106 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@56640950: startup date [Fri Sep 11 12:45:15 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@26fafc08
12:45:15.979 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
12:45:16.277 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
12:45:16.665 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
12:45:16.698 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
12:45:16.810 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c9a96e68] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.942 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$625736a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.951 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.956 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@6e984cc4' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.967 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$872bd954] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.976 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:16.999 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$e5c37165] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
12:45:17.465 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
12:45:17.475 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
12:45:17.483 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
12:45:17.484 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
12:45:17.487 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
12:45:17.733 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
12:45:17.737 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
12:45:17.737 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2631 ms
12:45:17.923 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
12:45:17.923 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
12:45:17.929 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@6c21d6b3
12:45:18.117 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
12:45:18.288 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
12:45:19.350 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
12:45:19.351 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
12:45:19.352 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
12:45:19.352 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
12:45:19.353 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
12:45:19.353 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
12:45:19.353 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
12:45:21.106 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
12:45:21.107 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
12:45:21.108 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.108 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
12:45:21.108 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
12:45:21.108 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.108 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
12:45:21.110 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
12:45:21.110 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
12:45:21.110 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
12:45:21.110 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
12:45:21.110 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.111 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
12:45:21.111 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
12:45:21.112 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
12:45:21.112 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
12:45:21.112 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
12:45:21.113 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
12:45:21.113 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.113 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
12:45:21.113 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
12:45:21.114 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.115 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
12:45:21.115 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
12:45:21.115 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
12:45:21.115 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
12:45:21.116 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
12:45:21.116 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
12:45:21.116 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
12:45:21.119 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
12:45:21.119 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
12:45:21.119 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
12:45:21.119 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
12:45:21.120 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
12:45:21.121 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
12:45:21.122 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
12:45:21.125 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
12:45:21.125 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
12:45:21.126 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
12:45:21.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
12:45:21.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
12:45:21.246 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
12:45:21.258 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.259 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.259 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.260 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.261 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.262 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
12:45:21.263 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
12:45:21.538 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
12:45:21.597 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
12:45:21.597 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
12:45:21.714 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
12:45:21.802 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@56640950: startup date [Fri Sep 11 12:45:15 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@26fafc08
12:45:21.860 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
12:45:21.860 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
12:45:22.549 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
12:45:22.556 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
12:45:22.556 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
12:45:22.557 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
12:45:22.557 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

12:45:22.557 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
12:45:22.557 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
12:45:22.557 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@1fa7da8a
12:45:22.623 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 68dfab64-c830-46b8-a52f-c117af3dc787

12:45:22.751 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@4ed42091, org.springframework.security.web.context.SecurityContextPersistenceFilter@79c2392, org.springframework.security.web.header.HeaderWriterFilter@91a6968, org.springframework.security.web.authentication.logout.LogoutFilter@4f25542e, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@14cfd673, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@3cd5b730, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@f307efe, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@43e19797, org.springframework.security.web.session.SessionManagementFilter@174b9b19, org.springframework.security.web.access.ExceptionTranslationFilter@55a4af9b, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@4c4aa2fa]
12:45:22.863 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
12:45:23.048 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
12:45:23.054 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
12:45:23.194 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
12:45:23.196 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
12:45:23.196 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
12:45:23.205 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
12:45:23.206 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
12:45:23.207 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
12:45:23.210 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
12:45:23.218 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
12:45:23.229 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=56640950,type=ConfigurationPropertiesRebinder]
12:45:23.235 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
12:45:23.236 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
12:45:23.256 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
12:45:23.268 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
12:45:23.271 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
12:45:23.272 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
12:45:23.272 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
12:45:23.273 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
12:45:23.273 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
12:45:23.361 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
12:45:23.362 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
12:45:23.366 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
12:45:23.366 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
12:45:23.368 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
12:45:23.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599799523369 with initial instances count: 5
12:45:23.376 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
12:45:23.376 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599799523376, current=UP, previous=STARTING]
12:45:23.377 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
12:45:23.379 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
12:45:23.380 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
12:45:23.391 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
12:45:23.401 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
12:45:23.423 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
12:45:23.515 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
12:45:23.516 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
12:45:23.517 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
12:45:23.525 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
12:45:23.526 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
12:45:23.528 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
12:45:23.529 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
12:45:23.530 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
12:45:23.539 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
12:45:23.546 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
12:45:23.548 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
12:45:23.548 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
12:45:23.550 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
12:45:23.551 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
12:45:23.552 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
12:45:23.553 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
12:45:23.557 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
12:45:23.558 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
12:45:23.559 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
12:45:23.583 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
12:45:23.583 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
12:45:23.597 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
12:45:23.604 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
12:45:23.613 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
12:45:23.633 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
12:45:23.634 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
12:45:23.636 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.935 seconds (JVM running for 11.785)
12:45:23.820 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
12:45:23.820 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
12:45:23.834 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
12:45:23.841 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 20 ms
12:45:23.991 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
12:45:24.068 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
12:45:24.070 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
12:46:23.907 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:46:23.935 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
12:46:23.952 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
12:46:23.953 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:46:23.958 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
12:46:23.962 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:46:23.965 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 21
12:46:23.970 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
12:46:27.579 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
12:46:27.580 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:46:27.583 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
12:46:27.588 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
12:46:27.595 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
12:48:11.291 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
12:48:11.295 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 18(Integer)
12:48:11.299 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 1
12:48:31.182 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:48:31.183 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:48:31.185 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:48:31.188 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:48:31.192 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 8
12:49:41.715 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:49:41.718 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
12:49:41.721 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - <==      Total: 3
12:49:41.723 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:49:41.724 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
12:49:41.727 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
12:49:41.729 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
12:49:41.734 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
12:49:50.260 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:49:50.260 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:49:50.262 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:49:50.264 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:49:50.268 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 8
12:50:00.713 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.id = ? 
12:50:00.716 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==> Parameters: 4(Integer)
12:50:00.718 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleById - <==      Total: 1
12:50:06.394 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.id = ? 
12:50:06.396 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==> Parameters: 1(Integer)
12:50:06.399 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleById - <==      Total: 1
12:50:11.536 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.id = ? 
12:50:11.538 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleById - ==> Parameters: 18(Integer)
12:50:11.541 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyPeopleById - <==      Total: 1
12:50:14.954 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:14.956 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:14.958 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:14.961 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:14.963 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:15.730 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:15.731 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:15.734 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:15.736 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:15.740 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:16.371 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:16.371 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 3(Integer), 33(Integer)
12:50:16.373 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:50:16.375 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 3(Integer), 33(Integer)
12:50:16.377 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:50:16.869 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:16.869 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 2(Integer), 33(Integer)
12:50:16.871 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:16.874 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 2(Integer), 33(Integer)
12:50:16.876 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:17.731 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:17.732 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:17.734 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:17.738 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:17.743 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:18.542 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:18.542 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:18.544 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:18.547 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:18.550 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:23.386 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:50:25.893 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:25.894 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:25.896 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:25.898 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 1(Integer), 33(Integer)
12:50:25.901 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:50:26.467 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:50:26.467 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 2(Integer), 33(Integer)
12:50:26.469 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:50:26.471 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 2(Integer), 33(Integer)
12:50:26.473 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 2
12:55:22.385 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:55:22.385 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:55:22.387 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:55:22.389 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:55:22.394 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
12:55:23.194 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:55:23.197 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
12:55:23.197 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:55:23.198 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
12:55:23.199 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.inputList - <==      Total: 3
12:55:23.200 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
12:55:23.204 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
12:55:23.212 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
12:55:23.411 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
12:57:37.027 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:57:37.028 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:37.029 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:37.031 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:37.033 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:39.119 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:57:39.123 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - ==> Parameters: 29(String), 34(Integer)
12:57:39.124 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.inputList - <==      Total: 0
12:57:39.126 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:57:39.126 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:39.128 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
12:57:39.131 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:39.133 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
12:57:41.604 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:57:41.604 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:41.606 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:41.609 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:41.611 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:42.135 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:57:42.136 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:42.137 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
12:57:42.139 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:57:42.140 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:42.142 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
12:57:42.143 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - ==> Parameters: 29(String), 34(Integer)
12:57:42.145 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.inputList - <==      Total: 0
12:57:43.105 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:57:43.105 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:43.107 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:43.111 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:43.113 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:44.364 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:57:44.364 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 3(Integer), 34(Integer)
12:57:44.366 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:44.367 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 3(Integer), 34(Integer)
12:57:44.369 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:44.927 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? 
12:57:44.927 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 1(Integer), 34(Integer)
12:57:44.929 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.parking_lot = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:44.932 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 1(Integer), 34(Integer)
12:57:44.936 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:47.860 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:57:47.861 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:47.864 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
12:57:47.868 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:47.868 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:57:47.871 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
12:57:47.871 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - ==> Parameters: 29(String), 34(Integer)
12:57:47.874 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.inputList - <==      Total: 0
12:57:52.045 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
12:57:52.051 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 29(String), 34(Integer)
12:57:52.052 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 0
12:57:52.055 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
12:57:52.056 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:52.058 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) 
12:57:52.061 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 34(String)
12:57:52.063 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 0
12:57:52.418 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:57:52.419 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:52.420 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc 
12:57:52.423 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 34(Integer), 34(Integer)
12:57:52.425 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 0
12:57:53.195 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:57:53.195 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:57:53.197 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:57:53.200 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:57:53.205 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
12:58:12.053 zt-spark [http-nio-9201-exec-5] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:12","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"5","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:12.054 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:12.057 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 5(Integer)
12:58:12.098 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:12.127 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:12.127 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:12.129 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:12.132 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:12.135 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
12:58:12.980 zt-spark [http-nio-9201-exec-6] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:12","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"1","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:12.981 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:12.984 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 1(Integer)
12:58:13.014 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:13.041 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:13.041 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:13.044 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:13.046 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:13.049 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 20
12:58:14.094 zt-spark [http-nio-9201-exec-10] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:14","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"2","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:14.095 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:14.097 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 2(Integer)
12:58:14.114 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:14.141 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:14.142 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:14.143 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:14.146 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:14.148 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 19
12:58:14.841 zt-spark [http-nio-9201-exec-2] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:14","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"36","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:14.842 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:14.844 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 36(Integer)
12:58:14.872 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:14.898 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:14.898 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:14.900 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:14.901 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:14.905 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 18
12:58:15.434 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:15","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"37","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:15.435 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:15.438 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 37(Integer)
12:58:15.472 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:15.498 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:15.498 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:15.500 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:15.501 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:15.504 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 17
12:58:16.289 zt-spark [http-nio-9201-exec-5] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:16","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"38","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:16.290 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:16.294 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 38(Integer)
12:58:16.314 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:16.344 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:16.344 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:16.346 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:16.348 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:16.350 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 16
12:58:16.970 zt-spark [http-nio-9201-exec-6] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:16","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"39","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:16.970 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:16.973 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 39(Integer)
12:58:17.005 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:17.038 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:17.039 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:17.041 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:17.045 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:17.048 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 15
12:58:17.657 zt-spark [http-nio-9201-exec-10] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:17","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"40","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:17.657 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:17.659 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 40(Integer)
12:58:17.689 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:17.724 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:17.724 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:17.726 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:17.729 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:17.731 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 14
12:58:18.949 zt-spark [http-nio-9201-exec-2] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:18","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"41","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:18.949 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:18.951 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 41(Integer)
12:58:18.980 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:19.007 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:19.007 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:19.009 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:19.011 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:19.013 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 13
12:58:20.951 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:20","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"42","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:20.951 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:20.954 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 42(Integer)
12:58:20.980 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:21.009 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:21.009 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:21.011 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:21.014 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:21.016 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 12
12:58:22.752 zt-spark [http-nio-9201-exec-5] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:22","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"43","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:22.753 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:22.755 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 43(Integer)
12:58:22.777 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:22.800 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:22.800 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:22.802 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:22.804 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:22.806 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 11
12:58:23.412 zt-spark [http-nio-9201-exec-6] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:23","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"44","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:23.412 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:23.414 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 44(Integer)
12:58:23.452 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:23.477 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:23.477 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:23.479 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:23.482 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:23.484 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 10
12:58:28.600 zt-spark [http-nio-9201-exec-10] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:28","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"45","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:28.601 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:28.604 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 45(Integer)
12:58:28.660 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:28.686 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:28.686 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:28.689 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:28.693 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:28.695 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 9
12:58:30.110 zt-spark [http-nio-9201-exec-2] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:30","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"46","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:30.111 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:30.114 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 46(Integer)
12:58:30.160 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:30.184 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:30.184 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:30.185 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:30.187 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:30.189 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 8
12:58:31.674 zt-spark [http-nio-9201-exec-3] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:31","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"66","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:31.674 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:31.678 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 66(Integer)
12:58:31.734 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:31.760 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:31.761 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:31.762 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:31.764 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:31.766 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 7
12:58:50.438 zt-spark [http-nio-9201-exec-5] INFO  c.z.z.c.CompanyWorkController - es_begin:{"address":"","logDate":"2020-09-11 12:58:50","methods":"DELETE","ip":"","originalSql":"","userAgent":"","userName":"fangjin","params":"67","serviceName":"","userId":"182","sqlCommandType":"","url":"/companywork/delete","userDeptId":"1","userEmpNo":"sss","tag":"spark_OPERATE"}es_end!
12:58:50.439 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==>  Preparing: update zt_company_work set del_flag = 0 where work_id = ? 
12:58:50.441 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - ==> Parameters: 67(Integer)
12:58:50.481 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.deleteCompanyWorkById - <==    Updates: 1
12:58:50.507 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:58:50.507 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:50.508 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:58:50.511 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:58:50.513 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 6
12:59:07.611 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: SELECT COUNT(1) FROM zt_company_people AS p LEFT JOIN sys_user AS u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ AS ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ AS so ON so.service_id = p.company WHERE p.del_flag = 1 AND p.com_id = ? AND p.com_id = ? 
12:59:07.611 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:59:07.613 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==>  Preparing: select p.id, so.service_name com_name, ao.`name` organ_name, p.company, p.parking_lot, p.user_name, p.`name`, p.tel, p.department, p.avatar, p.remark, p.lng, p.lat, p.login_time, p.last_login_date, p.code, p.is_duty, p.create_time, u.user_realname as create_name from zt_company_people as p LEFT JOIN sys_user as u ON u.user_id = p.create_by LEFT JOIN sys_administrative_organ as ao ON ao.organ_id = p.parking_lot LEFT JOIN sys_service_organ as so ON so.service_id = p.company where p.del_flag = 1 and p.com_id = ? AND p.com_id = ? ORDER BY p.is_duty desc LIMIT 0,30 
12:59:07.615 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - ==> Parameters: 33(Integer), 33(Integer)
12:59:07.618 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyPeopleListByComId - <==      Total: 8
12:59:08.529 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
12:59:08.529 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:59:08.531 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
12:59:08.533 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
12:59:08.535 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 6
12:59:10.404 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
12:59:10.404 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
12:59:10.406 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
12:59:10.408 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
12:59:10.410 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
13:00:23.435 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:05:23.459 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:07:56.864 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
13:07:56.864 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
13:07:56.866 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
13:07:56.868 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
13:07:56.870 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 6
13:08:57.578 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
13:08:57.579 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
13:08:57.579 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:08:57.581 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
13:08:57.581 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
13:08:57.584 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.inputList - <==      Total: 3
13:08:57.585 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:08:57.588 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:09:01.476 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
13:09:01.478 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
13:09:01.481 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
13:09:04.235 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
13:09:04.235 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
13:09:04.236 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
13:09:04.238 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
13:09:04.241 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
13:09:04.935 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_work AS cw LEFT JOIN zt_company_people AS cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 
13:09:04.935 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
13:09:04.937 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==>  Preparing: SELECT cw.* FROM zt_company_work as cw LEFT JOIN zt_company_people as cp ON cw.people_id = cp.id WHERE cp.del_flag = 1 AND cw.del_flag = 1 ORDER BY cw.work_start_time desc LIMIT 0,20 
13:09:04.938 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - ==> Parameters: 
13:09:04.940 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyWorkListByLike - <==      Total: 6
13:09:06.552 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
13:09:06.552 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:09:06.555 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
13:09:06.558 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:09:06.561 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:09:06.561 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 and parking_lot = ? and com_id = ? order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
13:09:06.564 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - ==> Parameters: 28(String), 33(Integer)
13:09:06.566 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.inputList - <==      Total: 3
13:10:23.483 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:14:44.361 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND people.name LIKE '%多%' 
13:14:44.361 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:44.363 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND people.name like '%多%' LIMIT 0,30 
13:14:44.366 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:44.369 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
13:14:50.182 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND people.name LIKE '%多%' 
13:14:50.183 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:50.184 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND people.name like '%多%' LIMIT 0,30 
13:14:50.186 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:50.189 zt-spark [http-nio-9201-exec-4] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
13:14:50.887 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND people.name LIKE '%多%' 
13:14:50.887 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:50.890 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND people.name like '%多%' LIMIT 0,30 
13:14:50.891 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:50.894 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
13:14:51.190 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND people.name LIKE '%多%' 
13:14:51.191 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:51.193 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND people.name like '%多%' LIMIT 0,30 
13:14:51.195 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:51.197 zt-spark [http-nio-9201-exec-5] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
13:14:57.957 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND people.name LIKE '%多%' 
13:14:57.958 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:57.960 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) AND people.name like '%多%' LIMIT 0,30 
13:14:57.963 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:14:57.965 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 2
13:15:16.175 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) 
13:15:16.175 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:15:16.177 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) LIMIT 0,30 
13:15:16.179 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String)
13:15:16.182 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:15:21.575 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND DATE_FORMAT(d.start_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.end_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
13:15:21.577 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-10 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp)
13:15:21.579 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) and DATE_FORMAT(d.start_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.end_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,30 
13:15:21.582 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-10 00:00:00.0(Timestamp), 2020-09-11 00:00:00.0(Timestamp)
13:15:21.585 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 4
13:15:23.507 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:15:27.661 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND DATE_FORMAT(d.start_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.end_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
13:15:27.662 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-10 00:00:00.0(Timestamp), 2020-10-22 00:00:00.0(Timestamp)
13:15:27.665 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) and DATE_FORMAT(d.start_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.end_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,30 
13:15:27.668 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-10 00:00:00.0(Timestamp), 2020-10-22 00:00:00.0(Timestamp)
13:15:27.671 zt-spark [http-nio-9201-exec-10] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:15:34.448 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 AND d.com_id IN (?) AND DATE_FORMAT(d.start_time, '%Y-%m-%d') >= DATE_FORMAT(?, '%Y-%m-%d') AND DATE_FORMAT(d.end_time, '%Y-%m-%d') <= DATE_FORMAT(?, '%Y-%m-%d') 
13:15:34.448 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-11 00:00:00.0(Timestamp), 2020-10-17 00:00:00.0(Timestamp)
13:15:34.450 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.com_id in ( ? ) and DATE_FORMAT(d.start_time,'%Y-%m-%d') >= DATE_FORMAT(?,'%Y-%m-%d') AND DATE_FORMAT(d.end_time,'%Y-%m-%d') <= DATE_FORMAT(?,'%Y-%m-%d') LIMIT 0,30 
13:15:34.452 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 33(String), 2020-09-11 00:00:00.0(Timestamp), 2020-10-17 00:00:00.0(Timestamp)
13:15:34.455 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 3
13:19:35.593 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
13:19:35.595 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
13:19:35.597 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
13:25:13.364 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5cc87d4c: startup date [Fri Sep 11 13:25:13 CST 2020]; root of context hierarchy
13:25:13.580 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:25:13.606 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$e4f0f468] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:13.836 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
13:25:13.876 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
13:25:14.090 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
13:25:14.090 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
13:25:14.165 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
13:25:14.165 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
13:25:14.346 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
13:25:14.434 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:25:14.550 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
13:25:14.552 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
13:25:14.554 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599801914554 with initial instances count: 4
13:25:14.783 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
13:25:15.001 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
13:25:15.001 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
13:25:15.036 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
13:25:15.054 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6f17a9e5: startup date [Fri Sep 11 13:25:15 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5cc87d4c
13:25:15.928 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
13:25:16.210 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:25:16.608 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=b246c794-5a41-3cd3-bed8-007b1c78fae9
13:25:16.641 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:25:16.751 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c8d6f16b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.888 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$6184b9a5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.896 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.901 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@123abc7f' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.910 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$86595c57] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.919 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:16.942 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$e4f0f468] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:25:17.405 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
13:25:17.415 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
13:25:17.424 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
13:25:17.424 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
13:25:17.427 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
13:25:17.672 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
13:25:17.676 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
13:25:17.676 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2622 ms
13:25:17.866 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:25:17.866 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:25:17.874 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@116c278c
13:25:18.090 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
13:25:18.257 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
13:25:19.305 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
13:25:19.305 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
13:25:19.305 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
13:25:19.305 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
13:25:19.305 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
13:25:19.306 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
13:25:19.306 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
13:25:19.306 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
13:25:19.306 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
13:25:19.307 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
13:25:19.307 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
13:25:19.308 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
13:25:21.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
13:25:21.063 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
13:25:21.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
13:25:21.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
13:25:21.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.064 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
13:25:21.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
13:25:21.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
13:25:21.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
13:25:21.066 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
13:25:21.067 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.067 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
13:25:21.067 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.069 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
13:25:21.070 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
13:25:21.070 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
13:25:21.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
13:25:21.071 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
13:25:21.072 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
13:25:21.072 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
13:25:21.072 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
13:25:21.072 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
13:25:21.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
13:25:21.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
13:25:21.075 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
13:25:21.076 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
13:25:21.077 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
13:25:21.077 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
13:25:21.078 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
13:25:21.080 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
13:25:21.081 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
13:25:21.082 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
13:25:21.084 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
13:25:21.084 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
13:25:21.201 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
13:25:21.212 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.213 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.213 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.213 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.213 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.213 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.214 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.215 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.216 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
13:25:21.217 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
13:25:21.496 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
13:25:21.553 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:25:21.553 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:25:21.673 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:25:21.762 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6f17a9e5: startup date [Fri Sep 11 13:25:15 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5cc87d4c
13:25:21.818 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:25:21.818 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:25:22.529 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
13:25:22.537 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
13:25:22.538 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
13:25:22.538 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
13:25:22.539 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

13:25:22.539 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
13:25:22.539 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
13:25:22.539 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@3b111859
13:25:22.606 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: b4b6f4bf-935c-412d-ae4d-487649b799e3

13:25:22.741 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@6b515b35, org.springframework.security.web.context.SecurityContextPersistenceFilter@7231c77a, org.springframework.security.web.header.HeaderWriterFilter@3e269b3b, org.springframework.security.web.authentication.logout.LogoutFilter@6a26eb1f, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2b007997, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@53968da, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4ee2e7d8, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3a90f30a, org.springframework.security.web.session.SessionManagementFilter@78bc1dd1, org.springframework.security.web.access.ExceptionTranslationFilter@2dffc48a, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@45f5b6b8]
13:25:23.097 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
13:25:23.280 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
13:25:23.286 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
13:25:23.427 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
13:25:23.429 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
13:25:23.429 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
13:25:23.438 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
13:25:23.440 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
13:25:23.440 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
13:25:23.444 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
13:25:23.452 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
13:25:23.463 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6f17a9e5,type=ConfigurationPropertiesRebinder]
13:25:23.468 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
13:25:23.470 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
13:25:23.489 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
13:25:23.503 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
13:25:23.506 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
13:25:23.507 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
13:25:23.507 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
13:25:23.507 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
13:25:23.507 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
13:25:23.585 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:25:23.585 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
13:25:23.585 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:25:23.585 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:25:23.586 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
13:25:23.586 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:25:23.586 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
13:25:23.586 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:25:23.589 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
13:25:23.590 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
13:25:23.591 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
13:25:23.592 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599801923592 with initial instances count: 4
13:25:23.599 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
13:25:23.600 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599801923600, current=UP, previous=STARTING]
13:25:23.601 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
13:25:23.603 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
13:25:23.604 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
13:25:23.615 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
13:25:23.624 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
13:25:23.650 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
13:25:23.759 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
13:25:23.760 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
13:25:23.762 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
13:25:23.770 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
13:25:23.772 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
13:25:23.775 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
13:25:23.776 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
13:25:23.777 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
13:25:23.787 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
13:25:23.796 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
13:25:23.798 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
13:25:23.799 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
13:25:23.801 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
13:25:23.802 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
13:25:23.804 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
13:25:23.805 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
13:25:23.810 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
13:25:23.811 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
13:25:23.812 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
13:25:23.844 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
13:25:23.844 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
13:25:23.865 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
13:25:23.876 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
13:25:23.886 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
13:25:23.920 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
13:25:23.922 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
13:25:23.925 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.331 seconds (JVM running for 12.467)
13:25:24.056 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
13:25:24.056 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
13:25:24.073 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
13:25:24.083 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 27 ms
13:25:24.227 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
13:25:24.292 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
13:25:24.293 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
13:26:41.298 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_file WHERE del_flag = 1 
13:26:41.310 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
13:26:41.317 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==>  Preparing: select id, document_name, signing_party, signing_time, code, termination_time, cooperation_mode, `leading`, tel, create_time, remark from zt_company_file where del_flag = 1 ORDER BY create_time desc LIMIT 0,30 
13:26:41.323 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyFileListByLike - ==> Parameters: 
13:26:41.331 zt-spark [http-nio-9201-exec-1] DEBUG c.z.z.m.C.selectCompanyFileListByLike - <==      Total: 9
13:26:43.887 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
13:26:43.890 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
13:26:43.900 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.inputList - <==      Total: 21
13:26:43.916 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
13:26:43.916 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:26:43.918 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
13:26:43.920 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:26:43.926 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:28:08.887 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
13:28:08.890 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
13:28:08.893 zt-spark [http-nio-9201-exec-6] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
13:28:36.118 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
13:28:36.119 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:28:36.121 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
13:28:36.123 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:28:36.124 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
13:28:36.127 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
13:28:36.129 zt-spark [http-nio-9201-exec-7] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:28:36.133 zt-spark [http-nio-9201-exec-8] DEBUG c.z.z.m.C.inputList - <==      Total: 21
13:28:37.833 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 and d.id = ? 
13:28:37.835 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - ==> Parameters: 17(Integer)
13:28:37.839 zt-spark [http-nio-9201-exec-9] DEBUG c.z.z.m.C.selectCompanyDutyById - <==      Total: 2
13:30:23.610 zt-spark [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:32:52.185 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: SELECT COUNT(1) FROM zt_company_duty d LEFT JOIN sys_administrative_organ organ ON organ.organ_id = d.organ_id LEFT JOIN zt_dutyid_peopleid dupeo ON dupeo.duty_id = d.id LEFT JOIN zt_company_people people ON people.id = dupeo.people_id LEFT JOIN zt_dutyid_peopleid_task dupeotask ON dupeotask.duty_people_id = dupeo.duty_people_id AND dupeotask.company_duty_id = d.id LEFT JOIN point_duty_job dutyjob ON dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user AS u ON d.create_by = u.user_id WHERE d.del_flag = 1 
13:32:52.186 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:32:52.188 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==>  Preparing: select d.id, d.duty_type, organ.name organName, d.organ_id, d.start_time, d.end_time, d.task_flag, d.task_description, d.com_id, d.duty_status, d.create_time, u.user_realname as createName, u.phone as createPhone, u.company_id, dupeo.duty_people_id, dupeo.duty_id, people.name people_name, people.tel peoplePhone, dupeo.duty_start_time, dupeo.duty_end_time, dupeo.people_id, dutyjob.equipment_name, dutyjob.equipment_num, dutyjob.id duty_job_id from zt_company_duty d left join sys_administrative_organ organ on organ.organ_id = d.organ_id left join zt_dutyid_peopleid dupeo on dupeo.duty_id = d.id left join zt_company_people people on people.id = dupeo.people_id left join zt_dutyid_peopleid_task dupeotask on dupeotask.duty_people_id = dupeo.duty_people_id and dupeotask.company_duty_id = d.id left join point_duty_job dutyjob on dutyjob.id = dupeotask.point_duty_job_id LEFT JOIN sys_user as u ON d.create_by = u.user_id where d.del_flag = 1 LIMIT 0,30 
13:32:52.190 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - ==> Parameters: 
13:32:52.195 zt-spark [http-nio-9201-exec-3] DEBUG c.z.z.m.C.selectCompanyDutyListByLike - <==      Total: 5
13:32:52.219 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==>  Preparing: SELECT * FROM zt_company_people WHERE 1=1 order by convert( `name` using gbk ) collate gbk_chinese_ci asc 
13:32:52.221 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - ==> Parameters: 
13:32:52.227 zt-spark [http-nio-9201-exec-2] DEBUG c.z.z.m.C.inputList - <==      Total: 21
14:01:05.898 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@49562e03: startup date [Fri Sep 11 14:01:05 CST 2020]; root of context hierarchy
14:01:06.328 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:01:06.370 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9c049b65] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:06.804 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:01:06.879 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:01:07.205 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:01:07.205 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:01:07.314 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:01:07.314 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:01:07.599 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:01:07.695 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:01:07.866 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:01:07.869 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
14:01:07.874 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804067873 with initial instances count: 4
14:01:08.322 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:01:08.539 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:01:08.539 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
14:01:08.544 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
14:01:08.561 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@327bbd12: startup date [Fri Sep 11 14:01:08 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@49562e03
14:01:09.793 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
14:01:10.155 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
14:01:10.666 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
14:01:10.715 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:01:10.858 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$7fea9868] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.033 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$189860a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.044 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.049 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@611266be' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.054 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$3d6d0354] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.065 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.093 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9c049b65] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:11.638 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
14:01:11.650 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
14:01:11.659 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
14:01:11.659 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
14:01:11.663 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
14:01:11.941 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
14:01:11.943 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
14:01:11.944 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3383 ms
14:01:12.181 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:01:12.181 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:01:12.190 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@40dfc46c
14:01:12.412 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
14:01:12.604 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
14:01:13.839 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
14:01:13.839 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
14:01:13.839 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
14:01:13.839 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
14:01:13.839 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
14:01:13.840 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
14:01:13.840 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
14:01:13.840 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
14:01:13.840 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
14:01:13.841 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
14:01:13.842 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
14:01:13.842 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
14:01:15.962 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
14:01:15.962 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
14:01:15.963 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.963 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
14:01:15.963 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
14:01:15.964 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:15.964 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.965 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
14:01:15.965 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
14:01:15.966 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
14:01:15.966 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
14:01:15.966 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:15.966 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:15.967 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.968 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
14:01:15.968 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
14:01:15.968 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
14:01:15.969 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
14:01:15.969 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:15.969 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:15.969 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.969 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.970 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
14:01:15.971 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
14:01:15.971 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
14:01:15.971 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
14:01:15.971 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:15.972 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:15.972 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:15.975 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
14:01:15.975 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:01:15.976 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
14:01:15.977 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
14:01:15.977 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
14:01:15.977 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
14:01:15.977 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
14:01:15.979 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
14:01:15.982 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
14:01:15.982 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
14:01:15.983 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
14:01:15.985 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
14:01:15.985 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:01:16.123 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
14:01:16.140 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.141 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.141 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.142 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.143 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.144 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.145 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.145 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.145 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.145 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:16.146 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:01:16.563 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
14:01:16.644 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:01:16.644 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:01:16.824 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:16.978 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@327bbd12: startup date [Fri Sep 11 14:01:08 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@49562e03
14:01:17.058 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:17.058 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:18.059 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
14:01:18.133 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
14:01:18.133 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
14:01:18.135 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
14:01:18.137 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

14:01:18.137 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
14:01:18.137 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
14:01:18.139 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@545fceb1
14:01:18.286 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 459db41e-de1b-475d-80fa-22ddc87bd337

14:01:18.522 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@271e5ae8, org.springframework.security.web.context.SecurityContextPersistenceFilter@5d940ccd, org.springframework.security.web.header.HeaderWriterFilter@79a31841, org.springframework.security.web.authentication.logout.LogoutFilter@646019d1, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2fef77c6, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2ca9e00b, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4e3322af, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@39cc4150, org.springframework.security.web.session.SessionManagementFilter@6809a5a5, org.springframework.security.web.access.ExceptionTranslationFilter@23d44edd, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@dfa250e]
14:01:18.654 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
14:01:18.858 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
14:01:18.862 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
14:01:19.009 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
14:01:19.011 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
14:01:19.011 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
14:01:19.021 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
14:01:19.022 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
14:01:19.023 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
14:01:19.026 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
14:01:19.034 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
14:01:19.046 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=327bbd12,type=ConfigurationPropertiesRebinder]
14:01:19.052 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
14:01:19.054 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
14:01:19.072 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
14:01:19.086 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:01:19.089 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:01:19.090 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:01:19.090 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:01:19.090 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:01:19.091 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:01:19.167 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:01:19.168 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:01:19.171 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:01:19.172 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
14:01:19.174 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
14:01:19.175 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804079175 with initial instances count: 4
14:01:19.183 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
14:01:19.183 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599804079183, current=UP, previous=STARTING]
14:01:19.185 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:01:19.187 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
14:01:19.187 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
14:01:19.200 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
14:01:19.215 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:01:19.250 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
14:01:19.375 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
14:01:19.376 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
14:01:19.378 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
14:01:19.388 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
14:01:19.390 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
14:01:19.392 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
14:01:19.393 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
14:01:19.394 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
14:01:19.410 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
14:01:19.417 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
14:01:19.418 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
14:01:19.420 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
14:01:19.423 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
14:01:19.424 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
14:01:19.426 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
14:01:19.428 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
14:01:19.434 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
14:01:19.435 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
14:01:19.437 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
14:01:19.463 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
14:01:19.463 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
14:01:19.481 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
14:01:19.488 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
14:01:19.496 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
14:01:19.520 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
14:01:19.521 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
14:01:19.524 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 14.725 seconds (JVM running for 16.382)
14:01:20.169 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
14:01:20.169 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
14:01:20.185 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:01:20.196 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 27 ms
14:01:20.347 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:01:20.445 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
14:01:20.449 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
14:01:44.037 zt-spark [Thread-45] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@327bbd12: startup date [Fri Sep 11 14:01:08 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@49562e03
14:01:44.039 zt-spark [Thread-45] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application zt-spark with eureka with status DOWN
14:01:44.039 zt-spark [Thread-45] WARN  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599804104039, current=DOWN, previous=UP]
14:01:44.039 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:01:44.042 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:01:44.042 zt-spark [Thread-45] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
14:01:44.043 zt-spark [Thread-45] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
14:01:44.044 zt-spark [Thread-45] INFO  o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 0
14:01:44.046 zt-spark [Thread-45] INFO  o.s.s.quartz.SchedulerFactoryBean - Shutting down Quartz Scheduler
14:01:44.046 zt-spark [Thread-45] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.
14:01:44.046 zt-spark [Thread-45] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED paused.
14:01:44.047 zt-spark [Thread-45] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.
14:01:44.048 zt-spark [Thread-45] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
14:01:44.048 zt-spark [Thread-45] INFO  o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans
14:01:48.311 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@182de71c: startup date [Fri Sep 11 14:01:48 CST 2020]; root of context hierarchy
14:01:48.545 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:01:48.572 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9d35afb6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:48.814 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:01:48.851 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:01:49.065 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:01:49.065 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:01:49.134 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:01:49.134 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:01:49.292 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:01:49.383 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:01:49.500 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:01:49.503 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
14:01:49.505 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804109505 with initial instances count: 5
14:01:49.737 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:01:49.957 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:01:49.957 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
14:01:49.960 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
14:01:49.974 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3928bfec: startup date [Fri Sep 11 14:01:49 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@182de71c
14:01:50.853 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
14:01:51.119 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
14:01:51.513 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
14:01:51.553 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:01:51.682 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$811bacb9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.819 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$19c974f3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.828 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.832 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@1405cc73' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.836 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$3e9e17a5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.845 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:51.868 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9d35afb6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:01:52.328 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
14:01:52.338 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
14:01:52.347 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
14:01:52.347 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
14:01:52.350 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
14:01:52.599 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
14:01:52.603 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
14:01:52.603 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2629 ms
14:01:52.788 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:01:52.788 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:01:52.795 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@37c4d43
14:01:52.981 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
14:01:53.152 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
14:01:54.237 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
14:01:54.237 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
14:01:54.238 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
14:01:54.239 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
14:01:54.239 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
14:01:54.240 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
14:01:54.240 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
14:01:55.904 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
14:01:55.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
14:01:55.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
14:01:55.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
14:01:55.905 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.906 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.907 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:55.908 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:55.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
14:01:55.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
14:01:55.909 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
14:01:55.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
14:01:55.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:55.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:55.910 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.911 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:01:55.912 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:01:55.915 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:01:55.915 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
14:01:55.915 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:01:55.916 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
14:01:55.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
14:01:55.917 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
14:01:55.918 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
14:01:55.920 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
14:01:55.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
14:01:55.921 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
14:01:55.923 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
14:01:55.924 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:01:56.024 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
14:01:56.035 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.036 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.037 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.037 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.037 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.037 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.037 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.038 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.039 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:01:56.040 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:01:56.315 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
14:01:56.372 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:01:56.372 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:01:56.489 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:56.580 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3928bfec: startup date [Fri Sep 11 14:01:49 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@182de71c
14:01:56.636 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:56.636 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:01:57.340 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
14:01:57.348 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
14:01:57.348 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
14:01:57.349 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
14:01:57.349 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

14:01:57.349 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
14:01:57.349 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
14:01:57.349 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@1ee768e9
14:01:57.413 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 9c3bad1a-3451-4e3a-91f7-92b287a557e6

14:01:57.540 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@3a09d1bb, org.springframework.security.web.context.SecurityContextPersistenceFilter@2295baf5, org.springframework.security.web.header.HeaderWriterFilter@5d9fa910, org.springframework.security.web.authentication.logout.LogoutFilter@21bc15b5, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@432d89f2, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1ab6437d, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5a15aa18, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@76201c5, org.springframework.security.web.session.SessionManagementFilter@762b70cb, org.springframework.security.web.access.ExceptionTranslationFilter@4598d32, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@5694c922]
14:01:57.655 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
14:01:57.823 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
14:01:57.829 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
14:01:57.952 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
14:01:57.953 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
14:01:57.953 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
14:01:57.960 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
14:01:57.961 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
14:01:57.962 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
14:01:57.966 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
14:01:57.973 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
14:01:57.982 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3928bfec,type=ConfigurationPropertiesRebinder]
14:01:57.987 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
14:01:57.988 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
14:01:58.005 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
14:01:58.017 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:01:58.020 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:01:58.021 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:01:58.021 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:01:58.021 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:01:58.021 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:01:58.062 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:01:58.062 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:01:58.063 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:01:58.066 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:01:58.067 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
14:01:58.068 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
14:01:58.069 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804118069 with initial instances count: 5
14:01:58.077 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
14:01:58.077 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599804118077, current=UP, previous=STARTING]
14:01:58.078 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:01:58.080 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
14:01:58.081 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
14:01:58.092 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
14:01:58.101 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:01:58.124 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
14:01:58.217 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
14:01:58.218 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
14:01:58.219 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
14:01:58.224 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
14:01:58.226 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
14:01:58.228 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
14:01:58.229 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
14:01:58.230 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
14:01:58.238 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
14:01:58.246 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
14:01:58.247 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
14:01:58.248 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
14:01:58.249 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
14:01:58.250 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
14:01:58.251 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
14:01:58.252 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
14:01:58.256 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
14:01:58.257 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
14:01:58.258 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
14:01:58.280 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
14:01:58.280 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
14:01:58.294 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
14:01:58.301 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
14:01:58.309 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
14:01:58.329 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
14:01:58.330 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
14:01:58.332 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 10.766 seconds (JVM running for 11.617)
14:01:58.712 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
14:01:58.712 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
14:01:58.726 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:01:58.733 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
14:01:58.891 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:01:58.980 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
14:01:58.981 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
14:02:05.918 zt-spark [http-nio-9201-exec-2] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$null$2(CompanyDutyServiceImpl.java:120)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$null$3(CompanyDutyServiceImpl.java:119)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$selectCompanyDutyListByLike$4(CompanyDutyServiceImpl.java:112)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectCompanyDutyListByLike(CompanyDutyServiceImpl.java:103)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$7a821723.selectCompanyDutyListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.page(CompanyDutyController.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
14:03:24.586 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@d6cb2b: startup date [Fri Sep 11 14:03:24 CST 2020]; root of context hierarchy
14:03:24.796 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:03:24.824 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$94c96276] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:25.061 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:03:25.099 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:03:25.319 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:03:25.320 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:03:25.395 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:03:25.395 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:03:25.572 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:03:25.659 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:03:25.660 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:03:25.772 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:03:25.775 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
14:03:25.779 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804205778 with initial instances count: 5
14:03:26.013 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:03:26.227 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:03:26.227 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
14:03:26.231 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
14:03:26.246 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3a67f9b6: startup date [Fri Sep 11 14:03:26 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@d6cb2b
14:03:27.121 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
14:03:27.415 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
14:03:27.797 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
14:03:27.829 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:03:27.941 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$78af5f79] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.078 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$115d27b3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.086 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.091 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@39161a57' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.095 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$3631ca65] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.104 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.126 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$94c96276] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:03:28.613 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
14:03:28.623 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
14:03:28.631 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
14:03:28.632 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
14:03:28.635 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
14:03:28.862 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
14:03:28.865 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
14:03:28.865 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2619 ms
14:03:29.052 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:03:29.052 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:03:29.058 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@7cfe990d
14:03:29.245 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
14:03:29.414 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
14:03:30.511 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
14:03:30.511 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
14:03:30.511 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
14:03:30.511 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
14:03:30.511 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
14:03:30.512 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
14:03:30.512 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
14:03:30.512 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
14:03:30.512 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
14:03:30.513 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
14:03:30.513 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
14:03:30.513 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
14:03:32.273 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
14:03:32.273 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
14:03:32.274 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.274 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
14:03:32.274 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
14:03:32.274 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.274 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:03:32.275 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
14:03:32.276 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
14:03:32.276 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
14:03:32.276 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
14:03:32.276 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.276 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:03:32.277 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:03:32.278 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
14:03:32.278 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
14:03:32.278 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
14:03:32.278 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
14:03:32.279 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.279 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:03:32.279 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:03:32.279 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.280 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:03:32.281 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:03:32.284 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
14:03:32.285 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
14:03:32.286 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
14:03:32.286 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:03:32.286 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
14:03:32.286 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
14:03:32.286 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
14:03:32.288 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
14:03:32.290 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
14:03:32.290 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
14:03:32.291 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
14:03:32.293 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
14:03:32.293 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:03:32.411 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
14:03:32.425 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.426 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.427 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.428 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.429 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.429 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.429 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:03:32.430 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:03:32.873 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
14:03:32.989 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:03:32.989 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:03:33.166 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:03:33.299 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@3a67f9b6: startup date [Fri Sep 11 14:03:26 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@d6cb2b
14:03:33.370 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:03:33.370 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:03:34.251 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
14:03:34.259 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
14:03:34.259 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
14:03:34.260 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
14:03:34.261 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

14:03:34.261 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
14:03:34.261 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
14:03:34.261 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@86c3dab
14:03:34.366 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 1a3e4c03-bf57-4126-b03c-627d447246c8

14:03:34.634 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@25688d8d, org.springframework.security.web.context.SecurityContextPersistenceFilter@262f1d05, org.springframework.security.web.header.HeaderWriterFilter@57d57220, org.springframework.security.web.authentication.logout.LogoutFilter@4d8b0da, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@2ae7ba14, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2f806bb3, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@ba39989, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5b963a2b, org.springframework.security.web.session.SessionManagementFilter@6c06c833, org.springframework.security.web.access.ExceptionTranslationFilter@2d7600cd, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@15107e43]
14:03:34.787 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
14:03:35.045 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
14:03:35.050 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
14:03:35.213 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
14:03:35.215 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
14:03:35.215 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
14:03:35.223 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
14:03:35.224 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
14:03:35.225 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
14:03:35.229 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
14:03:35.238 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
14:03:35.248 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3a67f9b6,type=ConfigurationPropertiesRebinder]
14:03:35.254 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
14:03:35.256 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
14:03:35.282 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
14:03:35.300 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:03:35.304 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:03:35.306 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:03:35.306 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:03:35.306 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:03:35.306 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:03:35.368 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:03:35.369 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:03:35.374 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:03:35.375 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
14:03:35.377 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
14:03:35.378 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804215378 with initial instances count: 5
14:03:35.388 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
14:03:35.388 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599804215388, current=UP, previous=STARTING]
14:03:35.390 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:03:35.392 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
14:03:35.393 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
14:03:35.407 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
14:03:35.420 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:03:35.442 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
14:03:35.540 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
14:03:35.541 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
14:03:35.542 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
14:03:35.548 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
14:03:35.549 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
14:03:35.552 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
14:03:35.553 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
14:03:35.554 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
14:03:35.562 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
14:03:35.570 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
14:03:35.571 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
14:03:35.572 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
14:03:35.573 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
14:03:35.574 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
14:03:35.575 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
14:03:35.576 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
14:03:35.579 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
14:03:35.580 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
14:03:35.581 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
14:03:35.607 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
14:03:35.607 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
14:03:35.622 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
14:03:35.630 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
14:03:35.638 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
14:03:35.659 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
14:03:35.660 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
14:03:35.662 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.819 seconds (JVM running for 12.65)
14:03:36.033 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:03:36.200 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
14:03:36.201 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
14:03:36.215 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:03:36.224 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 22 ms
14:03:36.296 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
14:03:36.297 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
14:04:54.973 zt-spark [http-nio-9201-exec-7] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$null$5(CompanyDutyServiceImpl.java:176)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$null$6(CompanyDutyServiceImpl.java:175)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.lambda$selectDutyPeopleListByLike$7(CompanyDutyServiceImpl.java:166)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl.selectDutyPeopleListByLike(CompanyDutyServiceImpl.java:162)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$FastClassBySpringCGLIB$$fdc8deb1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.CompanyDutyServiceImpl$$EnhancerBySpringCGLIB$$2f6a70cf.selectDutyPeopleListByLike(<generated>)
	at com.ztman.ztspark.controller.CompanyDutyController.list(CompanyDutyController.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
14:05:33.374 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@378ee755: startup date [Fri Sep 11 14:05:33 CST 2020]; root of context hierarchy
14:05:33.792 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:05:33.825 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$5a69daa1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:34.157 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:05:34.198 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:05:34.441 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:05:34.442 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:05:34.528 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:05:34.529 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:05:34.739 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:05:34.829 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:05:34.829 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:05:34.829 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:05:34.829 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:05:34.830 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:05:34.830 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:05:34.830 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:05:34.950 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:05:34.953 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
14:05:34.956 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804334955 with initial instances count: 5
14:05:35.190 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:05:35.423 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:05:35.423 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
14:05:35.427 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
14:05:35.443 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@10470487: startup date [Fri Sep 11 14:05:35 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@378ee755
14:05:36.366 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
14:05:36.654 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
14:05:37.064 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
14:05:37.096 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:05:37.210 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$3e4fd7a4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.356 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$d6fd9fde] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.365 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.370 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@71a54959' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.375 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$fbd24290] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.385 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.409 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$5a69daa1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:05:37.917 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
14:05:37.926 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
14:05:37.934 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
14:05:37.934 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
14:05:37.937 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
14:05:38.195 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
14:05:38.198 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
14:05:38.198 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2755 ms
14:05:38.388 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:05:38.388 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:05:38.394 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@2da09222
14:05:38.586 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
14:05:38.757 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
14:05:39.823 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
14:05:39.823 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
14:05:39.823 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
14:05:39.823 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
14:05:39.823 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
14:05:39.824 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
14:05:39.824 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
14:05:39.824 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
14:05:39.824 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
14:05:39.825 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
14:05:39.825 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
14:05:39.826 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
14:05:41.578 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
14:05:41.579 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
14:05:41.579 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.579 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
14:05:41.580 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
14:05:41.580 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.580 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:05:41.581 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
14:05:41.581 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
14:05:41.582 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
14:05:41.582 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
14:05:41.582 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.582 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:05:41.582 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:05:41.584 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
14:05:41.584 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
14:05:41.584 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
14:05:41.584 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
14:05:41.584 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.585 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:05:41.585 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:05:41.585 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.586 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
14:05:41.586 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
14:05:41.587 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
14:05:41.587 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
14:05:41.587 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:05:41.587 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:05:41.587 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:05:41.590 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
14:05:41.590 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
14:05:41.590 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
14:05:41.591 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
14:05:41.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
14:05:41.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
14:05:41.592 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
14:05:41.593 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
14:05:41.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
14:05:41.596 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
14:05:41.597 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
14:05:41.599 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
14:05:41.599 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:05:41.710 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
14:05:41.722 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.723 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.724 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.725 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.726 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.727 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:05:41.728 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:05:42.042 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
14:05:42.099 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:05:42.099 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:05:42.217 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:05:42.304 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@10470487: startup date [Fri Sep 11 14:05:35 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@378ee755
14:05:42.364 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:05:42.364 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:05:43.060 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
14:05:43.068 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
14:05:43.068 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
14:05:43.068 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
14:05:43.069 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

14:05:43.069 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
14:05:43.069 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
14:05:43.069 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@5801997d
14:05:43.135 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: 32416f86-a7d7-4703-9078-eb3f384f50bb

14:05:43.266 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@3be7508f, org.springframework.security.web.context.SecurityContextPersistenceFilter@73cd274a, org.springframework.security.web.header.HeaderWriterFilter@612232f0, org.springframework.security.web.authentication.logout.LogoutFilter@403c743, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@3050706d, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@307b4bf1, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@363b9c8b, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@6c334785, org.springframework.security.web.session.SessionManagementFilter@60e2ec84, org.springframework.security.web.access.ExceptionTranslationFilter@1b900815, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@89e8478]
14:05:43.384 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
14:05:43.552 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
14:05:43.558 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
14:05:43.680 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
14:05:43.681 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
14:05:43.681 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
14:05:43.689 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
14:05:43.690 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
14:05:43.691 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
14:05:43.694 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
14:05:43.701 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
14:05:43.711 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=10470487,type=ConfigurationPropertiesRebinder]
14:05:43.717 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
14:05:43.718 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
14:05:43.736 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
14:05:43.748 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:05:43.751 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:05:43.752 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:05:43.752 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:05:43.752 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:05:43.752 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:05:43.799 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:05:43.800 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:05:43.804 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:05:43.805 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
14:05:43.807 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
14:05:43.808 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599804343808 with initial instances count: 5
14:05:43.815 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
14:05:43.815 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599804343815, current=UP, previous=STARTING]
14:05:43.817 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:05:43.819 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
14:05:43.820 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
14:05:43.833 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
14:05:43.843 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:05:43.868 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
14:05:43.959 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
14:05:43.960 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
14:05:43.961 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
14:05:43.968 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
14:05:43.969 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
14:05:43.972 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
14:05:43.973 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
14:05:43.974 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
14:05:43.983 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
14:05:43.990 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
14:05:43.991 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
14:05:43.992 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
14:05:43.994 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
14:05:43.995 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
14:05:43.996 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
14:05:43.997 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
14:05:44.001 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
14:05:44.003 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
14:05:44.004 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
14:05:44.029 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
14:05:44.029 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
14:05:44.044 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
14:05:44.052 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
14:05:44.060 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
14:05:44.083 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
14:05:44.084 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
14:05:44.087 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 11.942 seconds (JVM running for 13.11)
14:05:44.352 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
14:05:44.352 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
14:05:44.366 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:05:44.374 zt-spark [RMI TCP Connection(3)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
14:05:44.522 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:05:44.649 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
14:05:44.651 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
14:39:57.432 zt-spark [restartedMain] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@3b0dc9f4: startup date [Fri Sep 11 14:39:57 CST 2020]; root of context hierarchy
14:39:57.666 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:39:57.697 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9a67cca0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:39:57.942 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:39:57.986 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:39:58.227 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:39:58.227 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:39:58.307 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:39:58.307 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:39:58.504 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:39:58.593 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:39:58.594 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:39:58.713 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:39:58.716 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Not registering with Eureka server per configuration
14:39:58.719 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599806398719 with initial instances count: 4
14:39:58.951 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:39:59.173 zt-spark [restartedMain] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:39:59.173 zt-spark [restartedMain] INFO  o.s.c.b.c.PropertySourceBootstrapConfiguration - Located property source: CompositePropertySource {name='configService', propertySources=[MapPropertySource {name='classpath:/config/zt-spark-dev.yml'}, MapPropertySource {name='classpath:/config/application-dev.yml'}]}
14:39:59.177 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - The following profiles are active: dev
14:39:59.192 zt-spark [restartedMain] INFO  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@293a3739: startup date [Fri Sep 11 14:39:59 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3b0dc9f4
14:40:00.085 zt-spark [restartedMain] INFO  o.s.b.f.s.DefaultListableBeanFactory - Overriding bean definition for bean 'websocketContainerCustomizer' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$UndertowWebSocketConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration; factoryMethodName=websocketContainerCustomizer; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/websocket/servlet/WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration.class]]
14:40:00.399 zt-spark [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
14:40:00.800 zt-spark [restartedMain] INFO  o.s.cloud.context.scope.GenericScope - BeanFactory id=e75a072a-735c-3e02-adbd-123f46bcdf70
14:40:00.833 zt-spark [restartedMain] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
14:40:00.943 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$7e4dc9a3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.086 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$16fb91dd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.094 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.099 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@45b063d0' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.103 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$3bd0348f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.112 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.137 zt-spark [restartedMain] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9a67cca0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
14:40:01.619 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9201 (http)
14:40:01.629 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9201"]
14:40:01.638 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
14:40:01.638 zt-spark [restartedMain] INFO  o.a.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.32
14:40:01.641 zt-spark [localhost-startStop-1] INFO  o.a.c.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\Program Files\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\Program Files\Git\cmd;D:\Program Files\Java\jdk1.8.0_221\bin;D:\Program Files\Java\jdk1.8.0_221\jre\bin;D:\Program Files\nodejs\;D:\Program Files\nodejs\node_global;C:\Users\Administrator\AppData\Roaming\npm;.]
14:40:01.990 zt-spark [localhost-startStop-1] INFO  org.apache.jasper.servlet.TldScanner - At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
14:40:01.994 zt-spark [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
14:40:01.994 zt-spark [localhost-startStop-1] INFO  o.s.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2802 ms
14:40:02.291 zt-spark [localhost-startStop-1] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:40:02.291 zt-spark [localhost-startStop-1] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:40:02.304 zt-spark [localhost-startStop-1] INFO  c.n.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@4b384a62
14:40:02.633 zt-spark [localhost-startStop-1] INFO  c.a.d.s.b.a.DruidDataSourceAutoConfigure - Init DruidDataSource
14:40:02.822 zt-spark [localhost-startStop-1] INFO  c.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
14:40:04.136 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
14:40:04.136 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webMvcMetricsFilter' to: [/*]
14:40:04.137 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
14:40:04.137 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
14:40:04.137 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
14:40:04.138 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.DelegatingFilterProxyRegistrationBean - Mapping filter: 'springSecurityFilterChain' to: [/*]
14:40:04.138 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'httpTraceFilter' to: [/*]
14:40:04.138 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
14:40:04.138 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
14:40:04.139 zt-spark [localhost-startStop-1] INFO  o.s.b.w.s.ServletRegistrationBean - Servlet statViewServlet mapped to [/druid/*]
14:40:04.141 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/jolokia' to jolokia-actuator-endpoint
14:40:04.142 zt-spark [localhost-startStop-1] INFO  o.s.b.a.e.w.ServletEndpointRegistrar - Registered '/actuator/hystrix.stream' to hystrix.stream-actuator-endpoint
14:40:06.124 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.update(com.ztman.ztspark.dto.CompanyDutyDTO)
14:40:06.125 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.delete(java.lang.Integer)
14:40:06.125 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/dutyPeople/list],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.list(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.125 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.save(com.ztman.ztspark.dto.CompanyDutyDTO)
14:40:06.126 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/page],methods=[POST]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyDutyController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.126 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyDutyController.info(java.lang.Integer)
14:40:06.126 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyduty/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyDutyController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:40:06.127 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.update(com.ztman.ztspark.entity.company.CompanyFile)
14:40:06.127 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.delete(java.lang.Integer)
14:40:06.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.save(com.ztman.ztspark.entity.company.CompanyFile)
14:40:06.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyFileController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyFileController.info(java.lang.Integer)
14:40:06.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyFileController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:40:06.128 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companyfile/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyFileController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:40:06.130 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.update(com.ztman.ztspark.entity.company.CompanyPeople)
14:40:06.130 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.delete(java.lang.Integer)
14:40:06.130 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.save(com.ztman.ztspark.entity.company.CompanyPeople)
14:40:06.130 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyPeopleController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.130 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyPeopleController.info(java.lang.Integer)
14:40:06.131 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:40:06.131 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyPeopleController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:40:06.131 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companypeople/inputList],methods=[GET]}" onto public java.util.List<com.ztman.ztspark.entity.company.CompanyPeople> com.ztman.ztspark.controller.CompanyPeopleController.inputList(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.132 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.update(com.ztman.ztspark.entity.company.CompanyWork)
14:40:06.132 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.delete(java.lang.Integer)
14:40:06.133 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork],methods=[POST]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.save(com.ztman.ztspark.entity.company.CompanyWork)
14:40:06.133 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/page],methods=[GET]}" onto public com.baomidou.mybatisplus.plugins.Page com.ztman.ztspark.controller.CompanyWorkController.page(java.util.Map<java.lang.String, java.lang.Object>)
14:40:06.133 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/{workId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.CompanyWorkController.info(java.lang.Integer)
14:40:06.133 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/downloadExcel],methods=[GET]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.downloadExcel(javax.servlet.http.HttpServletResponse,java.util.Map<java.lang.String, java.lang.Object>) throws java.io.IOException
14:40:06.133 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/companywork/uploadExcel],methods=[POST]}" onto public void com.ztman.ztspark.controller.CompanyWorkController.uploadExcel(org.springframework.web.multipart.MultipartFile) throws java.lang.Exception
14:40:06.136 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerify(com.ztman.ztspark.entity.workorder.dto.WorkOrderVerifyDTO)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDetail(java.lang.String)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/{id}],methods=[DELETE]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderDelete(java.lang.String)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/page],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String) throws java.io.IOException
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/assign],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssign(com.ztman.ztspark.entity.workorder.dto.WorkOrderAssignDTO)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/process/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderProcess(java.lang.String)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderAssignList],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(int,int,java.lang.String,java.lang.String,java.lang.String)
14:40:06.137 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/import],methods=[GET]}" onto public void com.ztman.ztspark.controller.ScheduleController.workOrderListImport(javax.servlet.http.HttpServletResponse,java.lang.String,java.lang.String,java.lang.String,java.lang.String)
14:40:06.138 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/supervise],methods=[PUT]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderSupervise(com.ztman.ztspark.entity.workorder.dto.WorkOrderSuperviseDTO)
14:40:06.138 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/attachment/{id}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderAttachment(java.lang.String)
14:40:06.138 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrder/verify/{workOrderId}],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderVerifyDetail(java.lang.String)
14:40:06.138 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/schedule/workOrderStatistics],methods=[GET]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.ScheduleController.workOrderStatistics()
14:40:06.140 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/upload/singlefile],methods=[POST],consumes=[multipart/form-data]}" onto public com.ztman.common.core.util.R com.ztman.ztspark.controller.UploadController.singlefile(org.springframework.web.multipart.MultipartFile) throws java.io.IOException
14:40:06.142 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/security]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
14:40:06.142 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources/configuration/ui]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
14:40:06.143 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/swagger-resources]}" onto public org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
14:40:06.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
14:40:06.145 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:40:06.270 zt-spark [restartedMain] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 20 endpoint(s) beneath base path '/actuator'
14:40:06.282 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/archaius],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.283 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/auditevents],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/beans],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/conditions],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/configprops],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.284 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env/{toMatch}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/env],methods=[DELETE],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/loggers/{name}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.285 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/heapdump],methods=[GET],produces=[application/octet-stream]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/threaddump],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics/{requiredMetricName}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/metrics],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/scheduledtasks],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/httptrace],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/mappings],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/refresh],methods=[POST],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/features],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.286 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.287 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator/service-registry],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v2+json || application/json],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
14:40:06.287 zt-spark [restartedMain] INFO  o.s.b.a.e.w.s.WebMvcEndpointHandlerMapping - Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
14:40:06.556 zt-spark [restartedMain] INFO  s.d.s.w.PropertySourcedRequestMappingHandlerMapping - Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)]
14:40:06.617 zt-spark [restartedMain] WARN  c.n.c.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
14:40:06.617 zt-spark [restartedMain] INFO  c.n.c.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
14:40:06.737 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:40:06.827 zt-spark [restartedMain] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@293a3739: startup date [Fri Sep 11 14:39:59 CST 2020]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3b0dc9f4
14:40:06.882 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:40:06.882 zt-spark [restartedMain] INFO  o.s.w.s.h.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
14:40:07.573 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
14:40:07.581 zt-spark [restartedMain] INFO  o.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
14:40:07.581 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.0 created.
14:40:07.582 zt-spark [restartedMain] INFO  org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
14:40:07.582 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'quartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

14:40:07.582 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'quartzScheduler' initialized from an externally provided properties instance.
14:40:07.582 zt-spark [restartedMain] INFO  org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.0
14:40:07.582 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - JobFactory set to: org.springframework.boot.autoconfigure.quartz.AutowireCapableBeanJobFactory@73befb99
14:40:07.648 zt-spark [restartedMain] INFO  o.s.b.a.s.s.UserDetailsServiceAutoConfiguration - 

Using generated security password: b685b5c4-c8c9-496b-9616-7a009f27da07

14:40:07.783 zt-spark [restartedMain] INFO  o.s.s.web.DefaultSecurityFilterChain - Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@13fe25c3, org.springframework.security.web.context.SecurityContextPersistenceFilter@6dc278a2, org.springframework.security.web.header.HeaderWriterFilter@3c06745f, org.springframework.security.web.authentication.logout.LogoutFilter@1fa631a5, org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter@600f865a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@66f3c39f, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5075b615, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@287145a9, org.springframework.security.web.session.SessionManagementFilter@cef04ce, org.springframework.security.web.access.ExceptionTranslationFilter@c05c93d, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@25b3d006]
14:40:07.908 zt-spark [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
14:40:08.097 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
14:40:08.103 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
14:40:08.240 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
14:40:08.242 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'statFilter' has been autodetected for JMX exposure
14:40:08.242 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
14:40:08.251 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
14:40:08.252 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
14:40:08.253 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
14:40:08.256 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
14:40:08.264 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
14:40:08.276 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=293a3739,type=ConfigurationPropertiesRebinder]
14:40:08.281 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
14:40:08.283 zt-spark [restartedMain] INFO  o.s.j.e.a.AnnotationMBeanExporter - Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
14:40:08.304 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 0
14:40:08.317 zt-spark [restartedMain] INFO  o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
14:40:08.320 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
14:40:08.321 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
14:40:08.321 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
14:40:08.321 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
14:40:08.321 zt-spark [restartedMain] INFO  c.n.d.p.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
14:40:08.401 zt-spark [restartedMain] INFO  c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Disable delta property : false
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application is null : false
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Application version is -1: true
14:40:08.403 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
14:40:08.407 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - The response status is 200
14:40:08.408 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
14:40:08.411 zt-spark [restartedMain] INFO  c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
14:40:08.413 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1599806408413 with initial instances count: 4
14:40:08.434 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaServiceRegistry - Registering application zt-spark with eureka with status UP
14:40:08.435 zt-spark [restartedMain] INFO  c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1599806408435, current=UP, previous=STARTING]
14:40:08.437 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201: registering service...
14:40:08.441 zt-spark [restartedMain] INFO  o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483647
14:40:08.442 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
14:40:08.468 zt-spark [restartedMain] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
14:40:08.570 zt-spark [DiscoveryClient-InstanceInfoReplicator-0] INFO  c.netflix.discovery.DiscoveryClient - DiscoveryClient_ZT-SPARK/WIN-4PV4BLRG218:zt-spark:9201 - registration status: 204
14:40:08.591 zt-spark [restartedMain] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
14:40:08.678 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_1
14:40:08.679 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_1
14:40:08.680 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_1
14:40:08.686 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_1
14:40:08.687 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_1
14:40:08.689 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_2
14:40:08.690 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_2
14:40:08.691 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_2
14:40:08.699 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_1
14:40:08.706 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_2
14:40:08.707 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_2
14:40:08.707 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_1
14:40:08.709 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: deleteUsingDELETE_3
14:40:08.709 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: downloadExcelUsingGET_3
14:40:08.710 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: infoUsingGET_3
14:40:08.711 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: pageUsingGET_2
14:40:08.715 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: saveUsingPOST_3
14:40:08.716 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: updateUsingPUT_3
14:40:08.717 zt-spark [restartedMain] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: uploadExcelUsingPOST_2
14:40:08.739 zt-spark [restartedMain] INFO  o.s.s.quartz.SchedulerFactoryBean - Starting Quartz Scheduler now
14:40:08.739 zt-spark [restartedMain] INFO  org.quartz.core.QuartzScheduler - Scheduler quartzScheduler_$_NON_CLUSTERED started.
14:40:08.754 zt-spark [restartedMain] INFO  o.s.s.a.ScheduledAnnotationBeanPostProcessor - No TaskScheduler/ScheduledExecutorService bean found for scheduled processing
14:40:08.760 zt-spark [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9201"]
14:40:08.767 zt-spark [restartedMain] INFO  o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
14:40:08.790 zt-spark [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 9201 (http) with context path ''
14:40:08.791 zt-spark [restartedMain] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 9201
14:40:08.793 zt-spark [restartedMain] INFO  com.ztman.ztspark.ZtSparkApplication - Started ZtSparkApplication in 12.076 seconds (JVM running for 12.884)
14:40:08.836 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring FrameworkServlet 'dispatcherServlet'
14:40:08.836 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
14:40:08.850 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Fetching config from server at : http://192.168.10.139:2001/
14:40:08.856 zt-spark [RMI TCP Connection(2)-192.168.10.139] INFO  o.s.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 20 ms
14:40:09.018 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  o.s.c.c.c.ConfigServicePropertySourceLocator - Located environment: name=zt-spark, profiles=[dev], label=null, version=null, state=null
14:40:09.090 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.EpollProvider - Starting without optional epoll library
14:40:09.091 zt-spark [RMI TCP Connection(1)-192.168.10.139] INFO  io.lettuce.core.KqueueProvider - Starting without optional kqueue library
14:41:17.089 zt-spark [http-nio-9201-exec-1] INFO  o.s.b.f.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [org/springframework/jdbc/support/sql-error-codes.xml]
14:41:17.111 zt-spark [http-nio-9201-exec-1] INFO  o.s.j.support.SQLErrorCodesFactory - SQLErrorCodes loaded: [DB2, Derby, H2, HDB, HSQL, Informix, MS-SQL, MySQL, Oracle, PostgreSQL, Sybase]
14:41:17.127 zt-spark [http-nio-9201-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.jdbc.BadSqlGrammarException: 
### Error querying database.  Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND (
		1 = 1
		 
			 
			 
			  
		 
		 
		 
		)
		ORDER BY
		a.id desc
		 
			' at line 37
### The error may exist in file [E:\shudaSpace\spark\zt-spark-work\zt-spark\service\target\classes\mapper\WorkOrderMapper.xml]
### The error may involve defaultParameterMap
### The error occurred while setting parameters
### SQL: SELECT   a.id AS id,   a.problem_level AS problemLevel,   a.problem_type AS problemType,   a.problem_desc AS problemDesc,   a.equipment_name AS equipmentName,   a.report_addr AS reportAddr,   a.report_time AS reportTime,   b.user_realname AS reportPersonName,   a.report_lng AS reportLng,   a.report_lat AS reportLat,   a.attachment_group_id AS attachmentGroupId,   (   CASE   d.tag   WHEN '1' THEN   '已派遣'   WHEN '2' THEN   '已受理'   WHEN '3' THEN   '处置中'   WHEN '4' THEN   '已完成'   WHEN '5' THEN   '已关闭' ELSE '待派遣'   END   ) AS process   FROM   work_order AS a   INNER JOIN sys_user AS b ON a.report_person_id = b.user_id   LEFT JOIN ( SELECT c.work_order_id, MAX( c.tag ) tag FROM   work_order_process AS c GROUP BY c.work_order_id ) AS d ON a.id =   d.work_order_id   WHERE   a.del_flag = '0'   AND a.tenant_id =    AND (   1 = 1                                   )   ORDER BY   a.id desc        LIMIT 0,    30
### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND (
		1 = 1
		 
			 
			 
			  
		 
		 
		 
		)
		ORDER BY
		a.id desc
		 
			' at line 37
; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND (
		1 = 1
		 
			 
			 
			  
		 
		 
		 
		)
		ORDER BY
		a.id desc
		 
			' at line 37] with root cause
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND (
		1 = 1
		 
			 
			 
			  
		 
		 
		 
		)
		ORDER BY
		a.id desc
		 
			' at line 37
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425)
	at com.mysql.jdbc.Util.getInstance(Util.java:408)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:944)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3976)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3912)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2486)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1197)
	at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3409)
	at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440)
	at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3407)
	at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:167)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:498)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:63)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49)
	at com.baomidou.mybatisplus.plugins.PerformanceInterceptor.intercept(PerformanceInterceptor.java:156)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61)
	at com.sun.proxy.$Proxy234.query(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy234.query(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63)
	at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:326)
	at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:139)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy184.workOrderAssignList(Unknown Source)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl.workOrderAssignList(WorkOrderServiceImpl.java:110)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl$$FastClassBySpringCGLIB$$8df30e67.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl$$EnhancerBySpringCGLIB$$17a58835.workOrderAssignList(<generated>)
	at com.ztman.ztspark.controller.ScheduleController.workOrderAssignList(ScheduleController.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
14:41:17.127 zt-spark [http-nio-9201-exec-2] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.jdbc.BadSqlGrammarException: 
### Error querying database.  Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND NOT EXISTS(
		select 1 from work_order_process as b
		where b.work_order_id ' at line 2
### The error may exist in file [E:\shudaSpace\spark\zt-spark-work\zt-spark\service\target\classes\mapper\WorkOrderMapper.xml]
### The error may involve defaultParameterMap
### The error occurred while setting parameters
### SQL: select 'pql' k ,count(1) v from work_order as a   where a.tenant_id =  AND NOT EXISTS(   select 1 from work_order_process as b   where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2' OR b.tag = '4'   OR b.tag = '5')   )   UNION ALL     select 'czl' k,count(1) v from work_order as a   where a.tenant_id =  AND   EXISTS(   select 1 from work_order_process as b   where b.work_order_id = a.id and (b.tag = '1' OR b.tag = '2')   )   AND   NOT EXISTS(   select 1 from work_order_process as b   where b.work_order_id = a.id and (b.tag = '4' OR b.tag = '5')   )   UNION ALL     select 'wcl' k,count(1) v from work_order as a   where a.tenant_id =  AND   EXISTS(   select 1 from work_order_process as b   where b.work_order_id = a.id and b.tag = '4'   )   AND   NOT EXISTS(   select 1 from work_order_process as b   where b.work_order_id = a.id and b.tag = '5'   )
### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND NOT EXISTS(
		select 1 from work_order_process as b
		where b.work_order_id ' at line 2
; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND NOT EXISTS(
		select 1 from work_order_process as b
		where b.work_order_id ' at line 2] with root cause
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND NOT EXISTS(
		select 1 from work_order_process as b
		where b.work_order_id ' at line 2
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425)
	at com.mysql.jdbc.Util.getInstance(Util.java:408)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:944)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3976)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3912)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2486)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1197)
	at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3409)
	at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440)
	at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3407)
	at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:167)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:498)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:63)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49)
	at com.baomidou.mybatisplus.plugins.PerformanceInterceptor.intercept(PerformanceInterceptor.java:156)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61)
	at com.sun.proxy.$Proxy234.query(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy234.query(Unknown Source)
	at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63)
	at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:326)
	at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433)
	at com.sun.proxy.$Proxy173.selectList(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230)
	at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:139)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy184.statistics(Unknown Source)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl.workOrderStatistics(WorkOrderServiceImpl.java:126)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl$$FastClassBySpringCGLIB$$8df30e67.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.ztman.ztspark.service.impl.WorkOrderServiceImpl$$EnhancerBySpringCGLIB$$17a58835.workOrderStatistics(<generated>)
	at com.ztman.ztspark.controller.ScheduleController.workOrderStatistics(ScheduleController.java:361)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
